{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction This platform is a collection of tools that aim to automate the process of collecting memory samples of numerous micro-controllers and their subsequent storage for future analysis. The memory data gathered will then be used mainly for SRAM-based Physical Unclonable Functions (PUF) analysis, as it is normally very difficult to gather enough data for this type of analysis. Motivation The purpose of our open platform is twofold: To provide easy access to a comprehensive database that includes thousands of samples of multiple boards, and to share the platform to carry out tailored experiments related to NBTI and data remanence effects. Our open platform succeeds in both aspects. From the economic point of view, our platform will save many resources to the users in terms of money (buying hundreds of devices) and time (collecting thousands of samples). Using the available raw-data, any user of the platform can carry out their own experiments (e.g. design of new post-processing, find systematic variations, etc.) with an enough number of samples and devices to consider the experiment statistically significant. Besides, the extra information provided (operating conditions, wafer position, etc) will open new possibilities to find vulnerabilities and develop new metrics. As a totally new feature, to the best of our knowledge unique up to the date, we offer the user the possibility of interaction with the boards by controlling the switch On/Off time of the micro-controllers (data remanence studies) and writing custom values in the SRAM (NBTI studies). Documentation structure The section Getting started shows how to install the platform and the dependencies required. The implementation of the platform is described in detail here . The documentation of the current platform is shown here","title":"Introduction"},{"location":"#introduction","text":"This platform is a collection of tools that aim to automate the process of collecting memory samples of numerous micro-controllers and their subsequent storage for future analysis. The memory data gathered will then be used mainly for SRAM-based Physical Unclonable Functions (PUF) analysis, as it is normally very difficult to gather enough data for this type of analysis.","title":"Introduction"},{"location":"#motivation","text":"The purpose of our open platform is twofold: To provide easy access to a comprehensive database that includes thousands of samples of multiple boards, and to share the platform to carry out tailored experiments related to NBTI and data remanence effects. Our open platform succeeds in both aspects. From the economic point of view, our platform will save many resources to the users in terms of money (buying hundreds of devices) and time (collecting thousands of samples). Using the available raw-data, any user of the platform can carry out their own experiments (e.g. design of new post-processing, find systematic variations, etc.) with an enough number of samples and devices to consider the experiment statistically significant. Besides, the extra information provided (operating conditions, wafer position, etc) will open new possibilities to find vulnerabilities and develop new metrics. As a totally new feature, to the best of our knowledge unique up to the date, we offer the user the possibility of interaction with the boards by controlling the switch On/Off time of the micro-controllers (data remanence studies) and writing custom values in the SRAM (NBTI studies).","title":"Motivation"},{"location":"#documentation-structure","text":"The section Getting started shows how to install the platform and the dependencies required. The implementation of the platform is described in detail here . The documentation of the current platform is shown here","title":"Documentation structure"},{"location":"code_exec/","text":"Code execution Custom code can be loaded into the devices memory and executed later thanks to zForth .","title":"Code Execution"},{"location":"code_exec/#code-execution","text":"Custom code can be loaded into the devices memory and executed later thanks to zForth .","title":"Code execution"},{"location":"commands/","text":"Executing commands A command refers to an operation that the station can carry out. All of the information necesary to carry such operation should be written to the header of the packet. Command Command code Description ACK 1 Packet acknowledge. PING 2 Discover devices in a chain. READ 3 Read a region of memory from a device. WRITE 4 Write values to a region of memory of a device. SENSORS 5 Read sensors from a device. LOAD 6 Load code into memory to be interpreted later. EXEC 7 Interpret code stored in memory. RETR 8 Retrieve the results from the code. ERR 255 Error during transmision. Info The script send_command.py can be used to send one of the predefined commands above to a running agent from the CLI. Once an agent has been deployed, and a reader has been assigned to it, new messages can be sent to the agent directly as seen below. Sending a message with an agent from fenneq import Agent # URL and exchange_name have to be the same as the other agents url = \"amqp://user:pass@localhost\" exchange_name = \"sram_commands\" topic = \"sram.discovery\" agent = Agent ( url , exchange_name , topic , Agent . JSON ) msg = { 'method' : 'READ' } # Message will be sent to sram.discovery agent . send ( msg ) # The message can be sent to another topic with the same agent agent . send ( msg , name = \"sram.nucleo\" ) Station commands Power on Power on the serial port connected to the dispatcher. Parameters { \"command\" : \"power_on\" } Logging Level Description INFO Port powered on. WARNING Could not power on port. ERROR Problem powering on port {port}: {reason}. Power off Power off the serial port connected to the dispatcher. Parameters { \"command\" : \"power_off\" } Logging Level Description INFO Port powered off. WARNING Could not power off port. ERROR Problem powering off port {port}: {reason}. Status Check whether the serial port of the dispatcher is on or off and the number of devices it is managing. Parameters { \"command\" : \"status\" } Results { \"state\" : \"ON\" | \"OFF\" , \"devices\" : [{ \"uid\" : str , \"pic\" : int , \"sram_size\" : int }, ... ] } Ping Register devices that are in the chain connected to the serial port. Parameters { \"command\" : \"ping\" } Logging Level Description ERROR Serial port is off. Please turn on the serial port first. ERROR There were devices connected but now no devices could be identified. ERROR No devices could be identified. WARNING Packet {packet} is corrupted. Results [{ \"uid\" : str , \"pic\" : int , \"sram_size\" : int }, ... ] Read Read all regions of memory from all devices managed by the dispatcher. This command can be done per device and per region of memory but it is performed on all devices and regions in one go. The ping command has to be executed first. Parameters { \"command\" : \"read\" } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Problem reading memory of device {device} at offset {offset} WARNING Packet {packet} for device {device} is corrupted. INFO Finished reading memory of device {device}. Write Write values to a region of memory of a device managed by the dispatcher. The ping command has to be executed first. Parameters { \"command\" : \"write\" , \"device\" : str , \"data\" : list [ int ], \"offset\" : int } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Device {device} is not managed. ERROR Offset {offset} for device {device} must be in range [0, {max_offset}] ERROR Problem writing to device {device} at offset {offset} ERROR Packet {packet} for device {device} is corrupted. INFO Data written correctly. Write invert Write inverted values to half of the devices managed by a dispatcher. Inverted values are calculated based on the first sample (a.k.a. reference sample) of a device. The ping command has to be executed first. Parameters { \"command\" : \"write_invert\" } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. WARNING At least one full memory sample has to be read from device {device}. WARNING The memory sample for device {device} is not complete. ERROR Problem writing inverted values to device {device} at offset {offset} ERROR Packet {packet} for device {device} is corrupted. DEBUG Wrote inverted values of device {device} at offset {offset}. INFO Finished inverting memory of device {device}. Sensors Read the sensors of the devices managed by a dispatcher. The ping command has to be executed first. Parameters { \"command\" : \"sensors\" } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Problem reading sensors of device {device}. WARNING Packet {packet} for device {device} is corrupted. Results { \"device\" : { \"uid\" : str , \"pic\" : int }, \"temperature\" : float , \"voltage\" : float } Load Load code onto a device managed by the dispatcher. The ping command has to be executed first. Parameters { \"command\" : \"load\" , \"device\" : str , \"source\" : str , \"offset\" : int } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Device {device} is not managed. ERROR Problem loading code for device {device}. ERROR Packet {packet} for device {device} is corrupted. INFO Code loaded on device {device} correctly. Execute Execute code loaded into a device managed by the dispatcher and write the results to memory. The ping command has to be executed first. Parameters { \"command\" : \"exec\" , \"device\" : str , \"reset\" : bool } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Device {device} is not managed. ERROR Problem executing code on device {device}. ERROR Packet {packet} for device {device} is corrupted. ERROR Code on device {device} executed with error code {code}. INFO Code executed on device {device} correctly. Retrieve Retrieve the results from executing loaded code from a device managed by the dispatcher. The ping command has to be executed first. Parameters { \"command\" : \"retr\" , \"device\" : str } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Device {device} is not managed. ERROR Problem retrieving results from device {device}. ERROR Packet {packet} for device {device} is corrupted. INFO Results retrieved correctly from device {device}. Results { \"raw_bytes\" : bytes , \"int\" : list [ int ], \"string\" : str }","title":"Available commands"},{"location":"commands/#executing-commands","text":"A command refers to an operation that the station can carry out. All of the information necesary to carry such operation should be written to the header of the packet. Command Command code Description ACK 1 Packet acknowledge. PING 2 Discover devices in a chain. READ 3 Read a region of memory from a device. WRITE 4 Write values to a region of memory of a device. SENSORS 5 Read sensors from a device. LOAD 6 Load code into memory to be interpreted later. EXEC 7 Interpret code stored in memory. RETR 8 Retrieve the results from the code. ERR 255 Error during transmision. Info The script send_command.py can be used to send one of the predefined commands above to a running agent from the CLI. Once an agent has been deployed, and a reader has been assigned to it, new messages can be sent to the agent directly as seen below. Sending a message with an agent from fenneq import Agent # URL and exchange_name have to be the same as the other agents url = \"amqp://user:pass@localhost\" exchange_name = \"sram_commands\" topic = \"sram.discovery\" agent = Agent ( url , exchange_name , topic , Agent . JSON ) msg = { 'method' : 'READ' } # Message will be sent to sram.discovery agent . send ( msg ) # The message can be sent to another topic with the same agent agent . send ( msg , name = \"sram.nucleo\" )","title":"Executing commands"},{"location":"commands/#station-commands","text":"","title":"Station commands"},{"location":"commands/#power-on","text":"Power on the serial port connected to the dispatcher. Parameters { \"command\" : \"power_on\" } Logging Level Description INFO Port powered on. WARNING Could not power on port. ERROR Problem powering on port {port}: {reason}.","title":"Power on"},{"location":"commands/#power-off","text":"Power off the serial port connected to the dispatcher. Parameters { \"command\" : \"power_off\" } Logging Level Description INFO Port powered off. WARNING Could not power off port. ERROR Problem powering off port {port}: {reason}.","title":"Power off"},{"location":"commands/#status","text":"Check whether the serial port of the dispatcher is on or off and the number of devices it is managing. Parameters { \"command\" : \"status\" } Results { \"state\" : \"ON\" | \"OFF\" , \"devices\" : [{ \"uid\" : str , \"pic\" : int , \"sram_size\" : int }, ... ] }","title":"Status"},{"location":"commands/#ping","text":"Register devices that are in the chain connected to the serial port. Parameters { \"command\" : \"ping\" } Logging Level Description ERROR Serial port is off. Please turn on the serial port first. ERROR There were devices connected but now no devices could be identified. ERROR No devices could be identified. WARNING Packet {packet} is corrupted. Results [{ \"uid\" : str , \"pic\" : int , \"sram_size\" : int }, ... ]","title":"Ping"},{"location":"commands/#read","text":"Read all regions of memory from all devices managed by the dispatcher. This command can be done per device and per region of memory but it is performed on all devices and regions in one go. The ping command has to be executed first. Parameters { \"command\" : \"read\" } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Problem reading memory of device {device} at offset {offset} WARNING Packet {packet} for device {device} is corrupted. INFO Finished reading memory of device {device}.","title":"Read"},{"location":"commands/#write","text":"Write values to a region of memory of a device managed by the dispatcher. The ping command has to be executed first. Parameters { \"command\" : \"write\" , \"device\" : str , \"data\" : list [ int ], \"offset\" : int } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Device {device} is not managed. ERROR Offset {offset} for device {device} must be in range [0, {max_offset}] ERROR Problem writing to device {device} at offset {offset} ERROR Packet {packet} for device {device} is corrupted. INFO Data written correctly.","title":"Write"},{"location":"commands/#write-invert","text":"Write inverted values to half of the devices managed by a dispatcher. Inverted values are calculated based on the first sample (a.k.a. reference sample) of a device. The ping command has to be executed first. Parameters { \"command\" : \"write_invert\" } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. WARNING At least one full memory sample has to be read from device {device}. WARNING The memory sample for device {device} is not complete. ERROR Problem writing inverted values to device {device} at offset {offset} ERROR Packet {packet} for device {device} is corrupted. DEBUG Wrote inverted values of device {device} at offset {offset}. INFO Finished inverting memory of device {device}.","title":"Write invert"},{"location":"commands/#sensors","text":"Read the sensors of the devices managed by a dispatcher. The ping command has to be executed first. Parameters { \"command\" : \"sensors\" } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Problem reading sensors of device {device}. WARNING Packet {packet} for device {device} is corrupted. Results { \"device\" : { \"uid\" : str , \"pic\" : int }, \"temperature\" : float , \"voltage\" : float }","title":"Sensors"},{"location":"commands/#load","text":"Load code onto a device managed by the dispatcher. The ping command has to be executed first. Parameters { \"command\" : \"load\" , \"device\" : str , \"source\" : str , \"offset\" : int } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Device {device} is not managed. ERROR Problem loading code for device {device}. ERROR Packet {packet} for device {device} is corrupted. INFO Code loaded on device {device} correctly.","title":"Load"},{"location":"commands/#execute","text":"Execute code loaded into a device managed by the dispatcher and write the results to memory. The ping command has to be executed first. Parameters { \"command\" : \"exec\" , \"device\" : str , \"reset\" : bool } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Device {device} is not managed. ERROR Problem executing code on device {device}. ERROR Packet {packet} for device {device} is corrupted. ERROR Code on device {device} executed with error code {code}. INFO Code executed on device {device} correctly.","title":"Execute"},{"location":"commands/#retrieve","text":"Retrieve the results from executing loaded code from a device managed by the dispatcher. The ping command has to be executed first. Parameters { \"command\" : \"retr\" , \"device\" : str } Logging Code Description ERROR Serial port is off. Please turn on the serial port first. ERROR No devices managed. ERROR Device {device} is not managed. ERROR Problem retrieving results from device {device}. ERROR Packet {packet} for device {device} is corrupted. INFO Results retrieved correctly from device {device}. Results { \"raw_bytes\" : bytes , \"int\" : list [ int ], \"string\" : str }","title":"Retrieve"},{"location":"communication/","text":"Packet based protocol The communication between a reader and a device chain is performed using a custom packet based protocol. The source code documentation of the packet can be found :doc: here <packet> . Field Encoding Description Method uint8_t Type of packet. See commands PIC uint16_t Position In Chain . Index of the device in the chain Options uint16_t Metadata for the packet UID char[25] Universal ID of the device Checksum uint32_t Checksum of the packet Data uint8_t[DATA_SIZE] Actual data of the packet The DATA_SIZE can be defined by the user, but it has to be small than the smallest SRAM size of a device in the chain. Working with packets Example of creation of a packet packet = Packet () # Generate a packet with default values # The following are the default values packet . with_method ( Method . Ping ) packet . with_options ( 0x0 ) packet . with_checksum ( 0 ) packet . with_pic ( 1 ) packet . with_uid ( \"DEVICE ID\" ) packet . with_data ([ 0x0 , ... , 0x0 ]) packet . craft () # Craft the packet to send it # The packet can now be used by calling `to_bytes` print ( packet . to_bytes ()) Warning Even if the packet has the default configuration, is is necesary to craft it before sending it, otherwise it will raise a ValueError . The method is_crafted returns True if the packet is ready to be sent.","title":"Communication"},{"location":"communication/#packet-based-protocol","text":"The communication between a reader and a device chain is performed using a custom packet based protocol. The source code documentation of the packet can be found :doc: here <packet> . Field Encoding Description Method uint8_t Type of packet. See commands PIC uint16_t Position In Chain . Index of the device in the chain Options uint16_t Metadata for the packet UID char[25] Universal ID of the device Checksum uint32_t Checksum of the packet Data uint8_t[DATA_SIZE] Actual data of the packet The DATA_SIZE can be defined by the user, but it has to be small than the smallest SRAM size of a device in the chain.","title":"Packet based protocol"},{"location":"communication/#working-with-packets","text":"Example of creation of a packet packet = Packet () # Generate a packet with default values # The following are the default values packet . with_method ( Method . Ping ) packet . with_options ( 0x0 ) packet . with_checksum ( 0 ) packet . with_pic ( 1 ) packet . with_uid ( \"DEVICE ID\" ) packet . with_data ([ 0x0 , ... , 0x0 ]) packet . craft () # Craft the packet to send it # The packet can now be used by calling `to_bytes` print ( packet . to_bytes ()) Warning Even if the packet has the default configuration, is is necesary to craft it before sending it, otherwise it will raise a ValueError . The method is_crafted returns True if the packet is ready to be sent.","title":"Working with packets"},{"location":"database/","text":"Storage The information is stored in a PostreSQL database. In the python code, the database is managed with the sqlalchemy ORM. That means that the tables in the database can be created from a python class. All of the logic concerning the database is carried out by the DBManager class. Schema definition SRAM samples and sensors are managed by the classes Sample and Sensor respectively. Storing samples and sensor information Example of storing a sample and sensor url = \"postgres://username:password@localhost:5432/database\" db = DBManager ( url ) sample = Sample ( uid = \"DEVICE ID\" , board_id = \"NUCLEO\" , pic = 1 , address = \"0x20000000\" , data = \",\" . join ([ str ( d ) for d in range ( 1024 )]), created_at = datetime . now (), ) db . insert ( sample ) sensor = Sensor ( uid = \"DEVICE ID\" , board_id = \"NUCLEO\" , temperature = 27 , voltage = 3300 , ) db . insert ( sensor ) db . commit ()","title":"Storage"},{"location":"database/#storage","text":"The information is stored in a PostreSQL database. In the python code, the database is managed with the sqlalchemy ORM. That means that the tables in the database can be created from a python class. All of the logic concerning the database is carried out by the DBManager class.","title":"Storage"},{"location":"database/#schema-definition","text":"SRAM samples and sensors are managed by the classes Sample and Sensor respectively.","title":"Schema definition"},{"location":"database/#storing-samples-and-sensor-information","text":"Example of storing a sample and sensor url = \"postgres://username:password@localhost:5432/database\" db = DBManager ( url ) sample = Sample ( uid = \"DEVICE ID\" , board_id = \"NUCLEO\" , pic = 1 , address = \"0x20000000\" , data = \",\" . join ([ str ( d ) for d in range ( 1024 )]), created_at = datetime . now (), ) db . insert ( sample ) sensor = Sensor ( uid = \"DEVICE ID\" , board_id = \"NUCLEO\" , temperature = 27 , voltage = 3300 , ) db . insert ( sensor ) db . commit ()","title":"Storing samples and sensor information"},{"location":"deployment/","text":"Setup guide This section will describe the requirements needed to deploy a station. Here we describe first the software requirements followed by the hardware requirements and lastly, their physical installation and deployment. Device source code This project contains code for two different STM32 boards. Each project is managed by STM32Cube. Devices should be programmed using the same software. Setting up docker The file docker-compose.yml provides the template necesary to launch those services. However, it is necesary to update the configuration values in the file before deploying. The main parameters to modify are user and password of both RabbitMQ and PostgreSQL. The other important parameter is the volume configuration for postgreSQL, (e.g. where to store the data in the computer). The path before the semicolon points to the path in the computer where to store the samples. The path after the semicolorn should not be modified . Note We can think of docker as a virtual machine. We can provide some paths (here volumes ) in the computer that will get linked to a path inside the container. The syntax is path_in_computer:path_in_docker . Example of docker-compose file version : \"3.9\" services : rabbitmq : image : rabbitmq:3-management-alpine container_name : 'rabbitmq' environment : RABBITMQ_ERLANG_COOKIE : \"ERLANG COOKIE\" RABBITMQ_DEFAULT_USER : \"username\" RABBITMQ_DEFAULT_PASS : \"password\" RABBITMQ_DEFAULT_VHOST : \"/\" ports : - 5672:5672 - 15672:15672 networks : - rabbitmq_net postgres : image : postgres:latest container_name : \"postgre\" environment : POSTGRES_USER : \"username\" POSTGRES_PASSWORD : \"password\" POSTGRES_DB : \"database\" ports : - 5432:5432 volumes : - /path/to/db:/var/lib/postgresql/data networks : rabbitmq_net : driver : bridge Start services with docker-compose $ docker-compose up -d -f /path/to/docker-compose.yml $ docker-compose up -d # If in the same path as docker-compose.yml Stop docker services $ docker-compose down # In the same path as docker-compose.yml Deployment services Once all the software is installed and the hardware is properly connected, the station should be ready for deployment. The deployment of the station can be carried out with the use of systemd services. #!/usr/bin/env python3 from sramplatform import Dispatcher , ConnParameters # Custom implementation of Reader from customreader import CustomReader reader = CustomReader ( \"Discovery\" , 0 , 125_000 ) params = ConnParameters ( \"rabbitmq_user\" , \"rabbitmq_pass\" ) platform = Dispatcher ( params , \"exchange_commands\" , \"station_name\" , \"exchange_logs\" ) platform . add_command ({ \"method\" : \"read\" }, reader . handle_read ) platform . add_command ({ \"method\" : \"write\" , \"data\" : True }, reader . handle_write ) if __name__ == '__main__' : platform . run () [Unit] Description=SRAM Reliability Platform After=network.target [Service] Type=simple Restart=always RestartSec=5 WorkingDirectory=/path/to/SRAMPlatform ExecStart=/path/to/virtualenv/bin/python3 main.py [Install] WantedBy=multi-user.target Operations can be scheduled by using the send_command.py script provided and a systemd timer (very similar to a cron job). The following example illustrates how to create the files necesary to power off the platform every friday at 17:00. [Unit] Description=Power off the SRAM Platform [Timer] OnCalendar=Fri *-*-* 17:00:00 Persistent=true [Install] WantedBy=timers.target [Unit] Description=Power off the SRAM Platform After=network.target [Service] Type=oneshot RemainAfterExit=true WorkingDirectory=/path/to/SRAMPlatform ExecStart=/path/to/virtualenv/bin/python3 send_command.py \"OFF\" [Install] WantedBy=multi-user.target Configuring a dispatcher Example of configuration agent : url : \"amqp://user:password@hostname\" name : \"agent name\" exchange : \"rabbitmq exchange\" reader : board_type : \"Type of board the reader manages\" port : \"/path/to/ttyUSB\" baudrate : 125000 logging : format : \"[%(asctime)s] [%(levelname)-8s] %(message)s\" datefmt : \"%H:%M:%S %d-%m-%Y\" loggers : - TelegramHandler : level : WARNING # INFO by default token : \"Telegram Bot Token\" chat_ids : 00000000000 # Custom log format format : \"[%(asctime)s] %(name)s\\n%(message)s\" # Filter logs with highel level than filter_level # If level and filter are defined, the logs allowed are # level <= level < filter_level filter_level : RESULTS - RabbitMQHandler : key : \"routing key\" exchange : \"\" - StreamHandler : level : DEBUG - MailHandler : email : \"email@gmail.com\" oauth : \"/path/to/oauth.json\" recipients : subject : - FileHandler : path : \"/path/to/file.log\" - RotatingFileHandler : path : \"/path/to/file.log\" maxBytes : 20000 backupCount : 7 - TimedRotatingFileHandler : path : \"/path/to/file.log\" when : \"midnight\" backupCount : 7","title":"Deployment"},{"location":"deployment/#setup-guide","text":"This section will describe the requirements needed to deploy a station. Here we describe first the software requirements followed by the hardware requirements and lastly, their physical installation and deployment.","title":"Setup guide"},{"location":"deployment/#device-source-code","text":"This project contains code for two different STM32 boards. Each project is managed by STM32Cube. Devices should be programmed using the same software.","title":"Device source code"},{"location":"deployment/#setting-up-docker","text":"The file docker-compose.yml provides the template necesary to launch those services. However, it is necesary to update the configuration values in the file before deploying. The main parameters to modify are user and password of both RabbitMQ and PostgreSQL. The other important parameter is the volume configuration for postgreSQL, (e.g. where to store the data in the computer). The path before the semicolon points to the path in the computer where to store the samples. The path after the semicolorn should not be modified . Note We can think of docker as a virtual machine. We can provide some paths (here volumes ) in the computer that will get linked to a path inside the container. The syntax is path_in_computer:path_in_docker . Example of docker-compose file version : \"3.9\" services : rabbitmq : image : rabbitmq:3-management-alpine container_name : 'rabbitmq' environment : RABBITMQ_ERLANG_COOKIE : \"ERLANG COOKIE\" RABBITMQ_DEFAULT_USER : \"username\" RABBITMQ_DEFAULT_PASS : \"password\" RABBITMQ_DEFAULT_VHOST : \"/\" ports : - 5672:5672 - 15672:15672 networks : - rabbitmq_net postgres : image : postgres:latest container_name : \"postgre\" environment : POSTGRES_USER : \"username\" POSTGRES_PASSWORD : \"password\" POSTGRES_DB : \"database\" ports : - 5432:5432 volumes : - /path/to/db:/var/lib/postgresql/data networks : rabbitmq_net : driver : bridge Start services with docker-compose $ docker-compose up -d -f /path/to/docker-compose.yml $ docker-compose up -d # If in the same path as docker-compose.yml Stop docker services $ docker-compose down # In the same path as docker-compose.yml","title":"Setting up docker"},{"location":"deployment/#deployment-services","text":"Once all the software is installed and the hardware is properly connected, the station should be ready for deployment. The deployment of the station can be carried out with the use of systemd services. #!/usr/bin/env python3 from sramplatform import Dispatcher , ConnParameters # Custom implementation of Reader from customreader import CustomReader reader = CustomReader ( \"Discovery\" , 0 , 125_000 ) params = ConnParameters ( \"rabbitmq_user\" , \"rabbitmq_pass\" ) platform = Dispatcher ( params , \"exchange_commands\" , \"station_name\" , \"exchange_logs\" ) platform . add_command ({ \"method\" : \"read\" }, reader . handle_read ) platform . add_command ({ \"method\" : \"write\" , \"data\" : True }, reader . handle_write ) if __name__ == '__main__' : platform . run () [Unit] Description=SRAM Reliability Platform After=network.target [Service] Type=simple Restart=always RestartSec=5 WorkingDirectory=/path/to/SRAMPlatform ExecStart=/path/to/virtualenv/bin/python3 main.py [Install] WantedBy=multi-user.target Operations can be scheduled by using the send_command.py script provided and a systemd timer (very similar to a cron job). The following example illustrates how to create the files necesary to power off the platform every friday at 17:00. [Unit] Description=Power off the SRAM Platform [Timer] OnCalendar=Fri *-*-* 17:00:00 Persistent=true [Install] WantedBy=timers.target [Unit] Description=Power off the SRAM Platform After=network.target [Service] Type=oneshot RemainAfterExit=true WorkingDirectory=/path/to/SRAMPlatform ExecStart=/path/to/virtualenv/bin/python3 send_command.py \"OFF\" [Install] WantedBy=multi-user.target","title":"Deployment services"},{"location":"deployment/#configuring-a-dispatcher","text":"Example of configuration agent : url : \"amqp://user:password@hostname\" name : \"agent name\" exchange : \"rabbitmq exchange\" reader : board_type : \"Type of board the reader manages\" port : \"/path/to/ttyUSB\" baudrate : 125000 logging : format : \"[%(asctime)s] [%(levelname)-8s] %(message)s\" datefmt : \"%H:%M:%S %d-%m-%Y\" loggers : - TelegramHandler : level : WARNING # INFO by default token : \"Telegram Bot Token\" chat_ids : 00000000000 # Custom log format format : \"[%(asctime)s] %(name)s\\n%(message)s\" # Filter logs with highel level than filter_level # If level and filter are defined, the logs allowed are # level <= level < filter_level filter_level : RESULTS - RabbitMQHandler : key : \"routing key\" exchange : \"\" - StreamHandler : level : DEBUG - MailHandler : email : \"email@gmail.com\" oauth : \"/path/to/oauth.json\" recipients : subject : - FileHandler : path : \"/path/to/file.log\" - RotatingFileHandler : path : \"/path/to/file.log\" maxBytes : 20000 backupCount : 7 - TimedRotatingFileHandler : path : \"/path/to/file.log\" when : \"midnight\" backupCount : 7","title":"Configuring a dispatcher"},{"location":"description/","text":"The SRAM Platform is composed of 3 main components: A dispatcher to handle messages between the user and the platform. A reader to receive and send commands from and to the connected devices. The devices connected to the platform to be studied. There are also two other components, a database and logging manager, whose purpose is the storage of samples and the recording of commands respectively. The source code of the platform can be found under the directory sramplatform inside the project. The API reference can be accesed here . Dispatcher The dispatcher is the first big component of the platform. It will listen to messages comming from a message broker and will dispatch the appropiato command to the required reader. A message broker enables applications and systems to communicate with each other and exchange information. It is the main mechanism that allows a user to send commands to a station to be processed and executed later in time. RabbitMQ is the the message broker chosen. One of the advantages of using RabbitMQ is that we have access to queues to hold messages so that users can send multiple commands at a time without the need of waiting for them to be executed directly. In order to manage the connections to the message broker and handling the messages, the library makes use of fenneq agents. The documentation of fenneq provides in detail explanations on how to setup an agent to connect to RabbitMQ. Reader The objective of the reader is to be provide an iterface to communicate with the different devices. It receives the messages from the dispatcher after they have been filtered and it generates the necessary data to be send to the devices to carry out the desired command. The code written is this library is device agnostic, so a reader can manage multiple types of devices at the same time. However, it is advised that a reader is in charge of only a specific type of device. Multiple readers can be assigned to the same dispatcher to be able to perform some commands on a series of devices with just a simple group of commands. The basic functionaly of a reader is defined ith the Reader interface. The documentation for this component is found in the reader module. Device A device is the smallest unit of the station. These are the physical devices whose memory will be read and studied. This framework is designed to work with microcontrollers but it should work with other devices as long as the communication protocol is implemented. Info In this documentation, the terms device and board are equivalent. Database manager The objective of this platform is to retrieve the memory of devices in order to be analysed later. In order to store the samples a database needs to be used to reliable store samples and retrieve them efficiently. The parameters for connection to a database are handled by the DBParameters class. The connection itself and operations can be carried out with the DBManager class. The default database is PostreSQL but another database can be used by configuring the DBParameters and docker, since the operations in the database are managed by an ORM. The documentation for this manager is found in the storage module. Logging manager The logging manager keeps track of every command that has been executed by a reader and display any errors or information along the way. The logging component is implement through the logging module in the standard library. The platform provides also some custom handlers to alert the user, such as RabbitMQHandler , TelegramHandler and MailHandler . The documentation for this manager is found in the logbook module. The logging section of the platform configuration shows all available configuration options for logging. The section is shown below. Logging configuration logging : format : \"[%(asctime)s] [%(levelname)-8s] %(message)s\" datefmt : \"%H:%M:%S %d-%m-%Y\" loggers : - TelegramHandler : level : WARNING # INFO by default token : \"Telegram Bot Token\" chat_ids : 00000000000 # Custom log format format : \"[%(asctime)s] %(name)s\\n%(message)s\" # Filter logs with highel level than filter_level # If level and filter are defined, the logs allowed are # level <= level < filter_level filter_level : RESULTS - RabbitMQHandler : key : \"routing key\" exchange : \"\" - StreamHandler : level : DEBUG - MailHandler : email : \"email@gmail.com\" oauth : \"/path/to/oauth.json\" recipients : subject : - FileHandler : path : \"/path/to/file.log\" - RotatingFileHandler : path : \"/path/to/file.log\" maxBytes : 20000 backupCount : 7 - TimedRotatingFileHandler : path : \"/path/to/file.log\" when : \"midnight\" backupCount : 7","title":"Description"},{"location":"description/#dispatcher","text":"The dispatcher is the first big component of the platform. It will listen to messages comming from a message broker and will dispatch the appropiato command to the required reader. A message broker enables applications and systems to communicate with each other and exchange information. It is the main mechanism that allows a user to send commands to a station to be processed and executed later in time. RabbitMQ is the the message broker chosen. One of the advantages of using RabbitMQ is that we have access to queues to hold messages so that users can send multiple commands at a time without the need of waiting for them to be executed directly. In order to manage the connections to the message broker and handling the messages, the library makes use of fenneq agents. The documentation of fenneq provides in detail explanations on how to setup an agent to connect to RabbitMQ.","title":"Dispatcher"},{"location":"description/#reader","text":"The objective of the reader is to be provide an iterface to communicate with the different devices. It receives the messages from the dispatcher after they have been filtered and it generates the necessary data to be send to the devices to carry out the desired command. The code written is this library is device agnostic, so a reader can manage multiple types of devices at the same time. However, it is advised that a reader is in charge of only a specific type of device. Multiple readers can be assigned to the same dispatcher to be able to perform some commands on a series of devices with just a simple group of commands. The basic functionaly of a reader is defined ith the Reader interface. The documentation for this component is found in the reader module.","title":"Reader"},{"location":"description/#device","text":"A device is the smallest unit of the station. These are the physical devices whose memory will be read and studied. This framework is designed to work with microcontrollers but it should work with other devices as long as the communication protocol is implemented. Info In this documentation, the terms device and board are equivalent.","title":"Device"},{"location":"description/#database-manager","text":"The objective of this platform is to retrieve the memory of devices in order to be analysed later. In order to store the samples a database needs to be used to reliable store samples and retrieve them efficiently. The parameters for connection to a database are handled by the DBParameters class. The connection itself and operations can be carried out with the DBManager class. The default database is PostreSQL but another database can be used by configuring the DBParameters and docker, since the operations in the database are managed by an ORM. The documentation for this manager is found in the storage module.","title":"Database manager"},{"location":"description/#logging-manager","text":"The logging manager keeps track of every command that has been executed by a reader and display any errors or information along the way. The logging component is implement through the logging module in the standard library. The platform provides also some custom handlers to alert the user, such as RabbitMQHandler , TelegramHandler and MailHandler . The documentation for this manager is found in the logbook module. The logging section of the platform configuration shows all available configuration options for logging. The section is shown below. Logging configuration logging : format : \"[%(asctime)s] [%(levelname)-8s] %(message)s\" datefmt : \"%H:%M:%S %d-%m-%Y\" loggers : - TelegramHandler : level : WARNING # INFO by default token : \"Telegram Bot Token\" chat_ids : 00000000000 # Custom log format format : \"[%(asctime)s] %(name)s\\n%(message)s\" # Filter logs with highel level than filter_level # If level and filter are defined, the logs allowed are # level <= level < filter_level filter_level : RESULTS - RabbitMQHandler : key : \"routing key\" exchange : \"\" - StreamHandler : level : DEBUG - MailHandler : email : \"email@gmail.com\" oauth : \"/path/to/oauth.json\" recipients : subject : - FileHandler : path : \"/path/to/file.log\" - RotatingFileHandler : path : \"/path/to/file.log\" maxBytes : 20000 backupCount : 7 - TimedRotatingFileHandler : path : \"/path/to/file.log\" when : \"midnight\" backupCount : 7","title":"Logging manager"},{"location":"device_api/","text":"The code for the different devices can be found in: SRAMPlatform/src/Device_Nucleo SRAMPlatform/src/Device_Discovery src/Device_Discovery \u2514\u2500\u2500 Core \u251c\u2500\u2500 Inc \u2502 \u251c\u2500\u2500 main.h \u2502 \u251c\u2500\u2500 sramconf.h \u2502 \u251c\u2500\u2500 sramplatform.h \u2502 \u2514\u2500\u2500 zforth.h \u2514\u2500\u2500 Src \u251c\u2500\u2500 main.c \u251c\u2500\u2500 sramplatform.c \u2514\u2500\u2500 zforth.c Example of sramconf.h #ifndef INC_SRAMCONF_H_ #define INC_SRAMCONF_H_ /// Start address of the SRAM #define SRAM_ADDRESS 0x20000000 /// Address of the VDD calibration value #define VDD_CAL_ADDRESS 0x1FF800F8 /// Address of the temperature at 30 calibration value #define TEMP30_CAL_ADDRESS 0x1FF800FA /// Address of the temperature at 110 calibration value #define TEMP110_CAL_ADDRESS 0x1FF800FE /// Number of blocks from SRAM_START the source buffer is located #define SRC_BUF_OFFSET 148 /// Number of blocks from SRAM_START the write buffer is located #define WRITE_BUF_OFFSET 150 /// Maximum number of bytes in the WRITE Buffer #define WRITE_BUF_MAX (DATA_SIZE) #endif /* INC_SRAMCONF_H_ */","title":"Device API"},{"location":"devices/","text":"Devices This platform was created with the intention of collecting data from micro-controllers. The devices we mainly have access to are the STM32L152RE and the STM32L152RCT6 . One of the limitations we have to solve is to maximize the number of devices we can connect to a computer. The USB protocol has a limitations of 127 devices in total, including USB hubs. Moreover the process of connecting or removing devices from a station will be very time consuming. In order to have relevant statistically relevant analysis for SRAM-based PUF, we need a very large number of devices (hundreds at least) so we need to use another solution for this. To solve this problem, the devices are connected in scan chains , that is, the computer connects to a device (the start of the chain) and the next device is connected to the device before it. Doing this the only limitation is having a power supply strong enough to keep all the connected devices turned on. The devices communicate between them by using the USART, which is very simple to configure and provides speeds of communication fast enough for this application. In order to control the devices that are connected to a chain, the station keeps track of each device unique id and their position in the chain (referred in the code as pic ). STM32 devices contain 96 internal bits stored in the SRAM, that can be used as a unique identifier of the device. In the case of using other devices, the user would need to store a unique id for each device in memory to be able to identify them in the future. To keep track of the position, each packet has a field called pic, that gets incremented every time a packet travels downstream. (Oposite as how the Time To Live of an IPC packet gets decremented after each jump). The process of gathering the information of every devices is through the PING command, described in detail commands . We can see in the following diagram, an example of how the different devices create chains and how different chains can be connected to a computer. USB Rx -> Tx Rx -> Tx Rx -> Tx Computer ------> Device ----------> Device ----------> ... ----------> Device | Tx -> Rx Tx -> Rx Tx -> Rx | | | | USB Rx -> Tx |-----> Device ----------> Device Tx -> Rx The software running on the devices has been created such that all devices run the same code, independently of their position in the chain. This makes the process of adding and removing boards very simple. Besides that, devices of different devices can be connected in the same scan chain, as each device is aware of its own SRAM size and can react to packets that ask for commands that cannot be carried out for an specific amount of memory. Since the Regarding the communication direction, there are two distinct directions: Upstream From the device to the station. Downstream From a device to the next device. This distinction will be important specially in the device source code. Each device allocates a buffer for each direction as to be able to receive data from both directions at the same time. This should not happen in real life, but one of the priority of the station is to guarantee the integrity of the data sent or received from a device. For that, only one of the buffers should be used at real time. This separation also makes the code very simple as it is very simple to setup the interreptions for the communication protocol to store the data received directly in the buffer. Info As it was said before, this platform was created with the intention of gathering data from micro-controllers. Other types of devices can be connected to the station as long as they use the same packet based protocol. If the user wants to use another communication protocol, they will need to write their own Device Reader and register the new reader to an agent.","title":"Devices"},{"location":"devices/#devices","text":"This platform was created with the intention of collecting data from micro-controllers. The devices we mainly have access to are the STM32L152RE and the STM32L152RCT6 . One of the limitations we have to solve is to maximize the number of devices we can connect to a computer. The USB protocol has a limitations of 127 devices in total, including USB hubs. Moreover the process of connecting or removing devices from a station will be very time consuming. In order to have relevant statistically relevant analysis for SRAM-based PUF, we need a very large number of devices (hundreds at least) so we need to use another solution for this. To solve this problem, the devices are connected in scan chains , that is, the computer connects to a device (the start of the chain) and the next device is connected to the device before it. Doing this the only limitation is having a power supply strong enough to keep all the connected devices turned on. The devices communicate between them by using the USART, which is very simple to configure and provides speeds of communication fast enough for this application. In order to control the devices that are connected to a chain, the station keeps track of each device unique id and their position in the chain (referred in the code as pic ). STM32 devices contain 96 internal bits stored in the SRAM, that can be used as a unique identifier of the device. In the case of using other devices, the user would need to store a unique id for each device in memory to be able to identify them in the future. To keep track of the position, each packet has a field called pic, that gets incremented every time a packet travels downstream. (Oposite as how the Time To Live of an IPC packet gets decremented after each jump). The process of gathering the information of every devices is through the PING command, described in detail commands . We can see in the following diagram, an example of how the different devices create chains and how different chains can be connected to a computer. USB Rx -> Tx Rx -> Tx Rx -> Tx Computer ------> Device ----------> Device ----------> ... ----------> Device | Tx -> Rx Tx -> Rx Tx -> Rx | | | | USB Rx -> Tx |-----> Device ----------> Device Tx -> Rx The software running on the devices has been created such that all devices run the same code, independently of their position in the chain. This makes the process of adding and removing boards very simple. Besides that, devices of different devices can be connected in the same scan chain, as each device is aware of its own SRAM size and can react to packets that ask for commands that cannot be carried out for an specific amount of memory. Since the Regarding the communication direction, there are two distinct directions: Upstream From the device to the station. Downstream From a device to the next device. This distinction will be important specially in the device source code. Each device allocates a buffer for each direction as to be able to receive data from both directions at the same time. This should not happen in real life, but one of the priority of the station is to guarantee the integrity of the data sent or received from a device. For that, only one of the buffers should be used at real time. This separation also makes the code very simple as it is very simple to setup the interreptions for the communication protocol to store the data received directly in the buffer. Info As it was said before, this platform was created with the intention of gathering data from micro-controllers. Other types of devices can be connected to the station as long as they use the same packet based protocol. If the user wants to use another communication protocol, they will need to write their own Device Reader and register the new reader to an agent.","title":"Devices"},{"location":"logging/","text":"Logging The way commands are added to a dispatcher is through the add_command() method. Implementation example of add_command() def add_command ( self , handler , func , ** options ): \"Add a command to a dispatcher\" @self . agent . on ( handler , ** options ) def handler_fn ( * args , ** kwargs ): response = func ( * args , ** kwargs ) if response : message = { \"handler\" : kwargs [ \"body\" ], \"response\" : response } self . log . send ( msg = message ) The result of the command, if any, will be logged automatically to the logging channel specified in the Dispatcher. Function template whose result is logged. from sramplatform import Status , LogLevel def custom_fn ( * args , ** kwargs ): if True : return { 'status' : Status . OK } else : return { 'status' : Status . OK , 'level' : LogLevel . Info , 'msg' : \"Error message\" }","title":"Logging"},{"location":"logging/#logging","text":"The way commands are added to a dispatcher is through the add_command() method. Implementation example of add_command() def add_command ( self , handler , func , ** options ): \"Add a command to a dispatcher\" @self . agent . on ( handler , ** options ) def handler_fn ( * args , ** kwargs ): response = func ( * args , ** kwargs ) if response : message = { \"handler\" : kwargs [ \"body\" ], \"response\" : response } self . log . send ( msg = message ) The result of the command, if any, will be logged automatically to the logging channel specified in the Dispatcher. Function template whose result is logged. from sramplatform import Status , LogLevel def custom_fn ( * args , ** kwargs ): if True : return { 'status' : Status . OK } else : return { 'status' : Status . OK , 'level' : LogLevel . Info , 'msg' : \"Error message\" }","title":"Logging"},{"location":"platform_api/","text":"Command Bases: Enum Command the platform should execute. Source code in sramplatform/packet.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Command ( Enum ): \"\"\"Command the platform should execute.\"\"\" # Packet has been received correctly. ACK = 1 # Identify devices in a chain. PING = 2 # Read a region of memory. READ = 3 # Write to a region of memory. WRITE = 4 # Read the sensors of a device. SENSORS = 5 # Load custom code in a device. LOAD = 6 # Execute custom code on a device. EXEC = 7 # Receive results from executing code. RETR = 8 # Error when receiveng a packet. ERR = 255 Packet Packet used for the communication protocol. Attributes: Name Type Description command Command the platform should execute. pic Position In Chain of the device. options Metadata for the packet. uid UID of the device. data Actual data of the packet. bytes Bytes representation of the packet. checksum Optional [ int ] CRC of the packet for integrity. Source code in sramplatform/packet.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 class Packet : \"\"\"Packet used for the communication protocol. Attributes: command: Command the platform should execute. pic: Position In Chain of the device. options: Metadata for the packet. uid: UID of the device. data: Actual data of the packet. bytes: Bytes representation of the packet. checksum: CRC of the packet for integrity. \"\"\" def __init__ ( self , data_size : int ): self . data_size = data_size self . bytes_fmt = f \"<BBI25s { self . data_size } BH\" self . size = struct . calcsize ( self . bytes_fmt ) self . __command : int = Command . PING . value self . __pic : int = 0 self . __options : int = 0x0 self . __uid : str = \"0\" * 25 self . __data : List [ int ] = [ 0x7 ] * self . data_size self . checksum : Optional [ int ] = None self . __bytes : Optional [ bytes ] = None @classmethod def full_size ( cls , data_size : int ): packet = cls ( data_size ) return packet . size def __str__ ( self ): checksum = self . checksum or 0 return ( f \"<Packet { Command ( self . __command ) . name } \" f \" { self . __pic : 03d } : { format_uid ( self . __uid ) } \" f \"[0x { self . __options : 04X } ] \" f \"CRC(0x { checksum : 04X } )>\" ) def __repr__ ( self ): checksum = self . checksum or 0 return ( f \"<Packet { Command ( self . __command ) . name } \" f \" { self . __pic : 03d } : { format_uid ( self . __uid ) } \" f \"[0x { self . __options : 04X } ] \" f \"CRC(0x { checksum : 04X } ) \" f \" { bytes ( self . __data ) } >\" ) @property def command ( self ): \"Getter for command\" return self . __command @property def pic ( self ): \"Getter for pic\" return self . __pic @property def options ( self ): \"Getter for options\" return self . __options @property def uid ( self ): \"Getter for uid\" return self . __uid @property def data ( self ): \"Getter for data\" return self . __data def with_command ( self , command : Union [ int , Command ]): \"\"\"Set the command of the packet.\"\"\" if isinstance ( command , Command ): self . __command = command . value else : self . __command = command def with_pic ( self , pic : int ): \"\"\"Set the pic of the packet.\"\"\" self . __pic = pic def with_uid ( self , uid : str ): \"\"\"Set the uid of the packet.\"\"\" self . __uid = uid def with_options ( self , options : int ): \"\"\"Set the options of the packet.\"\"\" self . __options = options def with_data ( self , data : list [ int ]): \"\"\"Set the data of the packet.\"\"\" self . __data = data def with_checksum ( self , checksum : int ): \"\"\"Set the checksum of the packet.\"\"\" self . checksum = checksum def is_crafted ( self ) -> bool : \"\"\"Check if a packet is ready to be sent. Returns: True if bytes is not None. \"\"\" return self . __bytes is not None def craft ( self ): \"\"\"Craft a packet to send. Calculate the checksum if it hasn't been calculated yet, and create the bytes representation of the packet. \"\"\" if isinstance ( self . __uid , bytes ): uid = self . __uid else : uid = bytes ( self . __uid , \"utf-8\" ) if self . checksum is None : self . __bytes = struct . pack ( self . bytes_fmt , self . __command , self . __pic , self . __options , uid , * self . __data , 0 , ) self . checksum = crc16 ( self . __bytes ) self . __bytes = struct . pack ( self . bytes_fmt , self . __command , self . __pic , self . __options , uid , * self . __data , self . checksum , ) @classmethod def from_bytes ( cls , data_size : int , raw_data : bytes ): \"\"\" Create a packet from bytes. Args: raw_data: Bytes representing the packet. Raises: ValueError: If the length of ``raw_data`` does not match ``Packet.SIZE``. Returns: Packet created from the bytes. \"\"\" packet = cls ( data_size ) if len ( raw_data ) != packet . size : error = f \"Packet size { len ( raw_data ) } does not match { data_size } \" raise ValueError ( error ) ( command , pic , options , uid , * data , checksum , ) = struct . unpack ( packet . bytes_fmt , raw_data ) packet . with_command ( command ) packet . with_pic ( pic ) packet . with_uid ( uid ) packet . with_options ( options ) packet . with_data ( data ) packet . with_checksum ( checksum ) packet . craft () return packet def extract_sensors ( self ) -> Dict : \"\"\"Extract the values of the sensors from the data. The information of the sensors is stored in the following way: - `temp_110_cal`: Temperature calibration at 110 Celsius. - `temp_30_cal`: Temperature calibration at 30 Celsius. - `temp_raw`: Raw value of temperature. - `vdd_cal`: Calibration of VDD. - `vdd_raw`: Raw value of VDD. All the values are stored in 2 bytes. Returns: Dictionary containing ``temperature`` and ``vdd``. \"\"\" def calc_vdd ( vdd : int , vdd_cal : int ) -> float : \"\"\" Calculate the working voltage. Args: vdd: Raw value from the voltage sensor. vdd_cal: Calibration value. Returns: The working vdd in volts. \"\"\" return round (( 3300 * vdd_cal / vdd ) * 0.001 , 5 ) def calc_temp ( temp : int , cal_30 : int , cal_110 : int ) -> float : \"\"\" Calculate the working temperature. Args: temp: Raw value from the temperature sensor. cal_30: Calibration value at 30 degrees celsius. cal_110: Calibration value at 110 degrees celsius. Returns: The working temperature in degrees celsius. \"\"\" return round ((( 110 - 30 ) / ( cal_110 - cal_30 )) * ( temp - cal_30 ) + 30.0 , 5 ) data = struct . unpack ( \"<HHHHH\" , bytes ( self . __data [: 10 ])) return { \"temperature\" : calc_temp ( data [ 2 ], data [ 1 ], data [ 0 ]), \"voltage\" : calc_vdd ( data [ 4 ], data [ 3 ]), } def to_bytes ( self ) -> bytes : \"\"\"Return the bytes representation the packet. Returns: Bytes representation of the packet. Raises: ValueError if packet is not crafted. \"\"\" if self . __bytes is None : raise ValueError ( \"Packet is not crafted. Call craft() method first\" ) return self . __bytes def check_crc ( self ) -> bool : if self . __bytes is None : raise ValueError ( \"Packet is not crafted. Call craft() method first\" ) buffer = bytearray ( self . __bytes ) buffer [ - 1 ], buffer [ - 2 ] = 0 , 0 return crc16 ( buffer ) == self . checksum command () property Getter for command Source code in sramplatform/packet.py 116 117 118 119 @property def command ( self ): \"Getter for command\" return self . __command craft () Craft a packet to send. Calculate the checksum if it hasn't been calculated yet, and create the bytes representation of the packet. Source code in sramplatform/packet.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def craft ( self ): \"\"\"Craft a packet to send. Calculate the checksum if it hasn't been calculated yet, and create the bytes representation of the packet. \"\"\" if isinstance ( self . __uid , bytes ): uid = self . __uid else : uid = bytes ( self . __uid , \"utf-8\" ) if self . checksum is None : self . __bytes = struct . pack ( self . bytes_fmt , self . __command , self . __pic , self . __options , uid , * self . __data , 0 , ) self . checksum = crc16 ( self . __bytes ) self . __bytes = struct . pack ( self . bytes_fmt , self . __command , self . __pic , self . __options , uid , * self . __data , self . checksum , ) data () property Getter for data Source code in sramplatform/packet.py 136 137 138 139 @property def data ( self ): \"Getter for data\" return self . __data extract_sensors () Extract the values of the sensors from the data. The information of the sensors is stored in the following way: temp_110_cal : Temperature calibration at 110 Celsius. temp_30_cal : Temperature calibration at 30 Celsius. temp_raw : Raw value of temperature. vdd_cal : Calibration of VDD. vdd_raw : Raw value of VDD. All the values are stored in 2 bytes. Returns: Type Description Dict Dictionary containing temperature and vdd . Source code in sramplatform/packet.py 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 def extract_sensors ( self ) -> Dict : \"\"\"Extract the values of the sensors from the data. The information of the sensors is stored in the following way: - `temp_110_cal`: Temperature calibration at 110 Celsius. - `temp_30_cal`: Temperature calibration at 30 Celsius. - `temp_raw`: Raw value of temperature. - `vdd_cal`: Calibration of VDD. - `vdd_raw`: Raw value of VDD. All the values are stored in 2 bytes. Returns: Dictionary containing ``temperature`` and ``vdd``. \"\"\" def calc_vdd ( vdd : int , vdd_cal : int ) -> float : \"\"\" Calculate the working voltage. Args: vdd: Raw value from the voltage sensor. vdd_cal: Calibration value. Returns: The working vdd in volts. \"\"\" return round (( 3300 * vdd_cal / vdd ) * 0.001 , 5 ) def calc_temp ( temp : int , cal_30 : int , cal_110 : int ) -> float : \"\"\" Calculate the working temperature. Args: temp: Raw value from the temperature sensor. cal_30: Calibration value at 30 degrees celsius. cal_110: Calibration value at 110 degrees celsius. Returns: The working temperature in degrees celsius. \"\"\" return round ((( 110 - 30 ) / ( cal_110 - cal_30 )) * ( temp - cal_30 ) + 30.0 , 5 ) data = struct . unpack ( \"<HHHHH\" , bytes ( self . __data [: 10 ])) return { \"temperature\" : calc_temp ( data [ 2 ], data [ 1 ], data [ 0 ]), \"voltage\" : calc_vdd ( data [ 4 ], data [ 3 ]), } from_bytes ( data_size , raw_data ) classmethod Create a packet from bytes. Parameters: Name Type Description Default raw_data bytes Bytes representing the packet. required Raises: Type Description ValueError If the length of raw_data does not match Packet.SIZE . Returns: Type Description Packet created from the bytes. Source code in sramplatform/packet.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 @classmethod def from_bytes ( cls , data_size : int , raw_data : bytes ): \"\"\" Create a packet from bytes. Args: raw_data: Bytes representing the packet. Raises: ValueError: If the length of ``raw_data`` does not match ``Packet.SIZE``. Returns: Packet created from the bytes. \"\"\" packet = cls ( data_size ) if len ( raw_data ) != packet . size : error = f \"Packet size { len ( raw_data ) } does not match { data_size } \" raise ValueError ( error ) ( command , pic , options , uid , * data , checksum , ) = struct . unpack ( packet . bytes_fmt , raw_data ) packet . with_command ( command ) packet . with_pic ( pic ) packet . with_uid ( uid ) packet . with_options ( options ) packet . with_data ( data ) packet . with_checksum ( checksum ) packet . craft () return packet is_crafted () Check if a packet is ready to be sent. Returns: Type Description bool True if bytes is not None. Source code in sramplatform/packet.py 168 169 170 171 172 173 174 def is_crafted ( self ) -> bool : \"\"\"Check if a packet is ready to be sent. Returns: True if bytes is not None. \"\"\" return self . __bytes is not None options () property Getter for options Source code in sramplatform/packet.py 126 127 128 129 @property def options ( self ): \"Getter for options\" return self . __options pic () property Getter for pic Source code in sramplatform/packet.py 121 122 123 124 @property def pic ( self ): \"Getter for pic\" return self . __pic to_bytes () Return the bytes representation the packet. Returns: Type Description bytes Bytes representation of the packet. Source code in sramplatform/packet.py 295 296 297 298 299 300 301 302 303 304 305 306 def to_bytes ( self ) -> bytes : \"\"\"Return the bytes representation the packet. Returns: Bytes representation of the packet. Raises: ValueError if packet is not crafted. \"\"\" if self . __bytes is None : raise ValueError ( \"Packet is not crafted. Call craft() method first\" ) return self . __bytes uid () property Getter for uid Source code in sramplatform/packet.py 131 132 133 134 @property def uid ( self ): \"Getter for uid\" return self . __uid with_checksum ( checksum ) Set the checksum of the packet. Source code in sramplatform/packet.py 164 165 166 def with_checksum ( self , checksum : int ): \"\"\"Set the checksum of the packet.\"\"\" self . checksum = checksum with_command ( command ) Set the command of the packet. Source code in sramplatform/packet.py 141 142 143 144 145 146 def with_command ( self , command : Union [ int , Command ]): \"\"\"Set the command of the packet.\"\"\" if isinstance ( command , Command ): self . __command = command . value else : self . __command = command with_data ( data ) Set the data of the packet. Source code in sramplatform/packet.py 160 161 162 def with_data ( self , data : list [ int ]): \"\"\"Set the data of the packet.\"\"\" self . __data = data with_options ( options ) Set the options of the packet. Source code in sramplatform/packet.py 156 157 158 def with_options ( self , options : int ): \"\"\"Set the options of the packet.\"\"\" self . __options = options with_pic ( pic ) Set the pic of the packet. Source code in sramplatform/packet.py 148 149 150 def with_pic ( self , pic : int ): \"\"\"Set the pic of the packet.\"\"\" self . __pic = pic with_uid ( uid ) Set the uid of the packet. Source code in sramplatform/packet.py 152 153 154 def with_uid ( self , uid : str ): \"\"\"Set the uid of the packet.\"\"\" self . __uid = uid crc16 ( buffer ) Calculate the CRC16 from a byte buffer. Parameters: Name Type Description Default buffer bytes Buffer of bytes. required Returns: Type Description int The calculated CRC. Source code in sramplatform/packet.py 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 def crc16 ( buffer : bytes ) -> int : \"\"\"Calculate the CRC16 from a byte buffer. Args: buffer: Buffer of bytes. Returns: The calculated CRC. \"\"\" crc = 0 def crc16_byte ( crc , data ): \"\"\"Helper function to get a value from the CRC16_LUT\"\"\" return ( crc >> 8 ) ^ CRC16_LUT [( crc ^ data ) & 0xFF ] for byte in buffer : crc = crc16_byte ( crc , byte ) return crc format_uid ( uid ) Format a device UID. If the uid is bytes, remove the null terminator. Parameters: Name Type Description Default uid Union [ str , bytes ] UID of the device. required Returns: Type Description str Ther formmated UID as a string. Source code in sramplatform/packet.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def format_uid ( uid : Union [ str , bytes ]) -> str : \"\"\"Format a device UID. If the uid is bytes, remove the null terminator. Args: uid: UID of the device. Returns: Ther formmated UID as a string. \"\"\" if isinstance ( uid , str ): return uid return uid . decode ( \"ascii\" ) . split ( \" \\x00 \" )[ 0 ] offset_to_address ( offset , data_size , sram_start = 536870912 ) Convert an offset in memory to absolute memory address. Parameters: Name Type Description Default offset int Offset from the start of the SRAM. required sram_start int Byte representing the start of the SRAM. 0x20000000 by default. 536870912 Raises: Type Description ValueError If offset is negative. Returns: Type Description str Address formated as 0xXXXXXXXX. Source code in sramplatform/packet.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def offset_to_address ( offset : int , data_size : int , sram_start : int = 0x20000000 ) -> str : \"\"\"Convert an offset in memory to absolute memory address. Args: offset: Offset from the start of the SRAM. sram_start: Byte representing the start of the SRAM. 0x20000000 by default. Raises: ValueError: If offset is negative. Returns: Address formated as 0xXXXXXXXX. \"\"\" if offset < 0 : raise ValueError ( \"Offset cannot be negative\" ) return f \"0x { sram_start + ( offset * data_size ) : 08X } \" DBManager Class to manage the communication with the database. The default database is PostreSQL. However, another database can be used in place by configuring the DBManager. The manager is allowed to insert into the database any object as long as it has been registered by using TableBase . For more instructions on how to register objects to the database please see https://docs.sqlalchemy.org/en/14/orm/declarative_tables.html . Example from sramplatform.storage import DBManager, TableBase class Users(TableBase): tablename = \"User\" id = Column(Integer, primary_key=True) name = Column(String, nullable=False) manager = DBManager(url) Queries can be made by using the session attribute. Example manager.session.query(User).all Attributes: Name Type Description session Session to the DB Parameters: Name Type Description Default url Union [ str , DBParameters ] DBParameters instance or string containing the url to connect. required Source code in sramplatform/storage.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class DBManager : \"\"\"Class to manage the communication with the database. The default database is PostreSQL. However, another database can be used in place by configuring the DBManager. The manager is allowed to insert into the database any object as long as it has been registered by using ``TableBase``. For more instructions on how to register objects to the database please see `https://docs.sqlalchemy.org/en/14/orm/declarative_tables.html`. Example: >>> from sramplatform.storage import DBManager, TableBase >>> >>> class Users(TableBase): >>> __tablename__ = \"User\" >>> id = Column(Integer, primary_key=True) >>> name = Column(String, nullable=False) >>> >>> manager = DBManager(url) Queries can be made by using the session attribute. Example: >>> manager.session.query(User).all Attributes: session: Session to the DB Args: url: DBParameters instance or string containing the url to connect. \"\"\" def __init__ ( self , url : Union [ str , DBParameters ]): engine = create_engine ( str ( url )) Session = sessionmaker ( engine ) self . session = Session () TableBase . metadata . create_all ( engine ) DBParameters dataclass Class to manage database connection parameters. By default it is assumed that the database is PostgreSQL. For a list of supported engines, please see https://docs.sqlalchemy.org/en/14/core/engines.html . Attributes: Name Type Description user str Username to connect to the database. password str User password to connect to the database. dbname Optional [ str ] Name of the database to connect. engine Optional [ str ] Database to use. Defaults to 'postgresql'. host Optional [ str ] Hostname for the database. Defaults to 'localhost'. port Optional [ int ] Connection port for the database. Defaults to 5432. Source code in sramplatform/storage.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @dataclass class DBParameters : \"\"\"Class to manage database connection parameters. By default it is assumed that the database is PostgreSQL. For a list of supported engines, please see `https://docs.sqlalchemy.org/en/14/core/engines.html`. Attributes: user: Username to connect to the database. password: User password to connect to the database. dbname: Name of the database to connect. engine: Database to use. Defaults to 'postgresql'. host: Hostname for the database. Defaults to 'localhost'. port: Connection port for the database. Defaults to 5432. \"\"\" user : str password : str dbname : Optional [ str ] = None engine : Optional [ str ] = None host : Optional [ str ] = None port : Optional [ int ] = None def __post_init__ ( self ): if self . engine is None : self . engine = \"postgresql\" if self . host is None : self . host = \"localhost\" if self . port is None : self . port = 5432 def __str__ ( self ): return ( f \" { self . engine } ://\" f \" { self . user } : { self . password } \" f \"@ { self . host } : { self . port } / { self . dbname } \" ) Reader Interface of a device reader. The reader acts as a proxy between the station and the devices. Attributes: Name Type Description name Descriptive name of the reader. Source code in sramplatform/reader.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Reader : \"\"\"Interface of a device reader. The reader acts as a proxy between the station and the devices. Attributes: name: Descriptive name of the reader. \"\"\" def __init__ ( self , name : str ): self . name = name def send ( self , data : bytes ): raise NotImplementedError def receive ( self ): raise NotImplementedError LogLevelFilter Bases: logging . Filter https://stackoverflow.com/a/7447596/190597 (robert) Source code in sramplatform/logbook.py 87 88 89 90 91 92 93 94 class LogLevelFilter ( logging . Filter ): \"\"\"https://stackoverflow.com/a/7447596/190597 (robert)\"\"\" def __init__ ( self , level ): self . level = level def filter ( self , record ): return record . levelno < self . level MailHandler Bases: logging . StreamHandler Log handler for Email. Source code in sramplatform/logbook.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 class MailHandler ( logging . StreamHandler ): \"\"\"Log handler for Email.\"\"\" def __init__ ( self , email , oauth_path , recipients , subject ): super ( MailHandler , self ) . __init__ ( self ) self . mail = yagmail . SMTP ( email , oauth2_file = oauth_path ) if isinstance ( recipients , list ): self . recipients = recipients else : self . recipients = list ( recipients ) self . subject = subject def emit ( self , record ): msg = self . format ( record ) template = f \"\"\" { msg } \"\"\" self . mail . send ( to = self . recipients , subject = self . subject , contents = template ) RabbitMQHandler Bases: logging . StreamHandler Log handler for RabbitMQ. Source code in sramplatform/logbook.py 114 115 116 117 118 119 120 121 122 123 class RabbitMQHandler ( logging . StreamHandler ): \"\"\"Log handler for RabbitMQ.\"\"\" def __init__ ( self , url , name , exchange ): super ( RabbitMQHandler , self ) . __init__ ( self ) self . agent = Sender ( url , name , exchange ) def emit ( self , record ): msg = self . format ( record ) self . agent . send ( msg ) TelegramHandler Bases: logging . StreamHandler Log handler for Telegram. Source code in sramplatform/logbook.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class TelegramHandler ( logging . StreamHandler ): \"\"\"Log handler for Telegram.\"\"\" def __init__ ( self , token , chat_ids ): super ( TelegramHandler , self ) . __init__ ( self ) self . bot = TeleBot ( token ) if isinstance ( chat_ids , list ): self . chat_ids = chat_ids else : self . chat_ids = [ chat_ids ] def emit ( self , record ): msg = self . format ( record ) for chat in self . chat_ids : self . bot . send_message ( chat , msg ) create_handler ( name , conf ) Create a handler from a name and a dict. Parameters: Name Type Description Default name str Name of the handler to create. required conf Dict [ str , Any ] Dictionary containing the handler configuration. required Returns: Type Description HandlerType The configured handler. Source code in sramplatform/logbook.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 def create_handler ( name : str , conf : Dict [ str , Any ]) -> HandlerType : \"\"\"Create a handler from a name and a dict. Args: name: Name of the handler to create. conf: Dictionary containing the handler configuration. Returns: The configured handler. \"\"\" if name == \"TelegramHandler\" : return TelegramHandler ( conf [ \"token\" ], conf [ \"chat_ids\" ]) if name == \"RabbitMQHandler\" : return RabbitMQHandler ( conf [ \"url\" ], conf [ \"key\" ], conf [ \"exachange\" ]) if name == \"MailHandler\" : return MailHandler ( conf [ \"mail\" ], conf [ \"oauth\" ], conf [ \"recipients\" ], conf [ \"subject\" ] ) if name == \"FileHandler\" : return FileHandler ( conf [ \"path\" ]) if name == \"StreamHandler\" : return StreamHandler ( sys . stdout ) if name == \"RotatingFileHandler\" : return RotatingFileHandler ( conf [ \"path\" ], maxBytes = conf [ \"maxBytes\" ], backupCount = conf [ \"backupCount\" ] ) if name == \"TimedRotatingFileHandler\" : return TimedRotatingFileHandler ( conf [ \"path\" ], when = conf [ \"when\" ], backupCount = conf [ \"backupCount\" ], ) raise ValueError ( f \"Handler { name } is not available\" ) make_formatter ( conf , fmt_default , datefmt_default ) Create a Log formatter from a dict. Parameters: Name Type Description Default conf Dict [ str , str ] Dictionary containing format and datefmt required fmt_default str Default format to use if none specified. required datefmt_default str Default datefmt to use if none specified. required Source code in sramplatform/logbook.py 32 33 34 35 36 37 38 39 40 41 42 43 def make_formatter ( conf : Dict [ str , str ], fmt_default : str , datefmt_default : str ): \"\"\"Create a Log formatter from a dict. Args: conf: Dictionary containing format and datefmt fmt_default: Default format to use if none specified. datefmt_default: Default datefmt to use if none specified. \"\"\" return logging . Formatter ( conf . get ( \"format\" , fmt_default ), datefmt = conf . get ( \"datefmt\" , datefmt_default ), ) Dispatcher Class used to dispatch reader methods based on the commands received. Attributes: Name Type Description agent Fenneq agent to listen for commands. logger Logger used to log information. db_session Session to a DB to store data. Source code in sramplatform/platform.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class Dispatcher : \"\"\"Class used to dispatch reader methods based on the commands received. Attributes: agent: Fenneq agent to listen for commands. logger: Logger used to log information. db_session: Session to a DB to store data. \"\"\" def __init__ ( self , agent , logger , dbmanager , timeout ): self . agent = agent self . dbmanager = dbmanager self . logger = logger self . timeout = timeout def add_command ( self , handler , func , ** options ): \"\"\" \"\"\" @self . agent . on ( handler , ** options ) def handler_fn ( msg ): command = msg . body [ \"command\" ] self . logger . debug ( \"Handler %s called\" , command ) try : signal . signal ( signal . SIGALRM , timeout_handler ) signal . alarm ( self . timeout ) func ( msg . body , self . logger , self . dbmanager . session ) except TimeoutError : self . logger . critical ( \"Handler %s timeout\" , command ) except CommandError as err : self . logger . error ( \" %s \" , err ) except Exception as excep : self . logger . critical ( f \"Error while executing handler: { excep } \" ) else : self . logger . debug ( \"Handler %s executed correctly\" , command ) finally : signal . alarm ( 0 ) def run ( self ): \"\"\"Make the dispatcher listen for commands.\"\"\" self . logger . debug ( f \" { self . agent . name } listening on { self . agent . exchange } \" ) self . agent . run () run () Make the dispatcher listen for commands. Source code in sramplatform/platform.py 68 69 70 71 def run ( self ): \"\"\"Make the dispatcher listen for commands.\"\"\" self . logger . debug ( f \" { self . agent . name } listening on { self . agent . exchange } \" ) self . agent . run () from_config ( config_path , reader_cls ) Read a YAML config to generate the components for a Dispatcher. Parameters: Name Type Description Default config_path str Path to the YAML config. required reader_cls ReaderType Class to use to instanciate a Reader. required Returns: Type Description Tuple [ Agent , ReaderType , object ] A tuple containing the Agent, Reader and Logger Source code in sramplatform/platform.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def from_config ( config_path : str , reader_cls : ReaderType ) -> Tuple [ Agent , ReaderType , object ]: \"\"\"Read a YAML config to generate the components for a Dispatcher. Args: config_path: Path to the YAML config. reader_cls: Class to use to instanciate a Reader. Returns: A tuple containing the Agent, Reader and Logger \"\"\" with open ( config_path , \"r\" ) as f : config = yaml . load ( f , Loader = yaml . Loader ) agent = Agent ( ** config [ \"agent\" ]) reader = reader_cls ( ** config [ \"reader\" ]) root_logger = logging . getLogger ( agent . name ) root_logger . setLevel ( logging . DEBUG ) conf_logging = config [ \"logging\" ] fmt_default = conf_logging [ \"format\" ] datefmt_default = conf_logging [ \"datefmt\" ] for logger_conf in conf_logging . get ( \"loggers\" , []): for name , conf in logger_conf . items (): handler = create_handler ( name , conf ) level = logging . getLevelName ( conf . get ( \"level\" , logging . INFO )) handler . setLevel ( level ) filter_level = conf . get ( \"filter_level\" , None ) if filter_level : handler . addFilter ( LogLevelFilter ( logging . getLevelName ( filter_level )) ) custom_fmt = make_formatter ( conf , fmt_default , datefmt_default ) handler . setFormatter ( custom_fmt ) root_logger . addHandler ( handler ) return agent , reader , root_logger","title":"Platform API"},{"location":"platform_api/#sramplatform.packet.Command","text":"Bases: Enum Command the platform should execute. Source code in sramplatform/packet.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Command ( Enum ): \"\"\"Command the platform should execute.\"\"\" # Packet has been received correctly. ACK = 1 # Identify devices in a chain. PING = 2 # Read a region of memory. READ = 3 # Write to a region of memory. WRITE = 4 # Read the sensors of a device. SENSORS = 5 # Load custom code in a device. LOAD = 6 # Execute custom code on a device. EXEC = 7 # Receive results from executing code. RETR = 8 # Error when receiveng a packet. ERR = 255","title":"Command"},{"location":"platform_api/#sramplatform.packet.Packet","text":"Packet used for the communication protocol. Attributes: Name Type Description command Command the platform should execute. pic Position In Chain of the device. options Metadata for the packet. uid UID of the device. data Actual data of the packet. bytes Bytes representation of the packet. checksum Optional [ int ] CRC of the packet for integrity. Source code in sramplatform/packet.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 class Packet : \"\"\"Packet used for the communication protocol. Attributes: command: Command the platform should execute. pic: Position In Chain of the device. options: Metadata for the packet. uid: UID of the device. data: Actual data of the packet. bytes: Bytes representation of the packet. checksum: CRC of the packet for integrity. \"\"\" def __init__ ( self , data_size : int ): self . data_size = data_size self . bytes_fmt = f \"<BBI25s { self . data_size } BH\" self . size = struct . calcsize ( self . bytes_fmt ) self . __command : int = Command . PING . value self . __pic : int = 0 self . __options : int = 0x0 self . __uid : str = \"0\" * 25 self . __data : List [ int ] = [ 0x7 ] * self . data_size self . checksum : Optional [ int ] = None self . __bytes : Optional [ bytes ] = None @classmethod def full_size ( cls , data_size : int ): packet = cls ( data_size ) return packet . size def __str__ ( self ): checksum = self . checksum or 0 return ( f \"<Packet { Command ( self . __command ) . name } \" f \" { self . __pic : 03d } : { format_uid ( self . __uid ) } \" f \"[0x { self . __options : 04X } ] \" f \"CRC(0x { checksum : 04X } )>\" ) def __repr__ ( self ): checksum = self . checksum or 0 return ( f \"<Packet { Command ( self . __command ) . name } \" f \" { self . __pic : 03d } : { format_uid ( self . __uid ) } \" f \"[0x { self . __options : 04X } ] \" f \"CRC(0x { checksum : 04X } ) \" f \" { bytes ( self . __data ) } >\" ) @property def command ( self ): \"Getter for command\" return self . __command @property def pic ( self ): \"Getter for pic\" return self . __pic @property def options ( self ): \"Getter for options\" return self . __options @property def uid ( self ): \"Getter for uid\" return self . __uid @property def data ( self ): \"Getter for data\" return self . __data def with_command ( self , command : Union [ int , Command ]): \"\"\"Set the command of the packet.\"\"\" if isinstance ( command , Command ): self . __command = command . value else : self . __command = command def with_pic ( self , pic : int ): \"\"\"Set the pic of the packet.\"\"\" self . __pic = pic def with_uid ( self , uid : str ): \"\"\"Set the uid of the packet.\"\"\" self . __uid = uid def with_options ( self , options : int ): \"\"\"Set the options of the packet.\"\"\" self . __options = options def with_data ( self , data : list [ int ]): \"\"\"Set the data of the packet.\"\"\" self . __data = data def with_checksum ( self , checksum : int ): \"\"\"Set the checksum of the packet.\"\"\" self . checksum = checksum def is_crafted ( self ) -> bool : \"\"\"Check if a packet is ready to be sent. Returns: True if bytes is not None. \"\"\" return self . __bytes is not None def craft ( self ): \"\"\"Craft a packet to send. Calculate the checksum if it hasn't been calculated yet, and create the bytes representation of the packet. \"\"\" if isinstance ( self . __uid , bytes ): uid = self . __uid else : uid = bytes ( self . __uid , \"utf-8\" ) if self . checksum is None : self . __bytes = struct . pack ( self . bytes_fmt , self . __command , self . __pic , self . __options , uid , * self . __data , 0 , ) self . checksum = crc16 ( self . __bytes ) self . __bytes = struct . pack ( self . bytes_fmt , self . __command , self . __pic , self . __options , uid , * self . __data , self . checksum , ) @classmethod def from_bytes ( cls , data_size : int , raw_data : bytes ): \"\"\" Create a packet from bytes. Args: raw_data: Bytes representing the packet. Raises: ValueError: If the length of ``raw_data`` does not match ``Packet.SIZE``. Returns: Packet created from the bytes. \"\"\" packet = cls ( data_size ) if len ( raw_data ) != packet . size : error = f \"Packet size { len ( raw_data ) } does not match { data_size } \" raise ValueError ( error ) ( command , pic , options , uid , * data , checksum , ) = struct . unpack ( packet . bytes_fmt , raw_data ) packet . with_command ( command ) packet . with_pic ( pic ) packet . with_uid ( uid ) packet . with_options ( options ) packet . with_data ( data ) packet . with_checksum ( checksum ) packet . craft () return packet def extract_sensors ( self ) -> Dict : \"\"\"Extract the values of the sensors from the data. The information of the sensors is stored in the following way: - `temp_110_cal`: Temperature calibration at 110 Celsius. - `temp_30_cal`: Temperature calibration at 30 Celsius. - `temp_raw`: Raw value of temperature. - `vdd_cal`: Calibration of VDD. - `vdd_raw`: Raw value of VDD. All the values are stored in 2 bytes. Returns: Dictionary containing ``temperature`` and ``vdd``. \"\"\" def calc_vdd ( vdd : int , vdd_cal : int ) -> float : \"\"\" Calculate the working voltage. Args: vdd: Raw value from the voltage sensor. vdd_cal: Calibration value. Returns: The working vdd in volts. \"\"\" return round (( 3300 * vdd_cal / vdd ) * 0.001 , 5 ) def calc_temp ( temp : int , cal_30 : int , cal_110 : int ) -> float : \"\"\" Calculate the working temperature. Args: temp: Raw value from the temperature sensor. cal_30: Calibration value at 30 degrees celsius. cal_110: Calibration value at 110 degrees celsius. Returns: The working temperature in degrees celsius. \"\"\" return round ((( 110 - 30 ) / ( cal_110 - cal_30 )) * ( temp - cal_30 ) + 30.0 , 5 ) data = struct . unpack ( \"<HHHHH\" , bytes ( self . __data [: 10 ])) return { \"temperature\" : calc_temp ( data [ 2 ], data [ 1 ], data [ 0 ]), \"voltage\" : calc_vdd ( data [ 4 ], data [ 3 ]), } def to_bytes ( self ) -> bytes : \"\"\"Return the bytes representation the packet. Returns: Bytes representation of the packet. Raises: ValueError if packet is not crafted. \"\"\" if self . __bytes is None : raise ValueError ( \"Packet is not crafted. Call craft() method first\" ) return self . __bytes def check_crc ( self ) -> bool : if self . __bytes is None : raise ValueError ( \"Packet is not crafted. Call craft() method first\" ) buffer = bytearray ( self . __bytes ) buffer [ - 1 ], buffer [ - 2 ] = 0 , 0 return crc16 ( buffer ) == self . checksum","title":"Packet"},{"location":"platform_api/#sramplatform.packet.Packet.command","text":"Getter for command Source code in sramplatform/packet.py 116 117 118 119 @property def command ( self ): \"Getter for command\" return self . __command","title":"command()"},{"location":"platform_api/#sramplatform.packet.Packet.craft","text":"Craft a packet to send. Calculate the checksum if it hasn't been calculated yet, and create the bytes representation of the packet. Source code in sramplatform/packet.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 def craft ( self ): \"\"\"Craft a packet to send. Calculate the checksum if it hasn't been calculated yet, and create the bytes representation of the packet. \"\"\" if isinstance ( self . __uid , bytes ): uid = self . __uid else : uid = bytes ( self . __uid , \"utf-8\" ) if self . checksum is None : self . __bytes = struct . pack ( self . bytes_fmt , self . __command , self . __pic , self . __options , uid , * self . __data , 0 , ) self . checksum = crc16 ( self . __bytes ) self . __bytes = struct . pack ( self . bytes_fmt , self . __command , self . __pic , self . __options , uid , * self . __data , self . checksum , )","title":"craft()"},{"location":"platform_api/#sramplatform.packet.Packet.data","text":"Getter for data Source code in sramplatform/packet.py 136 137 138 139 @property def data ( self ): \"Getter for data\" return self . __data","title":"data()"},{"location":"platform_api/#sramplatform.packet.Packet.extract_sensors","text":"Extract the values of the sensors from the data. The information of the sensors is stored in the following way: temp_110_cal : Temperature calibration at 110 Celsius. temp_30_cal : Temperature calibration at 30 Celsius. temp_raw : Raw value of temperature. vdd_cal : Calibration of VDD. vdd_raw : Raw value of VDD. All the values are stored in 2 bytes. Returns: Type Description Dict Dictionary containing temperature and vdd . Source code in sramplatform/packet.py 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 def extract_sensors ( self ) -> Dict : \"\"\"Extract the values of the sensors from the data. The information of the sensors is stored in the following way: - `temp_110_cal`: Temperature calibration at 110 Celsius. - `temp_30_cal`: Temperature calibration at 30 Celsius. - `temp_raw`: Raw value of temperature. - `vdd_cal`: Calibration of VDD. - `vdd_raw`: Raw value of VDD. All the values are stored in 2 bytes. Returns: Dictionary containing ``temperature`` and ``vdd``. \"\"\" def calc_vdd ( vdd : int , vdd_cal : int ) -> float : \"\"\" Calculate the working voltage. Args: vdd: Raw value from the voltage sensor. vdd_cal: Calibration value. Returns: The working vdd in volts. \"\"\" return round (( 3300 * vdd_cal / vdd ) * 0.001 , 5 ) def calc_temp ( temp : int , cal_30 : int , cal_110 : int ) -> float : \"\"\" Calculate the working temperature. Args: temp: Raw value from the temperature sensor. cal_30: Calibration value at 30 degrees celsius. cal_110: Calibration value at 110 degrees celsius. Returns: The working temperature in degrees celsius. \"\"\" return round ((( 110 - 30 ) / ( cal_110 - cal_30 )) * ( temp - cal_30 ) + 30.0 , 5 ) data = struct . unpack ( \"<HHHHH\" , bytes ( self . __data [: 10 ])) return { \"temperature\" : calc_temp ( data [ 2 ], data [ 1 ], data [ 0 ]), \"voltage\" : calc_vdd ( data [ 4 ], data [ 3 ]), }","title":"extract_sensors()"},{"location":"platform_api/#sramplatform.packet.Packet.from_bytes","text":"Create a packet from bytes. Parameters: Name Type Description Default raw_data bytes Bytes representing the packet. required Raises: Type Description ValueError If the length of raw_data does not match Packet.SIZE . Returns: Type Description Packet created from the bytes. Source code in sramplatform/packet.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 @classmethod def from_bytes ( cls , data_size : int , raw_data : bytes ): \"\"\" Create a packet from bytes. Args: raw_data: Bytes representing the packet. Raises: ValueError: If the length of ``raw_data`` does not match ``Packet.SIZE``. Returns: Packet created from the bytes. \"\"\" packet = cls ( data_size ) if len ( raw_data ) != packet . size : error = f \"Packet size { len ( raw_data ) } does not match { data_size } \" raise ValueError ( error ) ( command , pic , options , uid , * data , checksum , ) = struct . unpack ( packet . bytes_fmt , raw_data ) packet . with_command ( command ) packet . with_pic ( pic ) packet . with_uid ( uid ) packet . with_options ( options ) packet . with_data ( data ) packet . with_checksum ( checksum ) packet . craft () return packet","title":"from_bytes()"},{"location":"platform_api/#sramplatform.packet.Packet.is_crafted","text":"Check if a packet is ready to be sent. Returns: Type Description bool True if bytes is not None. Source code in sramplatform/packet.py 168 169 170 171 172 173 174 def is_crafted ( self ) -> bool : \"\"\"Check if a packet is ready to be sent. Returns: True if bytes is not None. \"\"\" return self . __bytes is not None","title":"is_crafted()"},{"location":"platform_api/#sramplatform.packet.Packet.options","text":"Getter for options Source code in sramplatform/packet.py 126 127 128 129 @property def options ( self ): \"Getter for options\" return self . __options","title":"options()"},{"location":"platform_api/#sramplatform.packet.Packet.pic","text":"Getter for pic Source code in sramplatform/packet.py 121 122 123 124 @property def pic ( self ): \"Getter for pic\" return self . __pic","title":"pic()"},{"location":"platform_api/#sramplatform.packet.Packet.to_bytes","text":"Return the bytes representation the packet. Returns: Type Description bytes Bytes representation of the packet. Source code in sramplatform/packet.py 295 296 297 298 299 300 301 302 303 304 305 306 def to_bytes ( self ) -> bytes : \"\"\"Return the bytes representation the packet. Returns: Bytes representation of the packet. Raises: ValueError if packet is not crafted. \"\"\" if self . __bytes is None : raise ValueError ( \"Packet is not crafted. Call craft() method first\" ) return self . __bytes","title":"to_bytes()"},{"location":"platform_api/#sramplatform.packet.Packet.uid","text":"Getter for uid Source code in sramplatform/packet.py 131 132 133 134 @property def uid ( self ): \"Getter for uid\" return self . __uid","title":"uid()"},{"location":"platform_api/#sramplatform.packet.Packet.with_checksum","text":"Set the checksum of the packet. Source code in sramplatform/packet.py 164 165 166 def with_checksum ( self , checksum : int ): \"\"\"Set the checksum of the packet.\"\"\" self . checksum = checksum","title":"with_checksum()"},{"location":"platform_api/#sramplatform.packet.Packet.with_command","text":"Set the command of the packet. Source code in sramplatform/packet.py 141 142 143 144 145 146 def with_command ( self , command : Union [ int , Command ]): \"\"\"Set the command of the packet.\"\"\" if isinstance ( command , Command ): self . __command = command . value else : self . __command = command","title":"with_command()"},{"location":"platform_api/#sramplatform.packet.Packet.with_data","text":"Set the data of the packet. Source code in sramplatform/packet.py 160 161 162 def with_data ( self , data : list [ int ]): \"\"\"Set the data of the packet.\"\"\" self . __data = data","title":"with_data()"},{"location":"platform_api/#sramplatform.packet.Packet.with_options","text":"Set the options of the packet. Source code in sramplatform/packet.py 156 157 158 def with_options ( self , options : int ): \"\"\"Set the options of the packet.\"\"\" self . __options = options","title":"with_options()"},{"location":"platform_api/#sramplatform.packet.Packet.with_pic","text":"Set the pic of the packet. Source code in sramplatform/packet.py 148 149 150 def with_pic ( self , pic : int ): \"\"\"Set the pic of the packet.\"\"\" self . __pic = pic","title":"with_pic()"},{"location":"platform_api/#sramplatform.packet.Packet.with_uid","text":"Set the uid of the packet. Source code in sramplatform/packet.py 152 153 154 def with_uid ( self , uid : str ): \"\"\"Set the uid of the packet.\"\"\" self . __uid = uid","title":"with_uid()"},{"location":"platform_api/#sramplatform.packet.crc16","text":"Calculate the CRC16 from a byte buffer. Parameters: Name Type Description Default buffer bytes Buffer of bytes. required Returns: Type Description int The calculated CRC. Source code in sramplatform/packet.py 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 def crc16 ( buffer : bytes ) -> int : \"\"\"Calculate the CRC16 from a byte buffer. Args: buffer: Buffer of bytes. Returns: The calculated CRC. \"\"\" crc = 0 def crc16_byte ( crc , data ): \"\"\"Helper function to get a value from the CRC16_LUT\"\"\" return ( crc >> 8 ) ^ CRC16_LUT [( crc ^ data ) & 0xFF ] for byte in buffer : crc = crc16_byte ( crc , byte ) return crc","title":"crc16()"},{"location":"platform_api/#sramplatform.packet.format_uid","text":"Format a device UID. If the uid is bytes, remove the null terminator. Parameters: Name Type Description Default uid Union [ str , bytes ] UID of the device. required Returns: Type Description str Ther formmated UID as a string. Source code in sramplatform/packet.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def format_uid ( uid : Union [ str , bytes ]) -> str : \"\"\"Format a device UID. If the uid is bytes, remove the null terminator. Args: uid: UID of the device. Returns: Ther formmated UID as a string. \"\"\" if isinstance ( uid , str ): return uid return uid . decode ( \"ascii\" ) . split ( \" \\x00 \" )[ 0 ]","title":"format_uid()"},{"location":"platform_api/#sramplatform.packet.offset_to_address","text":"Convert an offset in memory to absolute memory address. Parameters: Name Type Description Default offset int Offset from the start of the SRAM. required sram_start int Byte representing the start of the SRAM. 0x20000000 by default. 536870912 Raises: Type Description ValueError If offset is negative. Returns: Type Description str Address formated as 0xXXXXXXXX. Source code in sramplatform/packet.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 def offset_to_address ( offset : int , data_size : int , sram_start : int = 0x20000000 ) -> str : \"\"\"Convert an offset in memory to absolute memory address. Args: offset: Offset from the start of the SRAM. sram_start: Byte representing the start of the SRAM. 0x20000000 by default. Raises: ValueError: If offset is negative. Returns: Address formated as 0xXXXXXXXX. \"\"\" if offset < 0 : raise ValueError ( \"Offset cannot be negative\" ) return f \"0x { sram_start + ( offset * data_size ) : 08X } \"","title":"offset_to_address()"},{"location":"platform_api/#sramplatform.storage.DBManager","text":"Class to manage the communication with the database. The default database is PostreSQL. However, another database can be used in place by configuring the DBManager. The manager is allowed to insert into the database any object as long as it has been registered by using TableBase . For more instructions on how to register objects to the database please see https://docs.sqlalchemy.org/en/14/orm/declarative_tables.html . Example from sramplatform.storage import DBManager, TableBase class Users(TableBase): tablename = \"User\" id = Column(Integer, primary_key=True) name = Column(String, nullable=False) manager = DBManager(url) Queries can be made by using the session attribute. Example manager.session.query(User).all Attributes: Name Type Description session Session to the DB Parameters: Name Type Description Default url Union [ str , DBParameters ] DBParameters instance or string containing the url to connect. required Source code in sramplatform/storage.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class DBManager : \"\"\"Class to manage the communication with the database. The default database is PostreSQL. However, another database can be used in place by configuring the DBManager. The manager is allowed to insert into the database any object as long as it has been registered by using ``TableBase``. For more instructions on how to register objects to the database please see `https://docs.sqlalchemy.org/en/14/orm/declarative_tables.html`. Example: >>> from sramplatform.storage import DBManager, TableBase >>> >>> class Users(TableBase): >>> __tablename__ = \"User\" >>> id = Column(Integer, primary_key=True) >>> name = Column(String, nullable=False) >>> >>> manager = DBManager(url) Queries can be made by using the session attribute. Example: >>> manager.session.query(User).all Attributes: session: Session to the DB Args: url: DBParameters instance or string containing the url to connect. \"\"\" def __init__ ( self , url : Union [ str , DBParameters ]): engine = create_engine ( str ( url )) Session = sessionmaker ( engine ) self . session = Session () TableBase . metadata . create_all ( engine )","title":"DBManager"},{"location":"platform_api/#sramplatform.storage.DBParameters","text":"Class to manage database connection parameters. By default it is assumed that the database is PostgreSQL. For a list of supported engines, please see https://docs.sqlalchemy.org/en/14/core/engines.html . Attributes: Name Type Description user str Username to connect to the database. password str User password to connect to the database. dbname Optional [ str ] Name of the database to connect. engine Optional [ str ] Database to use. Defaults to 'postgresql'. host Optional [ str ] Hostname for the database. Defaults to 'localhost'. port Optional [ int ] Connection port for the database. Defaults to 5432. Source code in sramplatform/storage.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @dataclass class DBParameters : \"\"\"Class to manage database connection parameters. By default it is assumed that the database is PostgreSQL. For a list of supported engines, please see `https://docs.sqlalchemy.org/en/14/core/engines.html`. Attributes: user: Username to connect to the database. password: User password to connect to the database. dbname: Name of the database to connect. engine: Database to use. Defaults to 'postgresql'. host: Hostname for the database. Defaults to 'localhost'. port: Connection port for the database. Defaults to 5432. \"\"\" user : str password : str dbname : Optional [ str ] = None engine : Optional [ str ] = None host : Optional [ str ] = None port : Optional [ int ] = None def __post_init__ ( self ): if self . engine is None : self . engine = \"postgresql\" if self . host is None : self . host = \"localhost\" if self . port is None : self . port = 5432 def __str__ ( self ): return ( f \" { self . engine } ://\" f \" { self . user } : { self . password } \" f \"@ { self . host } : { self . port } / { self . dbname } \" )","title":"DBParameters"},{"location":"platform_api/#sramplatform.reader.Reader","text":"Interface of a device reader. The reader acts as a proxy between the station and the devices. Attributes: Name Type Description name Descriptive name of the reader. Source code in sramplatform/reader.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Reader : \"\"\"Interface of a device reader. The reader acts as a proxy between the station and the devices. Attributes: name: Descriptive name of the reader. \"\"\" def __init__ ( self , name : str ): self . name = name def send ( self , data : bytes ): raise NotImplementedError def receive ( self ): raise NotImplementedError","title":"Reader"},{"location":"platform_api/#sramplatform.logbook.LogLevelFilter","text":"Bases: logging . Filter https://stackoverflow.com/a/7447596/190597 (robert) Source code in sramplatform/logbook.py 87 88 89 90 91 92 93 94 class LogLevelFilter ( logging . Filter ): \"\"\"https://stackoverflow.com/a/7447596/190597 (robert)\"\"\" def __init__ ( self , level ): self . level = level def filter ( self , record ): return record . levelno < self . level","title":"LogLevelFilter"},{"location":"platform_api/#sramplatform.logbook.MailHandler","text":"Bases: logging . StreamHandler Log handler for Email. Source code in sramplatform/logbook.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 class MailHandler ( logging . StreamHandler ): \"\"\"Log handler for Email.\"\"\" def __init__ ( self , email , oauth_path , recipients , subject ): super ( MailHandler , self ) . __init__ ( self ) self . mail = yagmail . SMTP ( email , oauth2_file = oauth_path ) if isinstance ( recipients , list ): self . recipients = recipients else : self . recipients = list ( recipients ) self . subject = subject def emit ( self , record ): msg = self . format ( record ) template = f \"\"\" { msg } \"\"\" self . mail . send ( to = self . recipients , subject = self . subject , contents = template )","title":"MailHandler"},{"location":"platform_api/#sramplatform.logbook.RabbitMQHandler","text":"Bases: logging . StreamHandler Log handler for RabbitMQ. Source code in sramplatform/logbook.py 114 115 116 117 118 119 120 121 122 123 class RabbitMQHandler ( logging . StreamHandler ): \"\"\"Log handler for RabbitMQ.\"\"\" def __init__ ( self , url , name , exchange ): super ( RabbitMQHandler , self ) . __init__ ( self ) self . agent = Sender ( url , name , exchange ) def emit ( self , record ): msg = self . format ( record ) self . agent . send ( msg )","title":"RabbitMQHandler"},{"location":"platform_api/#sramplatform.logbook.TelegramHandler","text":"Bases: logging . StreamHandler Log handler for Telegram. Source code in sramplatform/logbook.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class TelegramHandler ( logging . StreamHandler ): \"\"\"Log handler for Telegram.\"\"\" def __init__ ( self , token , chat_ids ): super ( TelegramHandler , self ) . __init__ ( self ) self . bot = TeleBot ( token ) if isinstance ( chat_ids , list ): self . chat_ids = chat_ids else : self . chat_ids = [ chat_ids ] def emit ( self , record ): msg = self . format ( record ) for chat in self . chat_ids : self . bot . send_message ( chat , msg )","title":"TelegramHandler"},{"location":"platform_api/#sramplatform.logbook.create_handler","text":"Create a handler from a name and a dict. Parameters: Name Type Description Default name str Name of the handler to create. required conf Dict [ str , Any ] Dictionary containing the handler configuration. required Returns: Type Description HandlerType The configured handler. Source code in sramplatform/logbook.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 def create_handler ( name : str , conf : Dict [ str , Any ]) -> HandlerType : \"\"\"Create a handler from a name and a dict. Args: name: Name of the handler to create. conf: Dictionary containing the handler configuration. Returns: The configured handler. \"\"\" if name == \"TelegramHandler\" : return TelegramHandler ( conf [ \"token\" ], conf [ \"chat_ids\" ]) if name == \"RabbitMQHandler\" : return RabbitMQHandler ( conf [ \"url\" ], conf [ \"key\" ], conf [ \"exachange\" ]) if name == \"MailHandler\" : return MailHandler ( conf [ \"mail\" ], conf [ \"oauth\" ], conf [ \"recipients\" ], conf [ \"subject\" ] ) if name == \"FileHandler\" : return FileHandler ( conf [ \"path\" ]) if name == \"StreamHandler\" : return StreamHandler ( sys . stdout ) if name == \"RotatingFileHandler\" : return RotatingFileHandler ( conf [ \"path\" ], maxBytes = conf [ \"maxBytes\" ], backupCount = conf [ \"backupCount\" ] ) if name == \"TimedRotatingFileHandler\" : return TimedRotatingFileHandler ( conf [ \"path\" ], when = conf [ \"when\" ], backupCount = conf [ \"backupCount\" ], ) raise ValueError ( f \"Handler { name } is not available\" )","title":"create_handler()"},{"location":"platform_api/#sramplatform.logbook.make_formatter","text":"Create a Log formatter from a dict. Parameters: Name Type Description Default conf Dict [ str , str ] Dictionary containing format and datefmt required fmt_default str Default format to use if none specified. required datefmt_default str Default datefmt to use if none specified. required Source code in sramplatform/logbook.py 32 33 34 35 36 37 38 39 40 41 42 43 def make_formatter ( conf : Dict [ str , str ], fmt_default : str , datefmt_default : str ): \"\"\"Create a Log formatter from a dict. Args: conf: Dictionary containing format and datefmt fmt_default: Default format to use if none specified. datefmt_default: Default datefmt to use if none specified. \"\"\" return logging . Formatter ( conf . get ( \"format\" , fmt_default ), datefmt = conf . get ( \"datefmt\" , datefmt_default ), )","title":"make_formatter()"},{"location":"platform_api/#sramplatform.platform.Dispatcher","text":"Class used to dispatch reader methods based on the commands received. Attributes: Name Type Description agent Fenneq agent to listen for commands. logger Logger used to log information. db_session Session to a DB to store data. Source code in sramplatform/platform.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class Dispatcher : \"\"\"Class used to dispatch reader methods based on the commands received. Attributes: agent: Fenneq agent to listen for commands. logger: Logger used to log information. db_session: Session to a DB to store data. \"\"\" def __init__ ( self , agent , logger , dbmanager , timeout ): self . agent = agent self . dbmanager = dbmanager self . logger = logger self . timeout = timeout def add_command ( self , handler , func , ** options ): \"\"\" \"\"\" @self . agent . on ( handler , ** options ) def handler_fn ( msg ): command = msg . body [ \"command\" ] self . logger . debug ( \"Handler %s called\" , command ) try : signal . signal ( signal . SIGALRM , timeout_handler ) signal . alarm ( self . timeout ) func ( msg . body , self . logger , self . dbmanager . session ) except TimeoutError : self . logger . critical ( \"Handler %s timeout\" , command ) except CommandError as err : self . logger . error ( \" %s \" , err ) except Exception as excep : self . logger . critical ( f \"Error while executing handler: { excep } \" ) else : self . logger . debug ( \"Handler %s executed correctly\" , command ) finally : signal . alarm ( 0 ) def run ( self ): \"\"\"Make the dispatcher listen for commands.\"\"\" self . logger . debug ( f \" { self . agent . name } listening on { self . agent . exchange } \" ) self . agent . run ()","title":"Dispatcher"},{"location":"platform_api/#sramplatform.platform.Dispatcher.run","text":"Make the dispatcher listen for commands. Source code in sramplatform/platform.py 68 69 70 71 def run ( self ): \"\"\"Make the dispatcher listen for commands.\"\"\" self . logger . debug ( f \" { self . agent . name } listening on { self . agent . exchange } \" ) self . agent . run ()","title":"run()"},{"location":"platform_api/#sramplatform.platform.from_config","text":"Read a YAML config to generate the components for a Dispatcher. Parameters: Name Type Description Default config_path str Path to the YAML config. required reader_cls ReaderType Class to use to instanciate a Reader. required Returns: Type Description Tuple [ Agent , ReaderType , object ] A tuple containing the Agent, Reader and Logger Source code in sramplatform/platform.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def from_config ( config_path : str , reader_cls : ReaderType ) -> Tuple [ Agent , ReaderType , object ]: \"\"\"Read a YAML config to generate the components for a Dispatcher. Args: config_path: Path to the YAML config. reader_cls: Class to use to instanciate a Reader. Returns: A tuple containing the Agent, Reader and Logger \"\"\" with open ( config_path , \"r\" ) as f : config = yaml . load ( f , Loader = yaml . Loader ) agent = Agent ( ** config [ \"agent\" ]) reader = reader_cls ( ** config [ \"reader\" ]) root_logger = logging . getLogger ( agent . name ) root_logger . setLevel ( logging . DEBUG ) conf_logging = config [ \"logging\" ] fmt_default = conf_logging [ \"format\" ] datefmt_default = conf_logging [ \"datefmt\" ] for logger_conf in conf_logging . get ( \"loggers\" , []): for name , conf in logger_conf . items (): handler = create_handler ( name , conf ) level = logging . getLevelName ( conf . get ( \"level\" , logging . INFO )) handler . setLevel ( level ) filter_level = conf . get ( \"filter_level\" , None ) if filter_level : handler . addFilter ( LogLevelFilter ( logging . getLevelName ( filter_level )) ) custom_fmt = make_formatter ( conf , fmt_default , datefmt_default ) handler . setFormatter ( custom_fmt ) root_logger . addHandler ( handler ) return agent , reader , root_logger","title":"from_config()"},{"location":"starting/","text":"Dependencies The platform uses RabbitMQ as the message broker and PostgreSQL as the default database. It is recommended to install Docker to use these tools. Python dependencies It is recomended, but not mandatory, to create a virtual environment to install the requirements. The following code describes the process of creating a virtual env and installing the dependencies. Using pip $ python3 -m venv /path/to/virtual_env $ source /path/to/virtual_env/bin/activate $ pip install -r requirements.txt $ deactivate # To exit the virtual environment Using poetry $ cd /path/to/SRAMPlatform $ poetry install To connect and handle the connection to RabbitMQ, the library Fenneq is needed. It can be installed with the following commands. Installing fenneq $ git clone https://github.com/servinagrero/fenneq.git && cd fenneq $ poetry install # or pip install","title":"Getting started"},{"location":"starting/#dependencies","text":"The platform uses RabbitMQ as the message broker and PostgreSQL as the default database. It is recommended to install Docker to use these tools.","title":"Dependencies"},{"location":"starting/#python-dependencies","text":"It is recomended, but not mandatory, to create a virtual environment to install the requirements. The following code describes the process of creating a virtual env and installing the dependencies. Using pip $ python3 -m venv /path/to/virtual_env $ source /path/to/virtual_env/bin/activate $ pip install -r requirements.txt $ deactivate # To exit the virtual environment Using poetry $ cd /path/to/SRAMPlatform $ poetry install To connect and handle the connection to RabbitMQ, the library Fenneq is needed. It can be installed with the following commands. Installing fenneq $ git clone https://github.com/servinagrero/fenneq.git && cd fenneq $ poetry install # or pip install","title":"Python dependencies"},{"location":"tima/","text":"TIMA SRAM Platform This section contains information about the SRAM platform that has been deployed and it's currently working at the TIMA Laboratory in Grenoble, France. The platform is composed of 84 ST nucleo boards and 45 ST discovery boards, composing a total of 129 devices. SRAM Platform using STM32 devices at TIMA Laboratory Data availability The data gathered in this station is publicly available online. To request available data, simply click on the following button to be directed to the website. There, you should provide for contact information and you will be able to filter the data. If the data requested is too large, it will be compressed in a zip file before. Request data Documentation structure The following sections explain all the implementation details of this instance. The code reference for this instance can be found under the src folder inside the project. The instance source code documentation can be accesed directly here while the documentation of the source code of the devices used can be found here","title":"Information"},{"location":"tima/#tima-sram-platform","text":"This section contains information about the SRAM platform that has been deployed and it's currently working at the TIMA Laboratory in Grenoble, France. The platform is composed of 84 ST nucleo boards and 45 ST discovery boards, composing a total of 129 devices. SRAM Platform using STM32 devices at TIMA Laboratory","title":"TIMA SRAM Platform"},{"location":"tima/#data-availability","text":"The data gathered in this station is publicly available online. To request available data, simply click on the following button to be directed to the website. There, you should provide for contact information and you will be able to filter the data. If the data requested is too large, it will be compressed in a zip file before. Request data","title":"Data availability"},{"location":"tima/#documentation-structure","text":"The following sections explain all the implementation details of this instance. The code reference for this instance can be found under the src folder inside the project. The instance source code documentation can be accesed directly here while the documentation of the source code of the devices used can be found here","title":"Documentation structure"},{"location":"tima_api/","text":"Device dataclass Class to represent a device. Source code in src/stm32reader.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @dataclass class Device : \"\"\"Class to represent a device.\"\"\" #: Universal ID of the device uid : str #: Position In Chain of the device. pic : int #: Size, in bytes, of the device's SRAM. sram_size : int def __eq__ ( self , other ): return self . uid == other . uid and self . pic == other . pic def __hash__ ( self ): return hash (( \"uid\" , self . uid , \"pic\" , self . pic )) def __str__ ( self ): return f \" { self . pic : 03d } : { format_uid ( self . uid ) } \" def __repr__ ( self ): return f \"<Device { self . pic : 03d } : { format_uid ( self . uid ) } 0x { self . sram_size : 08X } >\" STM32Reader Bases: Reader Reader implementation for STM32 boards. The functionaly of the reader is implemented in the methods called handle_{command} . Attributes: Name Type Description name Descriptive name of the Reader. devices List [ Device ] List of managed devices. port State of the devices and the serial port. Source code in src/stm32reader.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 class STM32Reader ( Reader ): \"\"\"Reader implementation for STM32 boards. The functionaly of the reader is implemented in the methods called `handle_{command}`. Attributes: name: Descriptive name of the Reader. devices: List of managed devices. port: State of the devices and the serial port. \"\"\" def __init__ ( self , board_type : str , port : str , baudrate : int , data_size : int ): super ( STM32Reader , self ) . __init__ ( board_type ) self . devices : List [ Device ] = [] self . name = board_type self . data_size = data_size port_path = Path ( port ) if not port_path . exists (): print ( f \"Port { port_path } does not exist\" ) sys . exit ( 1 ) ser = Serial ( port_path . as_posix (), baudrate , timeout = None ) self . port = { \"state\" : \"ON\" , \"serial\" : ser , \"path\" : port_path } def send ( self , data : bytes ): \"\"\"Transmit data through the serial port. Args: data: Bytes to sent. \"\"\" ser = self . port [ \"serial\" ] ser . flushInput () ser . write ( data ) ser . flushOutput () def receive ( self , timeout : float = 0.2 , tries = 50 ) -> List [ Packet ]: \"\"\"Received data from the serial port. Args: timeout: Time to wait until start receiving information. Returns: List of packets received. \"\"\" packet_size = Packet . full_size ( self . data_size ) ser = self . port [ \"serial\" ] ser . flushInput () packets = [] msg = b \"\" time . sleep ( timeout ) checks = deque ( maxlen = tries // 2 ) for _ in range ( tries ): checks . appendleft ( ser . in_waiting ) while ser . in_waiting : while len ( msg ) < packet_size : msg += ser . read () packets . append ( Packet . from_bytes ( self . data_size , msg )) msg = b \"\" if all ( num == 0 for num in checks ) and packets : return packets time . sleep ( 0.05 ) return packets def handle_status ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Show the status of the reader. Args: props: Dict[str, Any] from the dispatcher logger: Logger instance to log data. db_session: DBManager instance to query and insert data. Returns: Status of the operation \"\"\" logger . results ( json . dumps ( { \"state\" : self . port [ \"state\" ], \"devices\" : [ d . __dict__ for d in self . devices ], } ) ) def handle_power_off ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Power off the serial port. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" try : p = run ([ \"ykushcmd\" , \"-d\" , \"a\" ]) if p . returncode == 0 : self . port [ \"state\" ] = \"OFF\" logger . info ( \"Port powered off\" ) else : logger . warning ( \"Could not power off port\" ) raise CommandError except Exception as excep : raise CommandError ( f \"Problem powering off port { self . port [ 'path' ] } : { excep } \" ) from excep def handle_power_on ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Power on the serial port. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" try : p = run ([ \"ykushcmd\" , \"-u\" , \"a\" ]) if p . returncode == 0 : self . port [ \"state\" ] = \"ON\" logger . info ( \"Port powered on\" ) else : logger . warning ( \"Could not power on port\" ) raise CommandError except Exception as excep : raise CommandError ( f \"Problem powering on port { self . port [ 'path' ] } : { excep } \" ) from excep def handle_ping ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Register the devices connected to the reader. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" status_correct : Optional [ bool ] = None prev_devices = self . devices packet = Packet ( self . data_size ) packet . with_command ( Command . PING ) packet . craft () self . send ( packet . to_bytes ()) packets = self . receive () if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Please turn on the serial port first\" ) if prev_devices and not packets : raise CommandError ( \"There were devices connected but now no devices could be identified\" ) if not packets : raise CommandError ( \"No devices could be identified\" ) devices : List [ Device ] = [] for packet in packets : if not packet . check_crc (): logger . warning ( f \"Packet { packet !s} is corrupted\" ) status_correct = False else : devices . append ( Device ( format_uid ( packet . uid ), packet . pic , packet . options ) ) self . devices = devices if status_correct is None : logger . results ( json . dumps ([ d . __dict__ for d in self . devices ])) def handle_sensors ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Register the devices connected to the reader. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) for dev in self . devices : packet = Packet ( self . data_size ) packet . with_command ( Command . SENSORS ) packet . with_uid ( dev . uid ) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : logger . error ( f \"Problem reading sensors for device { dev } \" ) continue if not packet . check_crc () or packet . command == Command . ERR : logger . warning ( f \"Packet { packet !s} for device { dev } is corrupted\" ) continue sensors_data = res . extract_sensors () logger . results ( json . dumps ( { \"device\" : { \"uid\" : dev . uid , \"pic\" : dev . pic }, \"temperature\" : sensors_data [ \"temperature\" ], \"voltage\" : sensors_data [ \"voltage\" ], } ) ) db_session . add ( Sensor ( uid = format_uid ( res . uid ), board_type = self . name , temperature = sensors_data [ \"temperature\" ], voltage = sensors_data [ \"voltage\" ], ) ) db_session . commit () def handle_read ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) # Only store the day the read is done current_day = datetime . now () current_day = current_day . replace ( hour = 12 , minute = 0 , second = 0 ) for dev in self . devices : for offset in range ( dev . sram_size // self . data_size ): address = offset_to_address ( self . data_size , offset ) packet = Packet ( self . data_size ) packet . with_command ( Command . READ ) packet . with_uid ( dev . uid ) packet . with_options ( offset ) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : logger . error ( f \"Problem reading memory of device { dev } at offset { offset } \" ) continue if not packet . check_crc () or packet . command == Command . ERR : logger . warning ( f \"Packet { packet !s} is corrupted\" ) continue logger . debug ( f \"Read memory of { dev } at offset { offset } \" ) db_session . add ( Sample ( board_type = self . name , uid = format_uid ( res . uid ), pic = dev . pic , address = address , data = \",\" . join ([ str ( d ) for d in res . data ]), created_at = current_day , ) ) db_session . commit () logger . info ( f \"Finished reading memory of { dev } \" ) def handle_write ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) offset = props [ \"offset\" ] dev_uid = props [ \"device\" ] dev = next ( filter ( lambda d : d . uid == dev_uid , self . devices ), None ) if not dev : raise CommandError ( f \"Device { dev_uid } is not managed\" ) max_offset = dev . sram_size // self . data_size if offset < 0 or offset > max_offset : raise CommandError ( f \"Offset { offset } for device { dev } must be in range [0, { max_offset } ]\" ) packet = Packet ( self . data_size ) packet . with_command ( Command . WRITE ) packet . with_uid ( dev . uid ) packet . with_options ( offset ) packet . with_data ([ int ( b ) for b in props [ \"data\" ]]) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : raise CommandError ( f \"Problem writing to memory of device { dev } at offset { offset } \" ) if not res . check_crc () or res . command == Command . ERR : raise CommandError ( f \"Packet { packet !s} is corrupted\" ) logger . info ( \"Data written correctly\" ) def handle_write_invert ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" We assume that a reader handles only one type of device, So all devices *should* have the same memory regions. Get first all different regions and later check that a device has at least one sample of all of them. \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) device_list = list ( self . devices ) for dev in device_list [: len ( self . devices ) // 2 ]: num_addresses = dev . sram_size // self . data_size samples = ( db_session . query ( Sample ) . filter ( Sample . uid == dev . uid ) . order_by ( Sample . address . asc (), Sample . created_at . asc ()) . limit ( num_addresses ) . all () ) if not samples : logger . warning ( f \"At least one full memory sample has to be read from device { dev } \" ) continue if len ( samples ) != num_addresses : logger . warning ( f \"The memory sample for device { dev } is not complete\" ) continue end_offset = ( num_addresses ) - READ_ONLY_REGIONS for offset in range ( READ_ONLY_REGIONS , end_offset ): sample = samples [ offset ] packet = Packet ( self . data_size ) packet . with_command ( Command . WRITE ) packet . with_uid ( dev . uid ) packet . with_options ( offset ) packet . with_data ([ 0xFF ^ int ( d ) for d in sample . data . split ( \",\" )]) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : logger . error ( f \"Problem writing inverted values of device { dev } at offset { offset } \" ) continue if not res . check_crc () or res . command == Command . ERR : logger . warning ( f \"Packet { packet !s} is corrupted\" ) continue logger . debug ( f \"Wrote inverted values of device { dev } at offset { offset } \" ) logger . info ( f \"Finished inverting memory of device { dev } \" ) def handle_load ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) dev_uid = props [ \"device\" ] dev = next ( filter ( lambda d : d . uid == dev_uid , self . devices ), None ) if not dev : raise CommandError ( f \"Device { dev_uid } is not managed\" ) source = props [ \"source\" ] len_code = len ( source ) data_buf = [ ord ( c ) for c in source ] + [ ord ( \" \\x00 \" )] * ( self . data_size - len_code ) packet = Packet ( self . data_size ) packet . with_command ( Command . LOAD ) packet . with_uid ( dev_uid ) packet . with_data ( data_buf ) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : raise CommandError ( f \"Problem loading code for device { dev } \" ) if not res . check_crc () or res . command == Command . ERR : raise CommandError ( f \"Packet { packet !s} is corrupted\" ) logger . info ( f \"Code loaded on device { dev } correctly\" ) def handle_exec ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) dev_uid = props [ \"device\" ] dev = next ( filter ( lambda d : d . uid == dev_uid , self . devices ), None ) if not dev : raise CommandError ( f \"Device { dev_uid } is not managed\" ) packet = Packet ( self . data_size ) packet . with_command ( Command . EXEC ) packet . with_uid ( dev_uid ) packet . with_options ( int ( props . get ( \"reset\" , 0 ))) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : raise CommandError ( f \"Problem executing code on device { dev } \" ) if not res . check_crc () or res . command == Command . ERR : raise CommandError ( f \"Packet { packet !s} is corrupted\" ) if res . options != 0 : raise CommandError ( f \"Code on device { dev } executed with error code { res . options } \" ) logger . info ( f \"Code on device { dev } executed correctly\" ) def handle_retr ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) dev_uid = props [ \"device\" ] dev = next ( filter ( lambda d : d . uid == dev_uid , self . devices ), None ) if not dev : raise CommandError ( f \"Device { dev_uid } is not managed\" ) packet = Packet ( self . data_size ) packet . with_command ( Command . RETR ) packet . with_uid ( dev . uid ) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : raise CommandError ( f \"Problem retrieving results from device { dev } \" ) if not res . check_crc () or res . command == Command . ERR : raise CommandError ( f \"Packet { packet !s} is corrupted\" ) numbers = struct . unpack ( f \"< { self . data_size // 4 } i\" , bytes ( res . data )) numbers_str = map ( str , numbers ) numbers_str = map ( lambda n : n . replace ( \"10\" , \" \\n \" ) . replace ( \"32\" , \" \" ), numbers_str ) logger . info ( f \"Results retrieved correctly from device { dev } \" ) logger . results ( json . dumps ( { \"raw_bytes\" : res . data , \"int\" : numbers , \"string\" : \"\" . join ( numbers_str ), } ) ) handle_ping ( props , logger , db_session ) Register the devices connected to the reader. Parameters: Name Type Description Default props Dict [ str , Any ] Dictionary containing the message from the dispatcher. required Returns: Type Description Dictionary with the status of the operation and metadata if needed. Source code in src/stm32reader.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 def handle_ping ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Register the devices connected to the reader. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" status_correct : Optional [ bool ] = None prev_devices = self . devices packet = Packet ( self . data_size ) packet . with_command ( Command . PING ) packet . craft () self . send ( packet . to_bytes ()) packets = self . receive () if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Please turn on the serial port first\" ) if prev_devices and not packets : raise CommandError ( \"There were devices connected but now no devices could be identified\" ) if not packets : raise CommandError ( \"No devices could be identified\" ) devices : List [ Device ] = [] for packet in packets : if not packet . check_crc (): logger . warning ( f \"Packet { packet !s} is corrupted\" ) status_correct = False else : devices . append ( Device ( format_uid ( packet . uid ), packet . pic , packet . options ) ) self . devices = devices if status_correct is None : logger . results ( json . dumps ([ d . __dict__ for d in self . devices ])) handle_power_off ( props , logger , db_session ) Power off the serial port. Parameters: Name Type Description Default props Dict [ str , Any ] Dictionary containing the message from the dispatcher. required Returns: Type Description Dictionary with the status of the operation and metadata if needed. Source code in src/stm32reader.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def handle_power_off ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Power off the serial port. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" try : p = run ([ \"ykushcmd\" , \"-d\" , \"a\" ]) if p . returncode == 0 : self . port [ \"state\" ] = \"OFF\" logger . info ( \"Port powered off\" ) else : logger . warning ( \"Could not power off port\" ) raise CommandError except Exception as excep : raise CommandError ( f \"Problem powering off port { self . port [ 'path' ] } : { excep } \" ) from excep handle_power_on ( props , logger , db_session ) Power on the serial port. Parameters: Name Type Description Default props Dict [ str , Any ] Dictionary containing the message from the dispatcher. required Returns: Type Description Dictionary with the status of the operation and metadata if needed. Source code in src/stm32reader.py 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def handle_power_on ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Power on the serial port. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" try : p = run ([ \"ykushcmd\" , \"-u\" , \"a\" ]) if p . returncode == 0 : self . port [ \"state\" ] = \"ON\" logger . info ( \"Port powered on\" ) else : logger . warning ( \"Could not power on port\" ) raise CommandError except Exception as excep : raise CommandError ( f \"Problem powering on port { self . port [ 'path' ] } : { excep } \" ) from excep handle_sensors ( props , logger , db_session ) Register the devices connected to the reader. Parameters: Name Type Description Default props Dict [ str , Any ] Dictionary containing the message from the dispatcher. required Returns: Type Description Dictionary with the status of the operation and metadata if needed. Source code in src/stm32reader.py 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 def handle_sensors ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Register the devices connected to the reader. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) for dev in self . devices : packet = Packet ( self . data_size ) packet . with_command ( Command . SENSORS ) packet . with_uid ( dev . uid ) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : logger . error ( f \"Problem reading sensors for device { dev } \" ) continue if not packet . check_crc () or packet . command == Command . ERR : logger . warning ( f \"Packet { packet !s} for device { dev } is corrupted\" ) continue sensors_data = res . extract_sensors () logger . results ( json . dumps ( { \"device\" : { \"uid\" : dev . uid , \"pic\" : dev . pic }, \"temperature\" : sensors_data [ \"temperature\" ], \"voltage\" : sensors_data [ \"voltage\" ], } ) ) db_session . add ( Sensor ( uid = format_uid ( res . uid ), board_type = self . name , temperature = sensors_data [ \"temperature\" ], voltage = sensors_data [ \"voltage\" ], ) ) db_session . commit () handle_status ( props , logger , db_session ) Show the status of the reader. Parameters: Name Type Description Default props Dict [ str , Any ] Dict[str, Any] from the dispatcher required logger Logger instance to log data. required db_session DBManager instance to query and insert data. required Returns: Type Description Status of the operation Source code in src/stm32reader.py 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def handle_status ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Show the status of the reader. Args: props: Dict[str, Any] from the dispatcher logger: Logger instance to log data. db_session: DBManager instance to query and insert data. Returns: Status of the operation \"\"\" logger . results ( json . dumps ( { \"state\" : self . port [ \"state\" ], \"devices\" : [ d . __dict__ for d in self . devices ], } ) ) handle_write_invert ( props , logger , db_session ) We assume that a reader handles only one type of device, So all devices should have the same memory regions. Get first all different regions and later check that a device has at least one sample of all of them. Source code in src/stm32reader.py 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 def handle_write_invert ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" We assume that a reader handles only one type of device, So all devices *should* have the same memory regions. Get first all different regions and later check that a device has at least one sample of all of them. \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) device_list = list ( self . devices ) for dev in device_list [: len ( self . devices ) // 2 ]: num_addresses = dev . sram_size // self . data_size samples = ( db_session . query ( Sample ) . filter ( Sample . uid == dev . uid ) . order_by ( Sample . address . asc (), Sample . created_at . asc ()) . limit ( num_addresses ) . all () ) if not samples : logger . warning ( f \"At least one full memory sample has to be read from device { dev } \" ) continue if len ( samples ) != num_addresses : logger . warning ( f \"The memory sample for device { dev } is not complete\" ) continue end_offset = ( num_addresses ) - READ_ONLY_REGIONS for offset in range ( READ_ONLY_REGIONS , end_offset ): sample = samples [ offset ] packet = Packet ( self . data_size ) packet . with_command ( Command . WRITE ) packet . with_uid ( dev . uid ) packet . with_options ( offset ) packet . with_data ([ 0xFF ^ int ( d ) for d in sample . data . split ( \",\" )]) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : logger . error ( f \"Problem writing inverted values of device { dev } at offset { offset } \" ) continue if not res . check_crc () or res . command == Command . ERR : logger . warning ( f \"Packet { packet !s} is corrupted\" ) continue logger . debug ( f \"Wrote inverted values of device { dev } at offset { offset } \" ) logger . info ( f \"Finished inverting memory of device { dev } \" ) receive ( timeout = 0.2 , tries = 50 ) Received data from the serial port. Parameters: Name Type Description Default timeout float Time to wait until start receiving information. 0.2 Returns: Type Description List [ Packet ] List of packets received. Source code in src/stm32reader.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 def receive ( self , timeout : float = 0.2 , tries = 50 ) -> List [ Packet ]: \"\"\"Received data from the serial port. Args: timeout: Time to wait until start receiving information. Returns: List of packets received. \"\"\" packet_size = Packet . full_size ( self . data_size ) ser = self . port [ \"serial\" ] ser . flushInput () packets = [] msg = b \"\" time . sleep ( timeout ) checks = deque ( maxlen = tries // 2 ) for _ in range ( tries ): checks . appendleft ( ser . in_waiting ) while ser . in_waiting : while len ( msg ) < packet_size : msg += ser . read () packets . append ( Packet . from_bytes ( self . data_size , msg )) msg = b \"\" if all ( num == 0 for num in checks ) and packets : return packets time . sleep ( 0.05 ) return packets send ( data ) Transmit data through the serial port. Parameters: Name Type Description Default data bytes Bytes to sent. required Source code in src/stm32reader.py 77 78 79 80 81 82 83 84 85 86 def send ( self , data : bytes ): \"\"\"Transmit data through the serial port. Args: data: Bytes to sent. \"\"\" ser = self . port [ \"serial\" ] ser . flushInput () ser . write ( data ) ser . flushOutput () Database Bases: TableBase Source code in src/database.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class Sample ( TableBase ): __tablename__ = \"CRPs\" # Internal id of the sample. id = Column ( Integer , primary_key = True ) # Type of device connected in the chain. board_type = Column ( String , nullable = False ) # Universal ID of the device. uid = Column ( String , nullable = False ) # Position In Chain of the device. pic = Column ( Integer , nullable = False ) # Region of SRAM. Formated as 0x00000000 address = Column ( String , nullable = False ) # Comma separated list of values from the memory. data = Column ( String , nullable = False ) # Timestamp when the sample was gathered. created_at = Column ( DateTime , server_default = func . now (), nullable = False ) Bases: TableBase Source code in src/database.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class Sensor ( TableBase ): __tablename__ = \"Sensors\" # Internal id of the sensor data. id = Column ( Integer , primary_key = True ) # Type of device connected in the chain. board_type = Column ( String , nullable = False ) # Universal ID of the device. uid = Column ( String , nullable = False ) # Temperature value in degrees celsius. temperature = Column ( Float , nullable = False ) # Internal VDD in volts. voltage = Column ( Float , nullable = False ) # Timestamp when the sensor data was obtained. created_at = Column ( DateTime , server_default = func . now (), nullable = False )","title":"Platform API"},{"location":"tima_api/#src.stm32reader.Device","text":"Class to represent a device. Source code in src/stm32reader.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @dataclass class Device : \"\"\"Class to represent a device.\"\"\" #: Universal ID of the device uid : str #: Position In Chain of the device. pic : int #: Size, in bytes, of the device's SRAM. sram_size : int def __eq__ ( self , other ): return self . uid == other . uid and self . pic == other . pic def __hash__ ( self ): return hash (( \"uid\" , self . uid , \"pic\" , self . pic )) def __str__ ( self ): return f \" { self . pic : 03d } : { format_uid ( self . uid ) } \" def __repr__ ( self ): return f \"<Device { self . pic : 03d } : { format_uid ( self . uid ) } 0x { self . sram_size : 08X } >\"","title":"Device"},{"location":"tima_api/#src.stm32reader.STM32Reader","text":"Bases: Reader Reader implementation for STM32 boards. The functionaly of the reader is implemented in the methods called handle_{command} . Attributes: Name Type Description name Descriptive name of the Reader. devices List [ Device ] List of managed devices. port State of the devices and the serial port. Source code in src/stm32reader.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 class STM32Reader ( Reader ): \"\"\"Reader implementation for STM32 boards. The functionaly of the reader is implemented in the methods called `handle_{command}`. Attributes: name: Descriptive name of the Reader. devices: List of managed devices. port: State of the devices and the serial port. \"\"\" def __init__ ( self , board_type : str , port : str , baudrate : int , data_size : int ): super ( STM32Reader , self ) . __init__ ( board_type ) self . devices : List [ Device ] = [] self . name = board_type self . data_size = data_size port_path = Path ( port ) if not port_path . exists (): print ( f \"Port { port_path } does not exist\" ) sys . exit ( 1 ) ser = Serial ( port_path . as_posix (), baudrate , timeout = None ) self . port = { \"state\" : \"ON\" , \"serial\" : ser , \"path\" : port_path } def send ( self , data : bytes ): \"\"\"Transmit data through the serial port. Args: data: Bytes to sent. \"\"\" ser = self . port [ \"serial\" ] ser . flushInput () ser . write ( data ) ser . flushOutput () def receive ( self , timeout : float = 0.2 , tries = 50 ) -> List [ Packet ]: \"\"\"Received data from the serial port. Args: timeout: Time to wait until start receiving information. Returns: List of packets received. \"\"\" packet_size = Packet . full_size ( self . data_size ) ser = self . port [ \"serial\" ] ser . flushInput () packets = [] msg = b \"\" time . sleep ( timeout ) checks = deque ( maxlen = tries // 2 ) for _ in range ( tries ): checks . appendleft ( ser . in_waiting ) while ser . in_waiting : while len ( msg ) < packet_size : msg += ser . read () packets . append ( Packet . from_bytes ( self . data_size , msg )) msg = b \"\" if all ( num == 0 for num in checks ) and packets : return packets time . sleep ( 0.05 ) return packets def handle_status ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Show the status of the reader. Args: props: Dict[str, Any] from the dispatcher logger: Logger instance to log data. db_session: DBManager instance to query and insert data. Returns: Status of the operation \"\"\" logger . results ( json . dumps ( { \"state\" : self . port [ \"state\" ], \"devices\" : [ d . __dict__ for d in self . devices ], } ) ) def handle_power_off ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Power off the serial port. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" try : p = run ([ \"ykushcmd\" , \"-d\" , \"a\" ]) if p . returncode == 0 : self . port [ \"state\" ] = \"OFF\" logger . info ( \"Port powered off\" ) else : logger . warning ( \"Could not power off port\" ) raise CommandError except Exception as excep : raise CommandError ( f \"Problem powering off port { self . port [ 'path' ] } : { excep } \" ) from excep def handle_power_on ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Power on the serial port. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" try : p = run ([ \"ykushcmd\" , \"-u\" , \"a\" ]) if p . returncode == 0 : self . port [ \"state\" ] = \"ON\" logger . info ( \"Port powered on\" ) else : logger . warning ( \"Could not power on port\" ) raise CommandError except Exception as excep : raise CommandError ( f \"Problem powering on port { self . port [ 'path' ] } : { excep } \" ) from excep def handle_ping ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Register the devices connected to the reader. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" status_correct : Optional [ bool ] = None prev_devices = self . devices packet = Packet ( self . data_size ) packet . with_command ( Command . PING ) packet . craft () self . send ( packet . to_bytes ()) packets = self . receive () if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Please turn on the serial port first\" ) if prev_devices and not packets : raise CommandError ( \"There were devices connected but now no devices could be identified\" ) if not packets : raise CommandError ( \"No devices could be identified\" ) devices : List [ Device ] = [] for packet in packets : if not packet . check_crc (): logger . warning ( f \"Packet { packet !s} is corrupted\" ) status_correct = False else : devices . append ( Device ( format_uid ( packet . uid ), packet . pic , packet . options ) ) self . devices = devices if status_correct is None : logger . results ( json . dumps ([ d . __dict__ for d in self . devices ])) def handle_sensors ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Register the devices connected to the reader. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) for dev in self . devices : packet = Packet ( self . data_size ) packet . with_command ( Command . SENSORS ) packet . with_uid ( dev . uid ) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : logger . error ( f \"Problem reading sensors for device { dev } \" ) continue if not packet . check_crc () or packet . command == Command . ERR : logger . warning ( f \"Packet { packet !s} for device { dev } is corrupted\" ) continue sensors_data = res . extract_sensors () logger . results ( json . dumps ( { \"device\" : { \"uid\" : dev . uid , \"pic\" : dev . pic }, \"temperature\" : sensors_data [ \"temperature\" ], \"voltage\" : sensors_data [ \"voltage\" ], } ) ) db_session . add ( Sensor ( uid = format_uid ( res . uid ), board_type = self . name , temperature = sensors_data [ \"temperature\" ], voltage = sensors_data [ \"voltage\" ], ) ) db_session . commit () def handle_read ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) # Only store the day the read is done current_day = datetime . now () current_day = current_day . replace ( hour = 12 , minute = 0 , second = 0 ) for dev in self . devices : for offset in range ( dev . sram_size // self . data_size ): address = offset_to_address ( self . data_size , offset ) packet = Packet ( self . data_size ) packet . with_command ( Command . READ ) packet . with_uid ( dev . uid ) packet . with_options ( offset ) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : logger . error ( f \"Problem reading memory of device { dev } at offset { offset } \" ) continue if not packet . check_crc () or packet . command == Command . ERR : logger . warning ( f \"Packet { packet !s} is corrupted\" ) continue logger . debug ( f \"Read memory of { dev } at offset { offset } \" ) db_session . add ( Sample ( board_type = self . name , uid = format_uid ( res . uid ), pic = dev . pic , address = address , data = \",\" . join ([ str ( d ) for d in res . data ]), created_at = current_day , ) ) db_session . commit () logger . info ( f \"Finished reading memory of { dev } \" ) def handle_write ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) offset = props [ \"offset\" ] dev_uid = props [ \"device\" ] dev = next ( filter ( lambda d : d . uid == dev_uid , self . devices ), None ) if not dev : raise CommandError ( f \"Device { dev_uid } is not managed\" ) max_offset = dev . sram_size // self . data_size if offset < 0 or offset > max_offset : raise CommandError ( f \"Offset { offset } for device { dev } must be in range [0, { max_offset } ]\" ) packet = Packet ( self . data_size ) packet . with_command ( Command . WRITE ) packet . with_uid ( dev . uid ) packet . with_options ( offset ) packet . with_data ([ int ( b ) for b in props [ \"data\" ]]) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : raise CommandError ( f \"Problem writing to memory of device { dev } at offset { offset } \" ) if not res . check_crc () or res . command == Command . ERR : raise CommandError ( f \"Packet { packet !s} is corrupted\" ) logger . info ( \"Data written correctly\" ) def handle_write_invert ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" We assume that a reader handles only one type of device, So all devices *should* have the same memory regions. Get first all different regions and later check that a device has at least one sample of all of them. \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) device_list = list ( self . devices ) for dev in device_list [: len ( self . devices ) // 2 ]: num_addresses = dev . sram_size // self . data_size samples = ( db_session . query ( Sample ) . filter ( Sample . uid == dev . uid ) . order_by ( Sample . address . asc (), Sample . created_at . asc ()) . limit ( num_addresses ) . all () ) if not samples : logger . warning ( f \"At least one full memory sample has to be read from device { dev } \" ) continue if len ( samples ) != num_addresses : logger . warning ( f \"The memory sample for device { dev } is not complete\" ) continue end_offset = ( num_addresses ) - READ_ONLY_REGIONS for offset in range ( READ_ONLY_REGIONS , end_offset ): sample = samples [ offset ] packet = Packet ( self . data_size ) packet . with_command ( Command . WRITE ) packet . with_uid ( dev . uid ) packet . with_options ( offset ) packet . with_data ([ 0xFF ^ int ( d ) for d in sample . data . split ( \",\" )]) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : logger . error ( f \"Problem writing inverted values of device { dev } at offset { offset } \" ) continue if not res . check_crc () or res . command == Command . ERR : logger . warning ( f \"Packet { packet !s} is corrupted\" ) continue logger . debug ( f \"Wrote inverted values of device { dev } at offset { offset } \" ) logger . info ( f \"Finished inverting memory of device { dev } \" ) def handle_load ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) dev_uid = props [ \"device\" ] dev = next ( filter ( lambda d : d . uid == dev_uid , self . devices ), None ) if not dev : raise CommandError ( f \"Device { dev_uid } is not managed\" ) source = props [ \"source\" ] len_code = len ( source ) data_buf = [ ord ( c ) for c in source ] + [ ord ( \" \\x00 \" )] * ( self . data_size - len_code ) packet = Packet ( self . data_size ) packet . with_command ( Command . LOAD ) packet . with_uid ( dev_uid ) packet . with_data ( data_buf ) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : raise CommandError ( f \"Problem loading code for device { dev } \" ) if not res . check_crc () or res . command == Command . ERR : raise CommandError ( f \"Packet { packet !s} is corrupted\" ) logger . info ( f \"Code loaded on device { dev } correctly\" ) def handle_exec ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) dev_uid = props [ \"device\" ] dev = next ( filter ( lambda d : d . uid == dev_uid , self . devices ), None ) if not dev : raise CommandError ( f \"Device { dev_uid } is not managed\" ) packet = Packet ( self . data_size ) packet . with_command ( Command . EXEC ) packet . with_uid ( dev_uid ) packet . with_options ( int ( props . get ( \"reset\" , 0 ))) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : raise CommandError ( f \"Problem executing code on device { dev } \" ) if not res . check_crc () or res . command == Command . ERR : raise CommandError ( f \"Packet { packet !s} is corrupted\" ) if res . options != 0 : raise CommandError ( f \"Code on device { dev } executed with error code { res . options } \" ) logger . info ( f \"Code on device { dev } executed correctly\" ) def handle_retr ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) dev_uid = props [ \"device\" ] dev = next ( filter ( lambda d : d . uid == dev_uid , self . devices ), None ) if not dev : raise CommandError ( f \"Device { dev_uid } is not managed\" ) packet = Packet ( self . data_size ) packet . with_command ( Command . RETR ) packet . with_uid ( dev . uid ) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : raise CommandError ( f \"Problem retrieving results from device { dev } \" ) if not res . check_crc () or res . command == Command . ERR : raise CommandError ( f \"Packet { packet !s} is corrupted\" ) numbers = struct . unpack ( f \"< { self . data_size // 4 } i\" , bytes ( res . data )) numbers_str = map ( str , numbers ) numbers_str = map ( lambda n : n . replace ( \"10\" , \" \\n \" ) . replace ( \"32\" , \" \" ), numbers_str ) logger . info ( f \"Results retrieved correctly from device { dev } \" ) logger . results ( json . dumps ( { \"raw_bytes\" : res . data , \"int\" : numbers , \"string\" : \"\" . join ( numbers_str ), } ) )","title":"STM32Reader"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_ping","text":"Register the devices connected to the reader. Parameters: Name Type Description Default props Dict [ str , Any ] Dictionary containing the message from the dispatcher. required Returns: Type Description Dictionary with the status of the operation and metadata if needed. Source code in src/stm32reader.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 def handle_ping ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Register the devices connected to the reader. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" status_correct : Optional [ bool ] = None prev_devices = self . devices packet = Packet ( self . data_size ) packet . with_command ( Command . PING ) packet . craft () self . send ( packet . to_bytes ()) packets = self . receive () if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Please turn on the serial port first\" ) if prev_devices and not packets : raise CommandError ( \"There were devices connected but now no devices could be identified\" ) if not packets : raise CommandError ( \"No devices could be identified\" ) devices : List [ Device ] = [] for packet in packets : if not packet . check_crc (): logger . warning ( f \"Packet { packet !s} is corrupted\" ) status_correct = False else : devices . append ( Device ( format_uid ( packet . uid ), packet . pic , packet . options ) ) self . devices = devices if status_correct is None : logger . results ( json . dumps ([ d . __dict__ for d in self . devices ]))","title":"handle_ping()"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_power_off","text":"Power off the serial port. Parameters: Name Type Description Default props Dict [ str , Any ] Dictionary containing the message from the dispatcher. required Returns: Type Description Dictionary with the status of the operation and metadata if needed. Source code in src/stm32reader.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def handle_power_off ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Power off the serial port. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" try : p = run ([ \"ykushcmd\" , \"-d\" , \"a\" ]) if p . returncode == 0 : self . port [ \"state\" ] = \"OFF\" logger . info ( \"Port powered off\" ) else : logger . warning ( \"Could not power off port\" ) raise CommandError except Exception as excep : raise CommandError ( f \"Problem powering off port { self . port [ 'path' ] } : { excep } \" ) from excep","title":"handle_power_off()"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_power_on","text":"Power on the serial port. Parameters: Name Type Description Default props Dict [ str , Any ] Dictionary containing the message from the dispatcher. required Returns: Type Description Dictionary with the status of the operation and metadata if needed. Source code in src/stm32reader.py 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def handle_power_on ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Power on the serial port. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" try : p = run ([ \"ykushcmd\" , \"-u\" , \"a\" ]) if p . returncode == 0 : self . port [ \"state\" ] = \"ON\" logger . info ( \"Port powered on\" ) else : logger . warning ( \"Could not power on port\" ) raise CommandError except Exception as excep : raise CommandError ( f \"Problem powering on port { self . port [ 'path' ] } : { excep } \" ) from excep","title":"handle_power_on()"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_sensors","text":"Register the devices connected to the reader. Parameters: Name Type Description Default props Dict [ str , Any ] Dictionary containing the message from the dispatcher. required Returns: Type Description Dictionary with the status of the operation and metadata if needed. Source code in src/stm32reader.py 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 def handle_sensors ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Register the devices connected to the reader. Args: props: Dictionary containing the message from the dispatcher. Returns: Dictionary with the status of the operation and metadata if needed. \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) for dev in self . devices : packet = Packet ( self . data_size ) packet . with_command ( Command . SENSORS ) packet . with_uid ( dev . uid ) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : logger . error ( f \"Problem reading sensors for device { dev } \" ) continue if not packet . check_crc () or packet . command == Command . ERR : logger . warning ( f \"Packet { packet !s} for device { dev } is corrupted\" ) continue sensors_data = res . extract_sensors () logger . results ( json . dumps ( { \"device\" : { \"uid\" : dev . uid , \"pic\" : dev . pic }, \"temperature\" : sensors_data [ \"temperature\" ], \"voltage\" : sensors_data [ \"voltage\" ], } ) ) db_session . add ( Sensor ( uid = format_uid ( res . uid ), board_type = self . name , temperature = sensors_data [ \"temperature\" ], voltage = sensors_data [ \"voltage\" ], ) ) db_session . commit ()","title":"handle_sensors()"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_status","text":"Show the status of the reader. Parameters: Name Type Description Default props Dict [ str , Any ] Dict[str, Any] from the dispatcher required logger Logger instance to log data. required db_session DBManager instance to query and insert data. required Returns: Type Description Status of the operation Source code in src/stm32reader.py 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def handle_status ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\"Show the status of the reader. Args: props: Dict[str, Any] from the dispatcher logger: Logger instance to log data. db_session: DBManager instance to query and insert data. Returns: Status of the operation \"\"\" logger . results ( json . dumps ( { \"state\" : self . port [ \"state\" ], \"devices\" : [ d . __dict__ for d in self . devices ], } ) )","title":"handle_status()"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_write_invert","text":"We assume that a reader handles only one type of device, So all devices should have the same memory regions. Get first all different regions and later check that a device has at least one sample of all of them. Source code in src/stm32reader.py 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 def handle_write_invert ( self , props : Dict [ str , Any ], logger , db_session ): \"\"\" We assume that a reader handles only one type of device, So all devices *should* have the same memory regions. Get first all different regions and later check that a device has at least one sample of all of them. \"\"\" if self . port [ \"state\" ] == \"OFF\" : raise CommandError ( \"Serial port is off. Turn on the serial port first\" ) if not self . devices : raise CommandError ( \"No devices managed\" ) device_list = list ( self . devices ) for dev in device_list [: len ( self . devices ) // 2 ]: num_addresses = dev . sram_size // self . data_size samples = ( db_session . query ( Sample ) . filter ( Sample . uid == dev . uid ) . order_by ( Sample . address . asc (), Sample . created_at . asc ()) . limit ( num_addresses ) . all () ) if not samples : logger . warning ( f \"At least one full memory sample has to be read from device { dev } \" ) continue if len ( samples ) != num_addresses : logger . warning ( f \"The memory sample for device { dev } is not complete\" ) continue end_offset = ( num_addresses ) - READ_ONLY_REGIONS for offset in range ( READ_ONLY_REGIONS , end_offset ): sample = samples [ offset ] packet = Packet ( self . data_size ) packet . with_command ( Command . WRITE ) packet . with_uid ( dev . uid ) packet . with_options ( offset ) packet . with_data ([ 0xFF ^ int ( d ) for d in sample . data . split ( \",\" )]) packet . craft () self . send ( packet . to_bytes ()) res = next ( iter ( self . receive ()), None ) if res is None : logger . error ( f \"Problem writing inverted values of device { dev } at offset { offset } \" ) continue if not res . check_crc () or res . command == Command . ERR : logger . warning ( f \"Packet { packet !s} is corrupted\" ) continue logger . debug ( f \"Wrote inverted values of device { dev } at offset { offset } \" ) logger . info ( f \"Finished inverting memory of device { dev } \" )","title":"handle_write_invert()"},{"location":"tima_api/#src.stm32reader.STM32Reader.receive","text":"Received data from the serial port. Parameters: Name Type Description Default timeout float Time to wait until start receiving information. 0.2 Returns: Type Description List [ Packet ] List of packets received. Source code in src/stm32reader.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 def receive ( self , timeout : float = 0.2 , tries = 50 ) -> List [ Packet ]: \"\"\"Received data from the serial port. Args: timeout: Time to wait until start receiving information. Returns: List of packets received. \"\"\" packet_size = Packet . full_size ( self . data_size ) ser = self . port [ \"serial\" ] ser . flushInput () packets = [] msg = b \"\" time . sleep ( timeout ) checks = deque ( maxlen = tries // 2 ) for _ in range ( tries ): checks . appendleft ( ser . in_waiting ) while ser . in_waiting : while len ( msg ) < packet_size : msg += ser . read () packets . append ( Packet . from_bytes ( self . data_size , msg )) msg = b \"\" if all ( num == 0 for num in checks ) and packets : return packets time . sleep ( 0.05 ) return packets","title":"receive()"},{"location":"tima_api/#src.stm32reader.STM32Reader.send","text":"Transmit data through the serial port. Parameters: Name Type Description Default data bytes Bytes to sent. required Source code in src/stm32reader.py 77 78 79 80 81 82 83 84 85 86 def send ( self , data : bytes ): \"\"\"Transmit data through the serial port. Args: data: Bytes to sent. \"\"\" ser = self . port [ \"serial\" ] ser . flushInput () ser . write ( data ) ser . flushOutput ()","title":"send()"},{"location":"tima_api/#database","text":"Bases: TableBase Source code in src/database.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class Sample ( TableBase ): __tablename__ = \"CRPs\" # Internal id of the sample. id = Column ( Integer , primary_key = True ) # Type of device connected in the chain. board_type = Column ( String , nullable = False ) # Universal ID of the device. uid = Column ( String , nullable = False ) # Position In Chain of the device. pic = Column ( Integer , nullable = False ) # Region of SRAM. Formated as 0x00000000 address = Column ( String , nullable = False ) # Comma separated list of values from the memory. data = Column ( String , nullable = False ) # Timestamp when the sample was gathered. created_at = Column ( DateTime , server_default = func . now (), nullable = False ) Bases: TableBase Source code in src/database.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class Sensor ( TableBase ): __tablename__ = \"Sensors\" # Internal id of the sensor data. id = Column ( Integer , primary_key = True ) # Type of device connected in the chain. board_type = Column ( String , nullable = False ) # Universal ID of the device. uid = Column ( String , nullable = False ) # Temperature value in degrees celsius. temperature = Column ( Float , nullable = False ) # Internal VDD in volts. voltage = Column ( Float , nullable = False ) # Timestamp when the sensor data was obtained. created_at = Column ( DateTime , server_default = func . now (), nullable = False )","title":"Database"}]}