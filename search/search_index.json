{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#introduction","title":"Introduction","text":"<p>This platform is a collection of tools that aim to automate the process of collecting memory samples of numerous micro-controllers and their subsequent storage for future analysis. The memory data gathered will then be used mainly for SRAM-based Physical Unclonable Functions (PUF) analysis, as it is normally very difficult to gather enough data for this type of analysis.</p>"},{"location":"#motivation","title":"Motivation","text":"<p>The purpose of our open platform is twofold: To provide easy access to a comprehensive database that includes thousands of samples of multiple boards, and to share the platform to carry out tailored experiments related to NBTI and data remanence effects. Our open platform succeeds in both aspects. From the economic point of view, our platform will save many resources to the users in terms of money (buying hundreds of devices) and time (collecting thousands of samples).</p> <p>Using the available raw-data, any user of the platform can carry out their own experiments (e.g. design of new post-processing, find systematic variations, etc.) with an enough number of samples and devices to consider the experiment statistically significant. Besides, the extra information provided (operating conditions, wafer position, etc) will open new possibilities to find vulnerabilities and develop new metrics. </p> <p>As a totally new feature, to the best of our knowledge unique up to the date, we offer the user the possibility of interaction with the boards by controlling the switch On/Off time of the micro-controllers (data remanence studies) and writing custom values in the SRAM (NBTI studies).</p>"},{"location":"#documentation-structure","title":"Documentation structure","text":"<p>The section Getting started shows how to install the platform and the dependencies required.</p> <p>The implementation of the platform is described in detail here.</p> <p>The documentation of the current platform is shown here</p> <p>Info</p> <p>This documentation is still in progress. Except things to be added, removed or changed.</p>"},{"location":"code_exec/","title":"Code execution","text":"<p>Custom code can be loaded into the devices memory and executed later thanks to zForth.</p>"},{"location":"commands/","title":"Executing commands","text":"<p>A command refers to an operation that the station can carry out. All of the information necesary to carry such operation should be written to the header of the packet. </p> Command Command code Description <code>ACK</code> 1 Packet acknowledge. <code>PING</code> 2 Discover devices in a chain. <code>READ</code> 3 Read a region of memory from a device. <code>WRITE</code> 4 Write values to a region of memory of a device. <code>SENSORS</code> 5 Read sensors from a device. <code>LOAD</code> 6 Load code into memory to be interpreted later. <code>EXEC</code> 7 Interpret code stored in memory. <code>RETR</code> 8 Retrieve the results from the code. <code>ERR</code> 255 Error during transmision. <p>Info</p> <p>The script <code>send_command.py</code> can be used to send one of the predefined commands above to a running agent from the CLI.</p> <p>Once an agent has been deployed, and a reader has been assigned to it, new messages can be sent to the agent directly as seen below.</p> Sending a message with an agent<pre><code>from fenneq import Agent\n# URL and exchange_name have to be the same as the other agents\nurl = \"amqp://user:pass@localhost\"\nexchange_name = \"sram_commands\"\ntopic = \"sram.discovery\"\nagent = Agent(\nurl, exchange_name, topic, Agent.JSON\n)\nmsg = {'method': 'READ'}\n# Message will be sent to sram.discovery\nagent.send(msg)\n# The message can be sent to another topic with the same agent\nagent.send(msg, name=\"sram.nucleo\") \n</code></pre>"},{"location":"commands/#station-commands","title":"Station commands","text":""},{"location":"commands/#power-on","title":"Power on","text":"<p>Power on the serial port connected to the dispatcher. </p> <code>Parameters</code> <pre><code>{\"command\": \"power_on\"}\n</code></pre> <code>Logging</code> Level Description INFO <code>Port powered on.</code> WARNING <code>Could not power on port.</code> ERROR <code>Problem powering on port {port}: {reason}.</code>"},{"location":"commands/#power-off","title":"Power off","text":"<p>Power off the serial port connected to the dispatcher.</p> <code>Parameters</code> <pre><code>{\"command\": \"power_off\"}\n</code></pre> <code>Logging</code> Level Description INFO <code>Port powered off.</code> WARNING <code>Could not power off port.</code> ERROR <code>Problem powering off port {port}: {reason}.</code>"},{"location":"commands/#status","title":"Status","text":"<p>Check whether the serial port of the dispatcher is on or off and the number of devices it is managing.</p> <code>Parameters</code> <pre><code>{\"command\": \"status\"}\n</code></pre> <code>Results</code> <pre><code>{\n\"state\": \"ON\" | \"OFF\", \n\"devices\": [{\"uid\": str, \"pic\": int, \"sram_size\": int}, ...]\n}\n</code></pre>"},{"location":"commands/#ping","title":"Ping","text":"<p>Register devices that are in the chain connected to the serial port.</p> <code>Parameters</code> <pre><code>{\"command\": \"ping\"}\n</code></pre> <code>Logging</code> Level Description ERROR <code>Serial port is off. Please turn on the serial port first.</code> ERROR <code>There were devices connected but now no devices could be identified.</code> ERROR <code>No devices could be identified.</code> WARNING <code>Packet {packet} is corrupted.</code> <code>Results</code> <p><code>[{\"uid\": str, \"pic\": int, \"sram_size\": int}, ...]</code></p>"},{"location":"commands/#read","title":"Read","text":"<p>Read all regions of memory from all devices managed by the dispatcher. This command can be done per device and per region of memory but it is performed on all devices and regions in one go.</p> <p>The ping command has to be executed first.</p> <code>Parameters</code> <p><code>{\"command\": \"read\"}</code></p> <code>Logging</code> Code Description ERROR <code>Serial port is off. Please turn on the serial port first.</code> ERROR <code>No devices managed.</code> ERROR <code>Problem reading memory of device {device} at offset {offset}</code> WARNING <code>Packet {packet} for device {device} is corrupted.</code> INFO <code>Finished reading memory of device {device}.</code>"},{"location":"commands/#write","title":"Write","text":"<p>Write values to a region of memory of a device managed by the dispatcher.</p> <p>The ping command has to be executed first.</p> <code>Parameters</code> <pre><code>{\"command\": \"write\", \"device\": str, \"data\": list[int], \"offset\": int}\n</code></pre> <code>Logging</code> Code Description ERROR <code>Serial port is off. Please turn on the serial port first.</code> ERROR <code>No devices managed.</code> ERROR <code>Device {device} is not managed.</code> ERROR <code>Offset {offset} for device {device} must be in range [0, {max_offset}]</code> ERROR <code>Problem writing to device {device} at offset {offset}</code> ERROR <code>Packet {packet} for device {device} is corrupted.</code> INFO <code>Data written correctly.</code>"},{"location":"commands/#write-invert","title":"Write invert","text":"<p>Write inverted values to half of the devices managed by a dispatcher. Inverted values are calculated based on the first sample (a.k.a. reference sample) of a device. </p> <p>The ping command has to be executed first.</p> <code>Parameters</code> <pre><code>{\"command\": \"write_invert\"}\n</code></pre> <code>Logging</code> Code Description ERROR <code>Serial port is off. Please turn on the serial port first.</code> ERROR <code>No devices managed.</code> WARNING <code>At least one full memory sample has to be read from device {device}.</code> WARNING <code>The memory sample for device {device} is not complete.</code> ERROR <code>Problem writing inverted values to device {device} at offset {offset}</code> ERROR <code>Packet {packet} for device {device} is corrupted.</code> DEBUG <code>Wrote inverted values of device {device} at offset {offset}.</code> INFO <code>Finished inverting memory of device {device}.</code>"},{"location":"commands/#sensors","title":"Sensors","text":"<p>Read the sensors of the devices managed by a dispatcher.</p> <p>The ping command has to be executed first.</p> <code>Parameters</code> <pre><code>{\"command\": \"sensors\"}\n</code></pre> <code>Logging</code> Code Description ERROR <code>Serial port is off. Please turn on the serial port first.</code> ERROR <code>No devices managed.</code> ERROR <code>Problem reading sensors of device {device}.</code> WARNING <code>Packet {packet} for device {device} is corrupted.</code> <code>Results</code> <pre><code>{\"device\": {\"uid\": str, \"pic\": int}, \"temperature\": float, \"voltage\": float}\n</code></pre>"},{"location":"commands/#load","title":"Load","text":"<p>Load code onto a device managed by the dispatcher. </p> <p>The ping command has to be executed first.</p> <code>Parameters</code> <pre><code>{\"command\": \"load\", \"device\": str, \"source\": str, \"offset\": int}\n</code></pre> <code>Logging</code> Code Description ERROR <code>Serial port is off. Please turn on the serial port first.</code> ERROR <code>No devices managed.</code> ERROR <code>Device {device} is not managed.</code> ERROR <code>Problem loading code for device {device}.</code> ERROR <code>Packet {packet} for device {device} is corrupted.</code> INFO <code>Code loaded on device {device} correctly.</code>"},{"location":"commands/#execute","title":"Execute","text":"<p>Execute code loaded into a device managed by the dispatcher and write the results to memory.</p> <p>The ping command has to be executed first.</p> <code>Parameters</code> <pre><code>{\"command\": \"exec\", \"device\": str, \"reset\": bool}\n</code></pre> <code>Logging</code> Code Description ERROR <code>Serial port is off. Please turn on the serial port first.</code> ERROR <code>No devices managed.</code> ERROR <code>Device {device} is not managed.</code> ERROR <code>Problem executing code on device {device}.</code> ERROR <code>Packet {packet} for device {device} is corrupted.</code> ERROR <code>Code on device {device} executed with error code {code}.</code> INFO <code>Code executed on device {device} correctly.</code>"},{"location":"commands/#retrieve","title":"Retrieve","text":"<p>Retrieve the results from executing loaded code from a device managed by the dispatcher.</p> <p>The ping command has to be executed first.</p> <code>Parameters</code> <pre><code>{\"command\": \"retr\", \"device\": str}\n</code></pre> <code>Logging</code> Code Description ERROR <code>Serial port is off. Please turn on the serial port first.</code> ERROR <code>No devices managed.</code> ERROR <code>Device {device} is not managed.</code> ERROR <code>Problem retrieving results from device {device}.</code> ERROR <code>Packet {packet} for device {device} is corrupted.</code> INFO <code>Results retrieved correctly from device {device}.</code> <code>Results</code> <pre><code>{\"raw_bytes\": bytes, \"int\": list[int], \"string\": str}\n</code></pre>"},{"location":"communication/","title":"Communication","text":""},{"location":"communication/#packet-based-protocol","title":"Packet based protocol","text":"<p>The communication between a reader and a device chain is performed using a custom packet based protocol.</p> <p>The source code documentation of the packet can be found :doc:<code>here &lt;packet&gt;</code>.</p> Field Encoding Description Method uint8_t Type of packet. See commands PIC uint16_t <code>Position In Chain</code>. Index of the device in the chain Options uint16_t Metadata for the packet UID char[25] Universal ID of the device Checksum uint32_t Checksum of the packet Data uint8_t[DATA_SIZE] Actual data of the packet <p>The DATA_SIZE can be defined by the user, but it has to be small than the smallest SRAM size of a device in the chain.</p>"},{"location":"communication/#working-with-packets","title":"Working with packets","text":"Example of creation of a packet<pre><code>packet = Packet() # Generate a packet with default values\n# The following are the default values\npacket.with_method(Method.Ping)\npacket.with_options(0x0)\npacket.with_checksum(0)\npacket.with_pic(1)\npacket.with_uid(\"DEVICE ID\")\npacket.with_data([0x0, ..., 0x0])\npacket.craft() # Craft the packet to send it\n# The packet can now be used by calling `to_bytes`\nprint(packet.to_bytes())\n</code></pre> <p>Warning</p> <p>Even if the packet has the default configuration, is is necesary to craft it before sending it, otherwise it will raise a <code>ValueError</code>. The method <code>is_crafted</code> returns <code>True</code> if the packet is ready to be sent.</p>"},{"location":"database/","title":"Storage","text":"<p>The information is stored in a PostreSQL database. In the python code, the database is managed with the sqlalchemy ORM. That means that the tables in the database can be created from a python class. All of the logic concerning the database is carried out by the DBManager class.</p>"},{"location":"database/#schema-definition","title":"Schema definition","text":"<p>SRAM samples and sensors are managed by the classes <code>Sample</code> and <code>Sensor</code> respectively.</p>"},{"location":"database/#storing-samples-and-sensor-information","title":"Storing samples and sensor information","text":"Example of storing a sample and sensor<pre><code>url = \"postgres://username:password@localhost:5432/database\"\ndb = DBManager(url)\nsample = Sample(\nuid=\"DEVICE ID\",\nboard_id=\"NUCLEO\",\npic=1,\naddress=\"0x20000000\",\ndata=\",\".join([str(d) for d in range(1024)]),\ncreated_at=datetime.now(),\n)\ndb.insert(sample)\nsensor = Sensor(\nuid=\"DEVICE ID\",\nboard_id=\"NUCLEO\",\ntemperature=27,\nvoltage=3300,\n)\ndb.insert(sensor)\ndb.commit()\n</code></pre>"},{"location":"deployment/","title":"Setup guide","text":"<p>This section will describe the requirements needed to deploy a station. Here we describe first the software requirements followed by the hardware requirements and lastly, their physical installation and deployment.</p>"},{"location":"deployment/#device-source-code","title":"Device source code","text":"<p>This project contains code for two different STM32 boards. Each project is managed by STM32Cube. Devices should be programmed using the same software.</p>"},{"location":"deployment/#setting-up-docker","title":"Setting up docker","text":"<p>The file docker-compose.yml provides the template necesary to launch those services. However, it is necesary to update the configuration values in the file before deploying. The main parameters to modify are user and password of both RabbitMQ and PostgreSQL. The other important parameter is the volume configuration for postgreSQL, (e.g. where to store the data in the computer). The path before the semicolon points to the path in the computer where to store the samples. The path after the semicolorn should not be modified.</p> <p>Note</p> <p>We can think of docker as a virtual machine. We can provide some paths (here <code>volumes</code>) in the computer that will get linked to a path inside the container. The syntax is <code>path_in_computer:path_in_docker</code>.</p> Example of docker-compose file<pre><code>version: '3'\nservices:\nzookeeper:\nimage: confluentinc/cp-zookeeper:7.3.0\ncontainer_name: zookeeper\nenvironment:\nZOOKEEPER_CLIENT_PORT: 2181\nZOOKEEPER_TICK_TIME: 2000\nbroker:\nimage: confluentinc/cp-kafka:7.3.0\ncontainer_name: broker\nports:\n# To learn about configuring Kafka for access across networks see\n# https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/\n- \"9092:9092\"\ndepends_on:\n- zookeeper\nenvironment:\nKAFKA_BROKER_ID: 1\nKAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'\nKAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT\nKAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092\nKAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\nKAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1\nKAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1\n</code></pre> Start services with docker-compose<pre><code>$ docker-compose up -d -f /path/to/docker-compose.yml\n$ docker-compose up -d # If in the same path as docker-compose.yml\n</code></pre> Stop docker services<pre><code>$ docker-compose down # In the same path as docker-compose.yml\n</code></pre>"},{"location":"deployment/#deployment-services","title":"Deployment services","text":"<p>Once all the software is installed and the hardware is properly connected, the station should be ready for deployment. The deployment of the station can be carried out with the use of systemd services.</p> <pre><code>#!/usr/bin/env python3\nfrom sramplatform import Dispatcher, ConnParameters\n# Custom implementation of Reader\nfrom customreader import CustomReader\nreader = CustomReader(\"Discovery\", 0, 125_000)\nparams = ConnParameters(\"rabbitmq_user\", \"rabbitmq_pass\")\nplatform = Dispatcher(\nparams, \"exchange_commands\", \"station_name\", \"exchange_logs\"\n)\nplatform.add_command({\"method\": \"read\"}, reader.handle_read)\nplatform.add_command({\"method\": \"write\", \"data\": True}, reader.handle_write)\nif __name__ == '__main__':\nplatform.run()\n</code></pre> <pre><code>[Unit]\nDescription=SRAM Reliability Platform\nAfter=network.target\n\n[Service]\nType=simple\nRestart=always\nRestartSec=5\nWorkingDirectory=/path/to/SRAMPlatform\nExecStart=/path/to/virtualenv/bin/python3 main.py\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Operations can be scheduled by using the send_command.py script provided and a systemd timer (very similar to a cron job). The following example illustrates how to create the files necesary to power off the platform every friday at 17:00.</p> <pre><code>[Unit]\nDescription=Power off the SRAM Platform\n\n[Timer]\nOnCalendar=Fri *-*-* 17:00:00\nPersistent=true\n\n[Install]\nWantedBy=timers.target\n</code></pre> <pre><code>[Unit]\nDescription=Power off the SRAM Platform\nAfter=network.target\n\n[Service]\nType=oneshot\nRemainAfterExit=true\nWorkingDirectory=/path/to/SRAMPlatform\nExecStart=/path/to/virtualenv/bin/python3 send_command.py \"OFF\"\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"deployment/#configuring-a-dispatcher","title":"Configuring a dispatcher","text":"Example of configuration<pre><code>agent:\nurl: \"amqp://user:password@hostname\"\nname: \"agent name\"\nexchange: \"rabbitmq exchange\"\nreader:\nboard_type: \"Type of board the reader manages\"\nport: \"/path/to/ttyUSB\"\nbaudrate: 125000\nlogging:\nformat: \"[%(asctime)s] [%(levelname)-8s] %(message)s\"\ndatefmt: \"%H:%M:%S %d-%m-%Y\"\nloggers:\n- TelegramHandler:\nlevel: WARNING # INFO by default\ntoken: \"Telegram Bot Token\"\nchat_ids: 00000000000\n# Custom log format\nformat: \"[%(asctime)s] %(name)s\\n%(message)s\"\n# Filter logs with highel level than filter_level\n# If level and filter are defined, the logs allowed are\n# level &lt;= level &lt; filter_level\nfilter_level: RESULTS\n- RabbitMQHandler:\nkey: \"routing key\"\nexchange: \"\"\n- StreamHandler:\nlevel: DEBUG\n- MailHandler:\nemail: \"email@gmail.com\"\noauth: \"/path/to/oauth.json\"\nrecipients:\nsubject: - FileHandler:\npath: \"/path/to/file.log\"\n- RotatingFileHandler:\npath: \"/path/to/file.log\"\nmaxBytes: 20000\nbackupCount: 7\n- TimedRotatingFileHandler:\npath: \"/path/to/file.log\"\nwhen: \"midnight\"\nbackupCount: 7\n</code></pre>"},{"location":"description/","title":"Description","text":"<p>The SRAM Platform is composed of 3 main components:</p> <ul> <li>A <code>dispatcher</code> to handle messages between the user and the platform.</li> <li>A <code>reader</code> to receive and send commands from and to the connected devices.</li> <li>The <code>devices</code> connected to the platform to be studied.</li> </ul> <p>There are also two other components, a database and logging manager, whose purpose is the storage of samples and the recording of commands respectively.</p> <p>The source code of the platform can be found under the directory <code>sramplatform</code> inside the project.  The API reference can be accesed here.</p>"},{"location":"description/#dispatcher","title":"Dispatcher","text":"<p>The dispatcher is the first big component of the platform. It will listen to messages comming from a message broker and will dispatch the appropiato command to the required reader.</p> <p>A message broker enables applications and systems to communicate with each other and exchange information. It is the main mechanism that allows a user to send commands to a station to be processed and executed later in time. RabbitMQ is the the message broker chosen. One of the advantages of using RabbitMQ is that we have access to queues to hold messages so that users can send multiple commands at a time without the need of waiting for them to be executed directly.</p> <p>In order to manage the connections to the message broker and handling the messages, the library makes use of fenneq agents. The documentation of fenneq provides in detail explanations on how to setup an agent to connect to RabbitMQ.</p>"},{"location":"description/#reader","title":"Reader","text":"<p>The objective of the reader is to be provide an iterface to communicate with the different devices. It receives the messages from the dispatcher after they have been filtered and it generates the necessary data to be send to the devices to carry out the desired command.</p> <p>The code written is this library is device agnostic, so a reader can manage multiple types of devices at the same time. However, it is advised that a reader is in charge of only a specific type of device. Multiple readers can be assigned to the same dispatcher to be able to perform some commands on a series of devices with just a simple group of commands.</p> <p>The basic functionaly of a reader is defined ith the <code>Reader</code> interface. The documentation for this component is found in the <code>reader</code> module.</p>"},{"location":"description/#device","title":"Device","text":"<p>A device is the smallest unit of the station. These are the physical devices whose memory will be read and studied. This framework is designed to work with microcontrollers but it should work with other devices as long as the communication protocol is implemented.</p> <p>Info</p> <p>In this documentation, the terms device and board are equivalent.</p>"},{"location":"description/#database-manager","title":"Database manager","text":"<p>The objective of this platform is to retrieve the memory of devices in order to be analysed later. In order to store the samples a database needs to be used to reliable store samples and retrieve them efficiently.</p> <p>The parameters for connection to a database are handled by the <code>DBParameters</code> class. The connection itself and operations can be carried out with the <code>DBManager</code> class. The default database is PostreSQL but another database can be used by configuring the DBParameters and docker, since the operations in the database are managed by an ORM.</p> <p>The documentation for this manager is found in the <code>storage</code> module.</p>"},{"location":"description/#logging-manager","title":"Logging manager","text":"<p>The logging manager keeps track of every command that has been executed by a reader and display any errors or information along the way. The logging component is implement through the logging module in the standard library. </p> <p>The platform provides also some custom handlers to alert the user, such as <code>RabbitMQHandler</code>, <code>TelegramHandler</code> and <code>MailHandler</code>.</p> <p>The documentation for this manager is found in the <code>logbook</code> module.</p> <p>The logging section of the platform configuration shows all available configuration options for logging. The section is shown below.</p> Logging configuration<pre><code>logging:\nformat: \"[%(asctime)s] [%(levelname)-8s] %(message)s\"\ndatefmt: \"%H:%M:%S %d-%m-%Y\"\nloggers:\n- TelegramHandler:\nlevel: WARNING # INFO by default\ntoken: \"Telegram Bot Token\"\nchat_ids: 00000000000\n# Custom log format\nformat: \"[%(asctime)s] %(name)s\\n%(message)s\"\n# Filter logs with highel level than filter_level\n# If level and filter are defined, the logs allowed are\n# level &lt;= level &lt; filter_level\nfilter_level: RESULTS\n- RabbitMQHandler:\nkey: \"routing key\"\nexchange: \"\"\n- StreamHandler:\nlevel: DEBUG\n- MailHandler:\nemail: \"email@gmail.com\"\noauth: \"/path/to/oauth.json\"\nrecipients:\nsubject: - FileHandler:\npath: \"/path/to/file.log\"\n- RotatingFileHandler:\npath: \"/path/to/file.log\"\nmaxBytes: 20000\nbackupCount: 7\n- TimedRotatingFileHandler:\npath: \"/path/to/file.log\"\nwhen: \"midnight\"\nbackupCount: 7\n</code></pre>"},{"location":"device_api/","title":"Device API","text":"<p>The code for the different devices can be found in:</p> <ul> <li><code>SRAMPlatform/src/Device_Nucleo</code></li> <li><code>SRAMPlatform/src/Device_Discovery</code></li> </ul> <pre><code>src/Device_Discovery\n\u2514\u2500\u2500 Core\n \u00a0\u00a0 \u251c\u2500\u2500 Inc\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 main.h\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sramconf.h\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sramplatform.h\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 zforth.h\n \u00a0\u00a0 \u2514\u2500\u2500 Src\n \u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 main.c\n \u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 sramplatform.c\n \u00a0\u00a0  \u00a0\u00a0 \u2514\u2500\u2500 zforth.c\n</code></pre> Example of sramconf.h<pre><code>#ifndef INC_SRAMCONF_H_\n#define INC_SRAMCONF_H_\n/// Start address of the SRAM\n#define SRAM_ADDRESS 0x20000000\n/// Address of the VDD calibration value\n#define VDD_CAL_ADDRESS 0x1FF800F8\n/// Address of the temperature at 30 calibration value\n#define TEMP30_CAL_ADDRESS 0x1FF800FA\n/// Address of the temperature at 110 calibration value\n#define TEMP110_CAL_ADDRESS 0x1FF800FE\n/// Number of blocks from SRAM_START the source buffer is located\n#define SRC_BUF_OFFSET 148\n/// Number of blocks from SRAM_START the write buffer is located\n#define WRITE_BUF_OFFSET 150\n/// Maximum number of bytes in the WRITE Buffer\n#define WRITE_BUF_MAX (DATA_SIZE)\n#endif /* INC_SRAMCONF_H_ */\n</code></pre>"},{"location":"devices/","title":"Devices","text":"<p>This platform was created with the intention of collecting data from micro-controllers. The devices we mainly have access to are the STM32L152RE and the STM32L152RCT6.</p> <p>One of the limitations we have to solve is to maximize the number of devices we can connect to a computer. The USB protocol has a limitations of 127 devices in total, including USB hubs. Moreover the process of connecting or removing devices from a station will be very time consuming. In order to have relevant statistically relevant analysis for SRAM-based PUF, we need a very large number of devices (hundreds at least) so we need to use another solution for this.</p> <p>To solve this problem, the devices are connected in scan chains, that is, the computer connects to a device (the start of the chain) and the next device is connected to the device before it. Doing this the only limitation is having a power supply strong enough to keep all the connected devices turned on. The devices communicate between them by using the USART, which is very simple to configure and provides speeds of communication fast enough for this application.</p> <p>In order to control the devices that are connected to a chain, the station keeps track of each device unique id and their position in the chain (referred in the code as pic). </p> <p>STM32 devices contain 96 internal bits stored in the SRAM, that can be used as a unique identifier of the device. In the case of using other devices, the user would need to store a unique id for each device in memory to be able to identify them in the future.</p> <p>To keep track of the position, each packet has a field called pic, that gets incremented every time a packet travels downstream. (Oposite as how the Time To Live of an IPC packet gets decremented after each jump). The process of gathering the information of every devices is through the PING command, described in detail commands.</p> <p>We can see in the following diagram, an example of how the different devices create chains and how different chains can be connected to a computer.</p> <pre><code>             USB           Rx -&gt; Tx           Rx -&gt; Tx        Rx -&gt; Tx\n  Computer ------&gt; Device ----------&gt; Device ----------&gt; ... ----------&gt; Device\n           |               Tx -&gt; Rx           Tx -&gt; Rx        Tx -&gt; Rx\n           |\n           |\n           |\n           | USB           Rx -&gt; Tx\n           |-----&gt; Device ----------&gt; Device \n                           Tx -&gt; Rx\n</code></pre> <p>The software running on the devices has been created such that all devices run the same code, independently of their position in the chain. This makes the process of adding and removing boards very simple. Besides that, devices of different devices can be connected in the same scan chain, as each device is aware of its own SRAM size and can react to packets that ask for commands that cannot be carried out for an specific amount of memory.</p> <p>Since the  Regarding the communication direction, there are two distinct directions:</p> <code>Upstream</code> <p>From the device to the station.</p> <code>Downstream</code> <p>From a device to the next device.</p> <p>This distinction will be important specially in the device source code. Each device allocates a buffer for each direction as to be able to receive data from both directions at the same time. This should not happen in real life, but one of the priority of the station is to guarantee the integrity of the data sent or received from a device. For that, only one of the buffers should be used at real time. This separation also makes the code very simple as it is very simple to setup the interreptions for the communication protocol to store the data received directly in the buffer.</p> <p>Info</p> <p>As it was said before, this platform was created with the intention of gathering data from micro-controllers. Other types of devices can be connected to the station as long as they use the same packet based protocol. If the user wants to use another communication protocol, they will need to write their own <code>Device Reader</code> and register the new reader to an agent.</p>"},{"location":"logging/","title":"Logging","text":"<p>The way commands are added to a dispatcher is through the <code>add_command()</code> method.</p> Implementation example of add_command()<pre><code>def add_command(self, handler, func, **options):\n\"Add a command to a dispatcher\"\n@self.agent.on(handler, **options)\ndef handler_fn(*args, **kwargs):\nresponse = func(*args, **kwargs)\nif response:\nmessage = {\"handler\": kwargs[\"body\"], \"response\": response}\nself.log.send(msg=message)\n</code></pre> <p>The result of the command, if any, will be logged automatically to the logging channel specified in the Dispatcher.</p> Function template whose result is logged.<pre><code>from sramplatform import Status, LogLevel\ndef custom_fn(*args, **kwargs):\nif True:\nreturn {'status': Status.OK}\nelse:\nreturn {\n'status': Status.OK,\n'level': LogLevel.Info,\n'msg': \"Error message\"\n}\n</code></pre>"},{"location":"platform_api/","title":"Platform API","text":""},{"location":"platform_api/#sramplatform.packet.Command","title":"<code>Command</code>","text":"<p>         Bases: <code>Enum</code></p> <p>Command the platform should execute.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>class Command(Enum):\n\"\"\"Command the platform should execute.\"\"\"\n# Packet has been received correctly.\nACK = 1\n# Identify devices in a chain.\nPING = 2\n# Read a region of memory.\nREAD = 3\n# Write to a region of memory.\nWRITE = 4\n# Read the sensors of a device.\nSENSORS = 5\n# Load custom code in a device.\nLOAD = 6\n# Execute custom code on a device.\nEXEC = 7\n# Receive results from executing code.\nRETR = 8\n# Error when receiveng a packet.\nERR = 255\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet","title":"<code>Packet</code>","text":"<p>Packet used for the communication protocol.</p> <p>Attributes:</p> Name Type Description <code>command</code> <p>Command the platform should execute.</p> <code>pic</code> <p>Position In Chain of the device.</p> <code>options</code> <p>Metadata for the packet.</p> <code>uid</code> <p>UID of the device.</p> <code>data</code> <p>Actual data of the packet.</p> <code>bytes</code> <p>Bytes representation of the packet.</p> <code>checksum</code> <code>Optional[int]</code> <p>CRC of the packet for integrity.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>class Packet:\n\"\"\"Packet used for the communication protocol.\n    Attributes:\n        command: Command the platform should execute.\n        pic: Position In Chain of the device.\n        options: Metadata for the packet.\n        uid: UID of the device.\n        data: Actual data of the packet.\n        bytes: Bytes representation of the packet.\n        checksum: CRC of the packet for integrity.\n    \"\"\"\ndef __init__(self, data_size: int):\nself.data_size = data_size\nself.bytes_fmt = f\"&lt;BBI25s{self.data_size}BH\"\nself.size = struct.calcsize(self.bytes_fmt)\nself.__command: int = Command.PING.value\nself.__pic: int = 0\nself.__options: int = 0x0\nself.__uid: str = \"0\" * 25\nself.__data: List[int] = [0x7] * self.data_size\nself.checksum: Optional[int] = None\nself.__bytes: Optional[bytes] = None\n@classmethod\ndef full_size(cls, data_size: int):\npacket = cls(data_size)\nreturn packet.size\ndef __str__(self):\nchecksum = self.checksum or 0\nreturn (\nf\"&lt;Packet {Command(self.__command).name} \"\nf\"{self.__pic:03d}:{format_uid(self.__uid)} \"\nf\"[0x{self.__options:04X}] \"\nf\"CRC(0x{checksum:04X})&gt;\"\n)\ndef __repr__(self):\nchecksum = self.checksum or 0\nreturn (\nf\"&lt;Packet {Command(self.__command).name} \"\nf\"{self.__pic:03d}:{format_uid(self.__uid)} \"\nf\"[0x{self.__options:04X}] \"\nf\"CRC(0x{checksum:04X}) \"\nf\"{bytes(self.__data)}&gt;\"\n)\n@property\ndef command(self):\n\"Getter for command\"\nreturn self.__command\n@property\ndef pic(self):\n\"Getter for pic\"\nreturn self.__pic\n@property\ndef options(self):\n\"Getter for options\"\nreturn self.__options\n@property\ndef uid(self):\n\"Getter for uid\"\nreturn self.__uid\n@property\ndef data(self):\n\"Getter for data\"\nreturn self.__data\ndef with_command(self, command: Union[int, Command]):\n\"\"\"Set the command of the packet.\"\"\"\nif isinstance(command, Command):\nself.__command = command.value\nelse:\nself.__command = command\ndef with_pic(self, pic: int):\n\"\"\"Set the pic of the packet.\"\"\"\nself.__pic = pic\ndef with_uid(self, uid: str):\n\"\"\"Set the uid of the packet.\"\"\"\nself.__uid = uid\ndef with_options(self, options: int):\n\"\"\"Set the options of the packet.\"\"\"\nself.__options = options\ndef with_data(self, data: list[int]):\n\"\"\"Set the data of the packet.\"\"\"\nself.__data = data\ndef with_checksum(self, checksum: int):\n\"\"\"Set the checksum of the packet.\"\"\"\nself.checksum = checksum\ndef is_crafted(self) -&gt; bool:\n\"\"\"Check if a packet is ready to be sent.\n        Returns:\n            True if bytes is not None.\n        \"\"\"\nreturn self.__bytes is not None\ndef craft(self):\n\"\"\"Craft a packet to send.\n        Calculate the checksum if it hasn't been calculated yet,\n        and create the bytes representation of the packet.\n        \"\"\"\nif isinstance(self.__uid, bytes):\nuid = self.__uid\nelse:\nuid = bytes(self.__uid, \"utf-8\")\nif self.checksum is None:\nself.__bytes = struct.pack(\nself.bytes_fmt,\nself.__command,\nself.__pic,\nself.__options,\nuid,\n*self.__data,\n0,\n)\nself.checksum = crc16(self.__bytes)\nself.__bytes = struct.pack(\nself.bytes_fmt,\nself.__command,\nself.__pic,\nself.__options,\nuid,\n*self.__data,\nself.checksum,\n)\n@classmethod\ndef from_bytes(cls, data_size: int, raw_data: bytes):\n\"\"\"\n        Create a packet from bytes.\n        Args:\n          raw_data: Bytes representing the packet.\n        Raises:\n          ValueError: If the length of ``raw_data`` does not match ``Packet.SIZE``.\n        Returns:\n          Packet created from the bytes.\n        \"\"\"\npacket = cls(data_size)\nif len(raw_data) != packet.size:\nerror = f\"Packet size {len(raw_data)} does not match {data_size}\"\nraise ValueError(error)\n(\ncommand,\npic,\noptions,\nuid,\n*data,\nchecksum,\n) = struct.unpack(packet.bytes_fmt, raw_data)\npacket.with_command(command)\npacket.with_pic(pic)\npacket.with_uid(uid)\npacket.with_options(options)\npacket.with_data(data)\npacket.with_checksum(checksum)\npacket.craft()\nreturn packet\ndef extract_sensors(self) -&gt; Dict:\n\"\"\"Extract the values of the sensors from the data.\n        The information of the sensors is stored in the following way:\n        - `temp_110_cal`: Temperature calibration at 110 Celsius.\n        - `temp_30_cal`: Temperature calibration at 30 Celsius.\n        - `temp_raw`: Raw value of temperature.\n        - `vdd_cal`: Calibration of VDD.\n        - `vdd_raw`: Raw value of VDD.\n        All the values are stored in 2 bytes.\n        Returns:\n            Dictionary containing ``temperature`` and ``vdd``.\n        \"\"\"\ndef calc_vdd(vdd: int, vdd_cal: int) -&gt; float:\n\"\"\"\n            Calculate the working voltage.\n            Args:\n              vdd: Raw value from the voltage sensor.\n              vdd_cal: Calibration value.\n            Returns:\n              The working vdd in volts.\n            \"\"\"\nreturn round((3300 * vdd_cal / vdd) * 0.001, 5)\ndef calc_temp(temp: int, cal_30: int, cal_110: int) -&gt; float:\n\"\"\"\n            Calculate the working temperature.\n            Args:\n              temp: Raw value from the temperature sensor.\n              cal_30: Calibration value at 30 degrees celsius.\n              cal_110: Calibration value at 110 degrees celsius.\n            Returns:\n              The working temperature in degrees celsius.\n            \"\"\"\nreturn round(((110 - 30) / (cal_110 - cal_30)) * (temp - cal_30) + 30.0, 5)\ndata = struct.unpack(\"&lt;HHHHH\", bytes(self.__data[:10]))\nreturn {\n\"temperature\": calc_temp(data[2], data[1], data[0]),\n\"voltage\": calc_vdd(data[4], data[3]),\n}\ndef to_bytes(self) -&gt; bytes:\n\"\"\"Return the bytes representation the packet.\n        Returns:\n            Bytes representation of the packet.\n        Raises:\n            ValueError if packet is not crafted.\n        \"\"\"\nif self.__bytes is None:\nraise ValueError(\"Packet is not crafted. Call craft() method first\")\nreturn self.__bytes\ndef check_crc(self) -&gt; bool:\nif self.__bytes is None:\nraise ValueError(\"Packet is not crafted. Call craft() method first\")\nbuffer = bytearray(self.__bytes)\nbuffer[-1], buffer[-2] = 0, 0\nreturn crc16(buffer) == self.checksum\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet.command","title":"<code>command</code>  <code>property</code>","text":"<p>Getter for command</p>"},{"location":"platform_api/#sramplatform.packet.Packet.data","title":"<code>data</code>  <code>property</code>","text":"<p>Getter for data</p>"},{"location":"platform_api/#sramplatform.packet.Packet.options","title":"<code>options</code>  <code>property</code>","text":"<p>Getter for options</p>"},{"location":"platform_api/#sramplatform.packet.Packet.pic","title":"<code>pic</code>  <code>property</code>","text":"<p>Getter for pic</p>"},{"location":"platform_api/#sramplatform.packet.Packet.uid","title":"<code>uid</code>  <code>property</code>","text":"<p>Getter for uid</p>"},{"location":"platform_api/#sramplatform.packet.Packet.craft","title":"<code>craft()</code>","text":"<p>Craft a packet to send.</p> <p>Calculate the checksum if it hasn't been calculated yet, and create the bytes representation of the packet.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def craft(self):\n\"\"\"Craft a packet to send.\n    Calculate the checksum if it hasn't been calculated yet,\n    and create the bytes representation of the packet.\n    \"\"\"\nif isinstance(self.__uid, bytes):\nuid = self.__uid\nelse:\nuid = bytes(self.__uid, \"utf-8\")\nif self.checksum is None:\nself.__bytes = struct.pack(\nself.bytes_fmt,\nself.__command,\nself.__pic,\nself.__options,\nuid,\n*self.__data,\n0,\n)\nself.checksum = crc16(self.__bytes)\nself.__bytes = struct.pack(\nself.bytes_fmt,\nself.__command,\nself.__pic,\nself.__options,\nuid,\n*self.__data,\nself.checksum,\n)\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet.extract_sensors","title":"<code>extract_sensors()</code>","text":"<p>Extract the values of the sensors from the data.</p> <p>The information of the sensors is stored in the following way:</p> <ul> <li><code>temp_110_cal</code>: Temperature calibration at 110 Celsius.</li> <li><code>temp_30_cal</code>: Temperature calibration at 30 Celsius.</li> <li><code>temp_raw</code>: Raw value of temperature.</li> <li><code>vdd_cal</code>: Calibration of VDD.</li> <li><code>vdd_raw</code>: Raw value of VDD.</li> </ul> <p>All the values are stored in 2 bytes.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>Dictionary containing <code>temperature</code> and <code>vdd</code>.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def extract_sensors(self) -&gt; Dict:\n\"\"\"Extract the values of the sensors from the data.\n    The information of the sensors is stored in the following way:\n    - `temp_110_cal`: Temperature calibration at 110 Celsius.\n    - `temp_30_cal`: Temperature calibration at 30 Celsius.\n    - `temp_raw`: Raw value of temperature.\n    - `vdd_cal`: Calibration of VDD.\n    - `vdd_raw`: Raw value of VDD.\n    All the values are stored in 2 bytes.\n    Returns:\n        Dictionary containing ``temperature`` and ``vdd``.\n    \"\"\"\ndef calc_vdd(vdd: int, vdd_cal: int) -&gt; float:\n\"\"\"\n        Calculate the working voltage.\n        Args:\n          vdd: Raw value from the voltage sensor.\n          vdd_cal: Calibration value.\n        Returns:\n          The working vdd in volts.\n        \"\"\"\nreturn round((3300 * vdd_cal / vdd) * 0.001, 5)\ndef calc_temp(temp: int, cal_30: int, cal_110: int) -&gt; float:\n\"\"\"\n        Calculate the working temperature.\n        Args:\n          temp: Raw value from the temperature sensor.\n          cal_30: Calibration value at 30 degrees celsius.\n          cal_110: Calibration value at 110 degrees celsius.\n        Returns:\n          The working temperature in degrees celsius.\n        \"\"\"\nreturn round(((110 - 30) / (cal_110 - cal_30)) * (temp - cal_30) + 30.0, 5)\ndata = struct.unpack(\"&lt;HHHHH\", bytes(self.__data[:10]))\nreturn {\n\"temperature\": calc_temp(data[2], data[1], data[0]),\n\"voltage\": calc_vdd(data[4], data[3]),\n}\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet.from_bytes","title":"<code>from_bytes(data_size, raw_data)</code>  <code>classmethod</code>","text":"<p>Create a packet from bytes.</p> <p>Parameters:</p> Name Type Description Default <code>raw_data</code> <code>bytes</code> <p>Bytes representing the packet.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the length of <code>raw_data</code> does not match <code>Packet.SIZE</code>.</p> <p>Returns:</p> Type Description <p>Packet created from the bytes.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>@classmethod\ndef from_bytes(cls, data_size: int, raw_data: bytes):\n\"\"\"\n    Create a packet from bytes.\n    Args:\n      raw_data: Bytes representing the packet.\n    Raises:\n      ValueError: If the length of ``raw_data`` does not match ``Packet.SIZE``.\n    Returns:\n      Packet created from the bytes.\n    \"\"\"\npacket = cls(data_size)\nif len(raw_data) != packet.size:\nerror = f\"Packet size {len(raw_data)} does not match {data_size}\"\nraise ValueError(error)\n(\ncommand,\npic,\noptions,\nuid,\n*data,\nchecksum,\n) = struct.unpack(packet.bytes_fmt, raw_data)\npacket.with_command(command)\npacket.with_pic(pic)\npacket.with_uid(uid)\npacket.with_options(options)\npacket.with_data(data)\npacket.with_checksum(checksum)\npacket.craft()\nreturn packet\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet.is_crafted","title":"<code>is_crafted()</code>","text":"<p>Check if a packet is ready to be sent.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if bytes is not None.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def is_crafted(self) -&gt; bool:\n\"\"\"Check if a packet is ready to be sent.\n    Returns:\n        True if bytes is not None.\n    \"\"\"\nreturn self.__bytes is not None\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet.to_bytes","title":"<code>to_bytes()</code>","text":"<p>Return the bytes representation the packet.</p> <p>Returns:</p> Type Description <code>bytes</code> <p>Bytes representation of the packet.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def to_bytes(self) -&gt; bytes:\n\"\"\"Return the bytes representation the packet.\n    Returns:\n        Bytes representation of the packet.\n    Raises:\n        ValueError if packet is not crafted.\n    \"\"\"\nif self.__bytes is None:\nraise ValueError(\"Packet is not crafted. Call craft() method first\")\nreturn self.__bytes\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet.with_checksum","title":"<code>with_checksum(checksum)</code>","text":"<p>Set the checksum of the packet.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def with_checksum(self, checksum: int):\n\"\"\"Set the checksum of the packet.\"\"\"\nself.checksum = checksum\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet.with_command","title":"<code>with_command(command)</code>","text":"<p>Set the command of the packet.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def with_command(self, command: Union[int, Command]):\n\"\"\"Set the command of the packet.\"\"\"\nif isinstance(command, Command):\nself.__command = command.value\nelse:\nself.__command = command\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet.with_data","title":"<code>with_data(data)</code>","text":"<p>Set the data of the packet.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def with_data(self, data: list[int]):\n\"\"\"Set the data of the packet.\"\"\"\nself.__data = data\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet.with_options","title":"<code>with_options(options)</code>","text":"<p>Set the options of the packet.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def with_options(self, options: int):\n\"\"\"Set the options of the packet.\"\"\"\nself.__options = options\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet.with_pic","title":"<code>with_pic(pic)</code>","text":"<p>Set the pic of the packet.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def with_pic(self, pic: int):\n\"\"\"Set the pic of the packet.\"\"\"\nself.__pic = pic\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.Packet.with_uid","title":"<code>with_uid(uid)</code>","text":"<p>Set the uid of the packet.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def with_uid(self, uid: str):\n\"\"\"Set the uid of the packet.\"\"\"\nself.__uid = uid\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.crc16","title":"<code>crc16(buffer)</code>","text":"<p>Calculate the CRC16 from a byte buffer.</p> <p>Parameters:</p> Name Type Description Default <code>buffer</code> <code>bytes</code> <p>Buffer of bytes.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The calculated CRC.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def crc16(buffer: bytes) -&gt; int:\n\"\"\"Calculate the CRC16 from a byte buffer.\n    Args:\n        buffer: Buffer of bytes.\n    Returns:\n        The calculated CRC.\n    \"\"\"\ncrc = 0\ndef crc16_byte(crc, data):\n\"\"\"Helper function to get a value from the CRC16_LUT\"\"\"\nreturn (crc &gt;&gt; 8) ^ CRC16_LUT[(crc ^ data) &amp; 0xFF]\nfor byte in buffer:\ncrc = crc16_byte(crc, byte)\nreturn crc\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.format_uid","title":"<code>format_uid(uid)</code>","text":"<p>Format a device UID.</p> <p>If the uid is bytes, remove the null terminator.</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>Union[str, bytes]</code> <p>UID of the device.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Ther formmated UID as a string.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def format_uid(uid: Union[str, bytes]) -&gt; str:\n\"\"\"Format a device UID.\n    If the uid is bytes, remove the null terminator.\n    Args:\n        uid: UID of the device.\n    Returns:\n        Ther formmated UID as a string.\n    \"\"\"\nif isinstance(uid, str):\nreturn uid\nreturn uid.decode(\"ascii\").split(\"\\x00\")[0]\n</code></pre>"},{"location":"platform_api/#sramplatform.packet.offset_to_address","title":"<code>offset_to_address(offset, data_size, sram_start=536870912)</code>","text":"<p>Convert an offset in memory to absolute memory address.</p> <p>Parameters:</p> Name Type Description Default <code>offset</code> <code>int</code> <p>Offset from the start of the SRAM.</p> required <code>sram_start</code> <code>int</code> <p>Byte representing the start of the SRAM. 0x20000000 by default.</p> <code>536870912</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If offset is negative.</p> <p>Returns:</p> Type Description <code>str</code> <p>Address formated as 0xXXXXXXXX.</p> Source code in <code>sramplatform/packet.py</code> <pre><code>def offset_to_address(offset: int, data_size: int, sram_start: int = 0x20000000) -&gt; str:\n\"\"\"Convert an offset in memory to absolute memory address.\n    Args:\n        offset: Offset from the start of the SRAM.\n        sram_start: Byte representing the start of the SRAM. 0x20000000 by default.\n    Raises:\n        ValueError: If offset is negative.\n    Returns:\n        Address formated as 0xXXXXXXXX.\n    \"\"\"\nif offset &lt; 0:\nraise ValueError(\"Offset cannot be negative\")\nreturn f\"0x{sram_start + (offset * data_size):08X}\"\n</code></pre>"},{"location":"platform_api/#sramplatform.storage.DBManager","title":"<code>DBManager</code>","text":"<p>Class to manage the communication with the database.</p> <p>The default database is PostreSQL. However, another database can be used in place by configuring the DBManager.</p> <p>The manager is allowed to insert into the database any object as long as it has been registered by using <code>TableBase</code>.  For more instructions on how to register objects to the database please see <code>https://docs.sqlalchemy.org/en/14/orm/declarative_tables.html</code>.</p> Example <p>from sramplatform.storage import DBManager, TableBase</p> <p>class Users(TableBase):     tablename = \"User\"     id = Column(Integer, primary_key=True)     name = Column(String, nullable=False)</p> <p>manager = DBManager(url)</p> <p>Queries can be made by using the session attribute.</p> Example <p>manager.session.query(User).all</p> <p>Attributes:</p> Name Type Description <code>session</code> <p>Session to the DB</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>Union[str, DBParameters]</code> <p>DBParameters instance or string containing the url to connect.</p> required Source code in <code>sramplatform/storage.py</code> <pre><code>class DBManager:\n\"\"\"Class to manage the communication with the database.\n    The default database is PostreSQL. However, another database can be used in place by configuring the DBManager.\n    The manager is allowed to insert into the database any object as long as it has been registered by using ``TableBase``.  For more instructions on how to register objects to the database please see `https://docs.sqlalchemy.org/en/14/orm/declarative_tables.html`.\n    Example:\n        &gt;&gt;&gt; from sramplatform.storage import DBManager, TableBase\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; class Users(TableBase):\n        &gt;&gt;&gt;     __tablename__ = \"User\"\n        &gt;&gt;&gt;     id = Column(Integer, primary_key=True)\n        &gt;&gt;&gt;     name = Column(String, nullable=False)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; manager = DBManager(url)\n    Queries can be made by using the session attribute.\n    Example:\n        &gt;&gt;&gt; manager.session.query(User).all\n    Attributes:\n        session: Session to the DB\n    Args:\n        url: DBParameters instance or string containing the url to connect.\n    \"\"\"\ndef __init__(self, url: Union[str, DBParameters]):\nengine = create_engine(str(url))\nSession = sessionmaker(engine)\nself.session = Session()\nTableBase.metadata.create_all(engine)\n</code></pre>"},{"location":"platform_api/#sramplatform.storage.DBParameters","title":"<code>DBParameters</code>  <code>dataclass</code>","text":"<p>Class to manage database connection parameters.</p> <p>By default it is assumed that the database is PostgreSQL. For a list of supported engines, please see <code>https://docs.sqlalchemy.org/en/14/core/engines.html</code>.</p> <p>Attributes:</p> Name Type Description <code>user</code> <code>str</code> <p>Username to connect to the database.</p> <code>password</code> <code>str</code> <p>User password to connect to the database.</p> <code>dbname</code> <code>Optional[str]</code> <p>Name of the database to connect.</p> <code>engine</code> <code>Optional[str]</code> <p>Database to use. Defaults to 'postgresql'.</p> <code>host</code> <code>Optional[str]</code> <p>Hostname for the database. Defaults to 'localhost'.</p> <code>port</code> <code>Optional[int]</code> <p>Connection port for the database. Defaults to 5432.</p> Source code in <code>sramplatform/storage.py</code> <pre><code>@dataclass\nclass DBParameters:\n\"\"\"Class to manage database connection parameters.\n    By default it is assumed that the database is PostgreSQL.\n    For a list of supported engines, please see `https://docs.sqlalchemy.org/en/14/core/engines.html`.\n    Attributes:\n        user: Username to connect to the database.\n        password: User password to connect to the database.\n        dbname: Name of the database to connect.\n        engine: Database to use. Defaults to 'postgresql'.\n        host: Hostname for the database. Defaults to 'localhost'.\n        port: Connection port for the database. Defaults to 5432.\n    \"\"\"\nuser: str\npassword: str\ndbname: Optional[str] = None\nengine: Optional[str] = None\nhost: Optional[str] = None\nport: Optional[int] = None\ndef __post_init__(self):\nif self.engine is None:\nself.engine = \"postgresql\"\nif self.host is None:\nself.host = \"localhost\"\nif self.port is None:\nself.port = 5432\ndef __str__(self):\nreturn (\nf\"{self.engine}://\"\nf\"{self.user}:{self.password}\"\nf\"@{self.host}:{self.port}/{self.dbname}\"\n)\n</code></pre>"},{"location":"platform_api/#sramplatform.reader.Reader","title":"<code>Reader</code>","text":"<p>Interface of a device reader.</p> <p>The reader acts as a proxy between the station and the devices.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>Descriptive name of the reader.</p> Source code in <code>sramplatform/reader.py</code> <pre><code>class Reader:\n\"\"\"Interface of a device reader.\n    The reader acts as a proxy between the station and the devices.\n    Attributes:\n        name: Descriptive name of the reader.\n    \"\"\"\ndef __init__(self, name: str):\nself.name = name\ndef send(self, data: bytes):\nraise NotImplementedError\ndef receive(self):\nraise NotImplementedError\n</code></pre>"},{"location":"platform_api/#sramplatform.logbook.LogLevelFilter","title":"<code>LogLevelFilter</code>","text":"<p>         Bases: <code>logging.Filter</code></p> <p>https://stackoverflow.com/a/7447596/190597 (robert)</p> Source code in <code>sramplatform/logbook.py</code> <pre><code>class LogLevelFilter(logging.Filter):\n\"\"\"https://stackoverflow.com/a/7447596/190597 (robert)\"\"\"\ndef __init__(self, level):\nself.level = level\ndef filter(self, record):\nreturn record.levelno &lt; self.level\n</code></pre>"},{"location":"platform_api/#sramplatform.logbook.MailHandler","title":"<code>MailHandler</code>","text":"<p>         Bases: <code>logging.StreamHandler</code></p> <p>Log handler for Email.</p> Source code in <code>sramplatform/logbook.py</code> <pre><code>class MailHandler(logging.StreamHandler):\n\"\"\"Log handler for Email.\"\"\"\ndef __init__(self, email, oauth_path, recipients, subject):\nsuper(MailHandler, self).__init__(self)\nself.mail = yagmail.SMTP(email, oauth2_file=oauth_path)\nif isinstance(recipients, list):\nself.recipients = recipients\nelse:\nself.recipients = list(recipients)\nself.subject = subject\ndef emit(self, record):\nmsg = self.format(record)\ntemplate = f\"\"\"\n{msg}\n        \"\"\"\nself.mail.send(to=self.recipients, subject=self.subject, contents=template)\n</code></pre>"},{"location":"platform_api/#sramplatform.logbook.RabbitMQHandler","title":"<code>RabbitMQHandler</code>","text":"<p>         Bases: <code>logging.StreamHandler</code></p> <p>Log handler for RabbitMQ.</p> Source code in <code>sramplatform/logbook.py</code> <pre><code>class RabbitMQHandler(logging.StreamHandler):\n\"\"\"Log handler for RabbitMQ.\"\"\"\ndef __init__(self, url, name, exchange):\nsuper(RabbitMQHandler, self).__init__(self)\nself.agent = Sender(url, name, exchange)\ndef emit(self, record):\nmsg = self.format(record)\nself.agent.send(msg)\n</code></pre>"},{"location":"platform_api/#sramplatform.logbook.TelegramHandler","title":"<code>TelegramHandler</code>","text":"<p>         Bases: <code>logging.StreamHandler</code></p> <p>Log handler for Telegram.</p> Source code in <code>sramplatform/logbook.py</code> <pre><code>class TelegramHandler(logging.StreamHandler):\n\"\"\"Log handler for Telegram.\"\"\"\ndef __init__(self, token, chat_ids):\nsuper(TelegramHandler, self).__init__(self)\nself.bot = TeleBot(token)\nif isinstance(chat_ids, list):\nself.chat_ids = chat_ids\nelse:\nself.chat_ids = [chat_ids]\ndef emit(self, record):\nmsg = self.format(record)\nfor chat in self.chat_ids:\nself.bot.send_message(chat, msg)\n</code></pre>"},{"location":"platform_api/#sramplatform.logbook.create_handler","title":"<code>create_handler(name, conf)</code>","text":"<p>Create a handler from a name and a dict.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the handler to create.</p> required <code>conf</code> <code>Dict[str, Any]</code> <p>Dictionary containing the handler configuration.</p> required <p>Returns:</p> Type Description <code>HandlerType</code> <p>The configured handler.</p> Source code in <code>sramplatform/logbook.py</code> <pre><code>def create_handler(name: str, conf: Dict[str, Any]) -&gt; HandlerType:\n\"\"\"Create a handler from a name and a dict.\n    Args:\n        name: Name of the handler to create.\n        conf: Dictionary containing the handler configuration.\n    Returns:\n        The configured handler.\n    \"\"\"\nif name == \"TelegramHandler\":\nreturn TelegramHandler(conf[\"token\"], conf[\"chat_ids\"])\nif name == \"RabbitMQHandler\":\nreturn RabbitMQHandler(conf[\"url\"], conf[\"key\"], conf[\"exachange\"])\nif name == \"MailHandler\":\nreturn MailHandler(\nconf[\"mail\"], conf[\"oauth\"], conf[\"recipients\"], conf[\"subject\"]\n)\nif name == \"FileHandler\":\nreturn FileHandler(conf[\"path\"])\nif name == \"StreamHandler\":\nreturn StreamHandler(sys.stdout)\nif name == \"RotatingFileHandler\":\nreturn RotatingFileHandler(\nconf[\"path\"], maxBytes=conf[\"maxBytes\"], backupCount=conf[\"backupCount\"]\n)\nif name == \"TimedRotatingFileHandler\":\nreturn TimedRotatingFileHandler(\nconf[\"path\"],\nwhen=conf[\"when\"],\nbackupCount=conf[\"backupCount\"],\n)\nraise ValueError(f\"Handler {name} is not available\")\n</code></pre>"},{"location":"platform_api/#sramplatform.logbook.make_formatter","title":"<code>make_formatter(conf, fmt_default, datefmt_default)</code>","text":"<p>Create a Log formatter from a dict.</p> <p>Parameters:</p> Name Type Description Default <code>conf</code> <code>Dict[str, str]</code> <p>Dictionary containing format and datefmt</p> required <code>fmt_default</code> <code>str</code> <p>Default format to use if none specified.</p> required <code>datefmt_default</code> <code>str</code> <p>Default datefmt to use if none specified.</p> required Source code in <code>sramplatform/logbook.py</code> <pre><code>def make_formatter(conf: Dict[str, str], fmt_default: str, datefmt_default: str):\n\"\"\"Create a Log formatter from a dict.\n    Args:\n        conf: Dictionary containing format and datefmt\n        fmt_default: Default format to use if none specified.\n        datefmt_default: Default datefmt to use if none specified.\n    \"\"\"\nreturn logging.Formatter(\nconf.get(\"format\", fmt_default),\ndatefmt=conf.get(\"datefmt\", datefmt_default),\n)\n</code></pre>"},{"location":"platform_api/#sramplatform.platform.Dispatcher","title":"<code>Dispatcher</code>","text":"<p>Class used to dispatch reader methods based on the commands received.</p> <p>Attributes:</p> Name Type Description <code>agent</code> <p>Fenneq agent to listen for commands.</p> <code>logger</code> <p>Logger used to log information.</p> <code>db_session</code> <p>Session to a DB to store data.</p> Source code in <code>sramplatform/platform.py</code> <pre><code>class Dispatcher:\n\"\"\"Class used to dispatch reader methods based on the commands received.\n    Attributes:\n        agent: Fenneq agent to listen for commands.\n        logger: Logger used to log information.\n        db_session: Session to a DB to store data.\n    \"\"\"\ndef __init__(self, agent, logger, dbmanager, timeout):\nself.agent = agent\nself.dbmanager = dbmanager\nself.logger = logger\nself.timeout = timeout\ndef add_command(self, handler, func, **options):\n\"\"\"\n        \"\"\"\n@self.agent.on(handler, **options)\ndef handler_fn(msg):\ncommand = msg.body[\"command\"]\nself.logger.debug(\"Handler %s called\", command)\ntry:\nsignal.signal(signal.SIGALRM, timeout_handler)\nsignal.alarm(self.timeout)\nfunc(msg.body, self.logger, self.dbmanager.session)\nexcept TimeoutError:\nself.logger.critical(\"Handler %s timeout\", command)\nexcept CommandError as err:\nself.logger.error(\"%s\", err)\nexcept Exception as excep:\nself.logger.critical(f\"Error while executing handler: {excep}\")\nelse:\nself.logger.debug(\"Handler %s executed correctly\", command)\nfinally:\nsignal.alarm(0)\ndef run(self):\n\"\"\"Make the dispatcher listen for commands.\"\"\"\nself.logger.debug(f\"{self.agent.name} listening on {self.agent.exchange}\")\nself.agent.run()\n</code></pre>"},{"location":"platform_api/#sramplatform.platform.Dispatcher.run","title":"<code>run()</code>","text":"<p>Make the dispatcher listen for commands.</p> Source code in <code>sramplatform/platform.py</code> <pre><code>def run(self):\n\"\"\"Make the dispatcher listen for commands.\"\"\"\nself.logger.debug(f\"{self.agent.name} listening on {self.agent.exchange}\")\nself.agent.run()\n</code></pre>"},{"location":"platform_api/#sramplatform.platform.from_config","title":"<code>from_config(config_path, reader_cls)</code>","text":"<p>Read a YAML config to generate the components for a Dispatcher.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to the YAML config.</p> required <code>reader_cls</code> <code>ReaderType</code> <p>Class to use to instanciate a Reader.</p> required <p>Returns:</p> Type Description <code>Tuple[Agent, ReaderType, object]</code> <p>A tuple containing the Agent, Reader and Logger</p> Source code in <code>sramplatform/platform.py</code> <pre><code>def from_config(\nconfig_path: str, reader_cls: ReaderType\n) -&gt; Tuple[Agent, ReaderType, object]:\n\"\"\"Read a YAML config to generate the components for a Dispatcher.\n    Args:\n        config_path: Path to the YAML config.\n        reader_cls: Class to use to instanciate a Reader.\n    Returns:\n        A tuple containing the Agent, Reader and Logger\n    \"\"\"\nwith open(config_path, \"r\") as f:\nconfig = yaml.load(f, Loader=yaml.Loader)\nagent = Agent(**config[\"agent\"])\nreader = reader_cls(**config[\"reader\"])\nroot_logger = logging.getLogger(agent.name)\nroot_logger.setLevel(logging.DEBUG)\nconf_logging = config[\"logging\"]\nfmt_default = conf_logging[\"format\"]\ndatefmt_default = conf_logging[\"datefmt\"]\nfor logger_conf in conf_logging.get(\"loggers\", []):\nfor name, conf in logger_conf.items():\nhandler = create_handler(name, conf)\nlevel = logging.getLevelName(conf.get(\"level\", logging.INFO))\nhandler.setLevel(level)\nfilter_level = conf.get(\"filter_level\", None)\nif filter_level:\nhandler.addFilter(\nLogLevelFilter(logging.getLevelName(filter_level))\n)\ncustom_fmt = make_formatter(conf, fmt_default, datefmt_default)\nhandler.setFormatter(custom_fmt)\nroot_logger.addHandler(handler)\nreturn agent, reader, root_logger\n</code></pre>"},{"location":"starting/","title":"Getting started","text":""},{"location":"starting/#dependencies","title":"Dependencies","text":"<p>The platform uses RabbitMQ as the message broker and PostgreSQL as the default database. </p> <p>It is recommended to install Docker to use these tools.</p>"},{"location":"starting/#python-dependencies","title":"Python dependencies","text":"<p>It is recomended, but not mandatory, to create a virtual environment to install the requirements. The following code describes the process of creating a virtual env and installing the dependencies.</p> Using pip<pre><code>$ python3 -m venv /path/to/virtual_env\n$ source /path/to/virtual_env/bin/activate\n$ pip install -r requirements.txt\n$ deactivate # To exit the virtual environment\n</code></pre> Using poetry<pre><code>$ cd /path/to/SRAMPlatform\n$ poetry install\n</code></pre> <p>To connect and handle the connection to RabbitMQ, the library Fenneq is needed. It can be installed with the following commands.</p> Installing fenneq<pre><code>$ git clone https://github.com/servinagrero/fenneq.git &amp;&amp; cd fenneq\n$ poetry install # or pip install\n</code></pre>"},{"location":"tima/","title":"TIMA SRAM Platform","text":"<p>This section contains information about the SRAM platform that has been deployed and it's currently working at the TIMA Laboratory in Grenoble, France. </p> <p>The platform is composed of 84 ST nucleo boards and 45 ST discovery boards, composing a total of 129 devices.</p> <p> </p> SRAM Platform using STM32 devices at TIMA Laboratory"},{"location":"tima/#data-availability","title":"Data availability","text":"<p>The data gathered in this station is publicly available online. To request available data, simply click on the following button to be directed to the website. There, you should provide for contact information and you will be able to filter the data. If the data requested is too large, it will be compressed in a zip file before.</p> <p>Request data</p> <p>If the requested data is used within a scientific or technical publication, you are requested to cite the following paper:</p> <p>S. Vinagrero, H. Martin, A. de Bignicourt, E.-I. Vatajelu, and G. Di Natale, \"SRAM-Based PUF Readouts,\" Scientific Data 10, 333 (2023). https://doi.org/10.1038/s41597-023-02225-9</p> <p>Official publication</p>"},{"location":"tima/#documentation-structure","title":"Documentation structure","text":"<p>The following sections explain all the implementation details of this instance.</p> <p>The code reference for this instance can be found under the <code>src</code> folder inside the project. The instance source code documentation can be accesed directly here while the documentation of the source code of the devices used can be found here</p>"},{"location":"tima_api/","title":"Platform API","text":""},{"location":"tima_api/#src.stm32reader.Device","title":"<code>Device</code>  <code>dataclass</code>","text":"<p>Class to represent a device.</p> Source code in <code>src/stm32reader.py</code> <pre><code>@dataclass\nclass Device:\n\"\"\"Class to represent a device.\"\"\"\n#: Universal ID of the device\nuid: str\n#: Position In Chain of the device.\npic: int\n#: Size, in bytes, of the device's SRAM.\nsram_size: int\ndef __eq__(self, other):\nreturn self.uid == other.uid and self.pic == other.pic\ndef __hash__(self):\nreturn hash((\"uid\", self.uid, \"pic\", self.pic))\ndef __str__(self):\nreturn f\"{self.pic:03d}:{format_uid(self.uid)}\"\ndef __repr__(self):\nreturn f\"&lt;Device {self.pic:03d}:{format_uid(self.uid)} 0x{self.sram_size:08X}&gt;\"\n</code></pre>"},{"location":"tima_api/#src.stm32reader.STM32Reader","title":"<code>STM32Reader</code>","text":"<p>         Bases: <code>Reader</code></p> <p>Reader implementation for STM32 boards.</p> <p>The functionaly of the reader is implemented in the methods called <code>handle_{command}</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>Descriptive name of the Reader.</p> <code>devices</code> <code>List[Device]</code> <p>List of managed devices.</p> <code>port</code> <p>State of the devices and the serial port.</p> Source code in <code>src/stm32reader.py</code> <pre><code>class STM32Reader(Reader):\n\"\"\"Reader implementation for STM32 boards.\n    The functionaly of the reader is implemented in the methods called `handle_{command}`.\n    Attributes:\n        name: Descriptive name of the Reader.\n        devices: List of managed devices.\n        port: State of the devices and the serial port.\n    \"\"\"\ndef __init__(self, board_type: str, port: str, baudrate: int, data_size: int):\nsuper(STM32Reader, self).__init__(board_type)\nself.devices: List[Device] = []\nself.name = board_type\nself.data_size = data_size\nport_path = Path(port)\nif not port_path.exists():\nprint(f\"Port {port_path} does not exist\")\nsys.exit(1)\nser = Serial(port_path.as_posix(), baudrate, timeout=None)\nself.port = {\"state\": \"ON\", \"serial\": ser, \"path\": port_path}\ndef send(self, data: bytes):\n\"\"\"Transmit data through the serial port.\n        Args:\n            data: Bytes to sent.\n        \"\"\"\nser = self.port[\"serial\"]\nser.flushInput()\nser.write(data)\nser.flushOutput()\ndef receive(self, timeout: float = 0.2, tries=200) -&gt; List[Packet]:\n\"\"\"Received data from the serial port.\n        Args:\n            timeout: Time to wait until start receiving information.\n        Returns:\n            List of packets received.\n        \"\"\"\npacket_size = Packet.full_size(self.data_size)\nser = self.port[\"serial\"]\nser.flushInput()\npackets = []\nmsg = b\"\"\ntime.sleep(timeout)\nchecks = deque(maxlen=tries // 2)\nfor _ in range(tries):\nchecks.appendleft(ser.in_waiting)\nwhile ser.in_waiting:\nwhile len(msg) &lt; packet_size:\nmsg += ser.read()\npackets.append(Packet.from_bytes(self.data_size, msg))\nmsg = b\"\"\nif all(num == 0 for num in checks) and packets:\nreturn packets\ntime.sleep(0.05)\nreturn packets\ndef handle_status(self, props: Dict[str, Any], logger, db_session):\n\"\"\"Show the status of the reader.\n        Args:\n            props: Dict[str, Any] from the dispatcher\n            logger: Logger instance to log data.\n            db_session: DBManager instance to query and insert data.\n        Returns:\n            Status of the operation\n        \"\"\"\nlogger.results(\njson.dumps(\n{\n\"state\": self.port[\"state\"],\n\"devices\": [d.__dict__ for d in self.devices],\n}\n)\n)\ndef handle_power_off(self, props: Dict[str, Any], logger, db_session):\n\"\"\"Power off the serial port.\n        Args:\n            props: Dictionary containing the message from the dispatcher.\n        Returns:\n            Dictionary with the status of the operation and metadata if needed.\n        \"\"\"\ntry:\np = run([\"ykushcmd\", \"-d\", \"a\"])\nif p.returncode == 0:\nself.port[\"state\"] = \"OFF\"\nlogger.info(\"Port powered off\")\nelse:\nraise CommandError(\"Could not power off port\")\nexcept Exception as excep:\nraise CommandError(f\"Problem powering off port {self.port['path']}: {excep}\") from excep\ndef handle_power_on(self, props: Dict[str, Any], logger, db_session):\n\"\"\"Power on the serial port.\n        Args:\n            props: Dictionary containing the message from the dispatcher.\n        Returns:\n            Dictionary with the status of the operation and metadata if needed.\n        \"\"\"\ntry:\np = run([\"ykushcmd\", \"-u\", \"a\"])\nif p.returncode == 0:\nself.port[\"state\"] = \"ON\"\nlogger.info(\"Port powered on\")\nelse:\nraise CommandError(\"Could not power on port\")\nexcept Exception as excep:\nraise CommandError(f\"Problem powering on port {self.port['path']}: {excep}\") from excep\ndef handle_ping(self, props: Dict[str, Any], logger, db_session):\n\"\"\"Register the devices connected to the reader.\n        Args:\n            props: Dictionary containing the message from the dispatcher.\n        Returns:\n            Dictionary with the status of the operation and metadata if needed.\n        \"\"\"\nstatus_correct: Optional[bool] = None\nprev_devices = self.devices\npacket = Packet(self.data_size)\npacket.with_command(Command.PING)\npacket.craft()\nself.send(packet.to_bytes())\npackets = self.receive()\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\n\"Serial port is off. Please turn on the serial port first\"\n)\nif prev_devices and not packets:\nraise CommandError(\n\"There were devices connected but now no devices could be identified\"\n)\nif not packets:\nraise CommandError(\"No devices could be identified\")\ndevices: List[Device] = []\nfor packet in packets:\nif not packet.check_crc():\nlogger.warning(f\"Packet {packet!s} is corrupted\")\nstatus_correct = False\nelse:\ndevices.append(\nDevice(format_uid(packet.uid), packet.pic, packet.options)\n)\nself.devices = devices\nif status_correct is None:\nlogger.results(json.dumps([d.__dict__ for d in self.devices]))\ndef handle_sensors(self, props: Dict[str, Any], logger, db_session):\n\"\"\"Register the devices connected to the reader.\n        Args:\n            props: Dictionary containing the message from the dispatcher.\n        Returns:\n            Dictionary with the status of the operation and metadata if needed.\n        \"\"\"\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\"Serial port is off. Turn on the serial port first\")\nif not self.devices:\nraise CommandError(\"No devices managed\")\ncurrent_day = datetime.now()\ncurrent_day = current_day.replace(hour=12, minute=0, second=0)\nfor dev in self.devices:\npacket = Packet(self.data_size)\npacket.with_command(Command.SENSORS)\npacket.with_uid(dev.uid)\npacket.craft()\nself.send(packet.to_bytes())\nres = next(iter(self.receive()), None)\nif res is None:\nlogger.error(f\"Problem reading sensors for device {dev}\")\ncontinue\nif not packet.check_crc() or packet.command == Command.ERR:\nlogger.warning(\nf\"Packet {packet!s} for device {dev} is corrupted\"\n)\ncontinue\nsensors_data = res.extract_sensors()\nlogger.results(\njson.dumps(\n{\n\"device\": {\"uid\": dev.uid, \"pic\": dev.pic},\n\"temperature\": sensors_data[\"temperature\"],\n\"voltage\": sensors_data[\"voltage\"],\n}\n)\n)\ndb_session.add(\nSensor(\nuid=format_uid(res.uid),\npic=dev.pic,\nboard_type=self.name,\ntemperature=sensors_data[\"temperature\"],\nvoltage=sensors_data[\"voltage\"],\ncreated_at=current_day,\n)\n)\ndb_session.commit()\ndef handle_read(self, props: Dict[str, Any], logger, db_session):\n\"\"\" \"\"\"\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\"Serial port is off. Turn on the serial port first\")\nif not self.devices:\nraise CommandError(\"No devices managed\")\n# Only store the day the read is done\ncurrent_day = datetime.now()\ncurrent_day = current_day.replace(hour=12, minute=0, second=0)\nfor dev in self.devices:\nfor offset in range(dev.sram_size // self.data_size):\naddress = offset_to_address(self.data_size, offset)\npacket = Packet(self.data_size)\npacket.with_command(Command.READ)\npacket.with_uid(dev.uid)\npacket.with_options(offset)\npacket.craft()\nself.send(packet.to_bytes())\nres = next(iter(self.receive()), None)\nif res is None:\nlogger.error(\nf\"Problem reading memory of device {dev} at offset {offset}\"\n)\ncontinue\nif not packet.check_crc() or packet.command == Command.ERR:\nlogger.warning(f\"Packet {packet!s} is corrupted\")\ncontinue\ndb_session.add(\nSample(\nboard_type=self.name,\nuid=format_uid(res.uid),\npic=dev.pic,\naddress=address,\ndata=\",\".join([str(d) for d in res.data]),\ncreated_at=current_day,\n)\n)\ndb_session.commit()\nlogger.debug(f\"Read memory of device {dev} at offset {offset}\")\nlogger.info(f\"Finished reading memory of {dev}\")\ndef handle_write(self, props: Dict[str, Any], logger, db_session):\n\"\"\" \"\"\"\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\"Serial port is off. Turn on the serial port first\")\nif not self.devices:\nraise CommandError(\"No devices managed\")\noffset = props[\"offset\"]\ndev_id = props[\"device\"]\ndev = next(filter(lambda d: d.uid == dev_id, self.devices), None)\nif not dev:\nraise CommandError(f\"Device {dev.id} is not managed\")\nmax_offset = dev.sram_size // self.data_size\nif offset &lt; 0 or offset &gt; max_offset:\nraise CommandError(\nf\"Offset {offset} for device {dev_id} must be in range [0, {max_offset}]\"\n)\npacket = Packet(self.data_size)\npacket.with_command(Command.WRITE)\npacket.with_uid(dev.uid)\npacket.with_options(offset)\npacket.with_data([int(b) for b in props[\"data\"]])\npacket.craft()\nself.send(packet.to_bytes())\nres = next(iter(self.receive()), None)\nif res is None:\nraise CommandError(\nf\"Problem writing to memory of device {dev.pic}{dev.uid} at offset {offset}\"\n)\nif not res.check_crc() or res.command == Command.ERR:\nraise CommandError(f\"Packet {packet!s} is corrupted\")\nlogger.info(\"Data written correctly\")\ndef handle_write_invert(self, props: Dict[str, Any], logger, db_session):\n\"\"\"\n        We assume that a reader handles only one type of device,\n        So all devices *should* have the same memory regions.\n        Get first all different regions and later check that a device\n        has at least one sample of all of them.\n        \"\"\"\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\"Serial port is off. Turn on the serial port first\")\nif not self.devices:\nraise CommandError(\"No devices managed\")\ndevice_list = list(self.devices)\nfor dev in device_list[: len(self.devices) // 2]:\nnum_addresses = dev.sram_size // self.data_size\nsamples = (\ndb_session.query(Sample)\n.filter(Sample.uid == dev.uid)\n.order_by(Sample.address.asc(), Sample.created_at.asc())\n.limit(num_addresses)\n.all()\n)\nif not samples:\nlogger.warning(\nf\"At least one full memory sample has to be read from device {dev}\"\n)\ncontinue\nif len(samples) != num_addresses:\nlogger.warning(\nf\"The memory sample for device {dev} is not complete\"\n)\ncontinue\nend_offset = (num_addresses) - READ_ONLY_REGIONS\nfor offset in range(READ_ONLY_REGIONS, end_offset):\nsample = samples[offset]\npacket = Packet(self.data_size)\npacket.with_command(Command.WRITE)\npacket.with_uid(dev.uid)\npacket.with_options(offset)\npacket.with_data([0xFF ^ int(d) for d in sample.data.split(\",\")])\npacket.craft()\nself.send(packet.to_bytes())\nres = next(iter(self.receive()), None)\nif res is None:\nlogger.error(\nf\"Problem writing inverted values of device {dev.pic}{dev.uid} at offset {offset}\"\n)\ncontinue\nif not res.check_crc() or res.command == Command.ERR:\nlogger.warning(f\"Packet {packet!s} is corrupted\")\ncontinue\nlogger.debug(f\"Inverted memory of device {dev} at offset {offset}\")\nlogger.info(f\"Finished inverting memory of device {dev}\")\ndef handle_write_const(self, props: Dict[str, Any], logger, db_session):\n\"\"\"\n        \"\"\"\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\"Serial port is off. Turn on the serial port first\")\nif not self.devices:\nraise CommandError(\"No devices managed\")\nvalue = props[\"value\"]\ndev_id = props[\"device\"]\ndev = next(filter(lambda d: d.uid == dev_id, self.devices), None)\nif not dev:\nraise CommandError(f\"Device {dev.id} is not managed\")\nend_offset = (num_addresses) - READ_ONLY_REGIONS\nfor offset in range(READ_ONLY_REGIONS, end_offset):\nsample = samples[offset]\npacket = Packet(self.data_size)\npacket.with_command(Command.WRITE)\npacket.with_uid(dev.uid)\npacket.with_options(offset)\npacket.with_data([value] * self.data_size)\npacket.craft()\nself.send(packet.to_bytes())\nres = next(iter(self.receive()), None)\nif res is None:\nlogger.error(\nf\"Problem writing constant value of device {dev} at offset {offset}\"\n)\ncontinue\nif not res.check_crc() or res.command == Command.ERR:\nlogger.warning(f\"Packet {packet!s} is corrupted\")\ncontinue\nlogger.debug(f\"Wrote constant in memory of device {dev} at offset {offset}\")\nlogger.info(f\"Finished writing constant to memory of device {dev}\")\ndef handle_load(self, props: Dict[str, Any], logger, db_session):\n\"\"\" \"\"\"\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\"Serial port is off. Turn on the serial port first\")\nif not self.devices:\nraise CommandError(\"No devices managed\")\ndev_uid = props[\"device\"]\ndev = next(filter(lambda d: d.uid == dev_uid, self.devices), None)\nif not dev:\nraise CommandError(f\"Device {dev.uid} is not managed\")\nsource = props[\"source\"]\nlen_code = len(source)\ndata_buf = [ord(c) for c in source] + [ord(\"\\x00\")] * (\nself.data_size - len_code\n)\npacket = Packet(self.data_size)\npacket.with_command(Command.LOAD)\npacket.with_uid(dev_uid)\npacket.with_data(data_buf)\npacket.craft()\nself.send(packet.to_bytes())\nres = next(iter(self.receive()), None)\nif res is None:\nraise CommandError(f\"Problem loading code for device {dev}\")\nif not res.check_crc() or res.command == Command.ERR:\nraise CommandError(f\"Packet {packet!s} is corrupted\")\nlogger.info(f\"Code loaded on device {dev} correctly\")\ndef handle_exec(self, props: Dict[str, Any], logger, db_session):\n\"\"\" \"\"\"\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\"Serial port is off. Turn on the serial port first\")\nif not self.devices:\nraise CommandError(\"No devices managed\")\ndev_uid = props[\"device\"]\ndev = next(filter(lambda d: d.uid == dev_uid, self.devices), None)\nif not dev:\nraise CommandError(f\"Device {dev_uid} is not managed\")\npacket = Packet(self.data_size)\npacket.with_command(Command.EXEC)\npacket.with_uid(dev_uid)\npacket.with_options(int(props.get(\"reset\", 0)))\npacket.craft()\nself.send(packet.to_bytes())\nres = next(iter(self.receive()), None)\nif res is None:\nraise CommandError(f\"Problem executing code on device {dev.pic}{dev.uid}\")\nif not res.check_crc() or res.command == Command.ERR:\nraise CommandError(f\"Packet {packet!s} is corrupted\")\nif res.options != 0:\nraise CommandError(\nf\"Code on device {dev} executed with error code {res.options}\"\n)\nlogger.info(f\"Code on device {dev} executed correctly\")\ndef handle_retr(self, props: Dict[str, Any], logger, db_session):\n\"\"\" \"\"\"\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\"Serial port is off. Turn on the serial port first\")\nif not self.devices:\nraise CommandError(\"No devices managed\")\ndev_uid = props[\"device\"]\ndev = next(filter(lambda d: d.uid == dev_uid, self.devices), None)\nif not dev:\nraise CommandError(f\"Device {dev_uid} is not managed\")\npacket = Packet(self.data_size)\npacket.with_command(Command.RETR)\npacket.with_uid(dev.uid)\npacket.craft()\nself.send(packet.to_bytes())\nres = next(iter(self.receive()), None)\nif res is None:\nraise CommandError(\nf\"Problem retrieving results from device {dev}\"\n)\nif not res.check_crc() or res.command == Command.ERR:\nraise CommandError(f\"Packet {packet!s} is corrupted\")\nnumbers = struct.unpack(f\"&lt;{self.data_size // 4}i\", bytes(res.data))\nnumbers_str = map(str, numbers)\nnumbers_str = map(\nlambda n: n.replace(\"10\", \"\\n\").replace(\"32\", \" \"), numbers_str\n)\nlogger.info(f\"Results retrieved correctly from device {dev_uid}\")\nlogger.results(\njson.dumps(\n{\n\"raw_bytes\": res.data,\n\"int\": numbers,\n\"string\": \"\".join(numbers_str),\n}\n)\n)\n</code></pre>"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_ping","title":"<code>handle_ping(props, logger, db_session)</code>","text":"<p>Register the devices connected to the reader.</p> <p>Parameters:</p> Name Type Description Default <code>props</code> <code>Dict[str, Any]</code> <p>Dictionary containing the message from the dispatcher.</p> required <p>Returns:</p> Type Description <p>Dictionary with the status of the operation and metadata if needed.</p> Source code in <code>src/stm32reader.py</code> <pre><code>def handle_ping(self, props: Dict[str, Any], logger, db_session):\n\"\"\"Register the devices connected to the reader.\n    Args:\n        props: Dictionary containing the message from the dispatcher.\n    Returns:\n        Dictionary with the status of the operation and metadata if needed.\n    \"\"\"\nstatus_correct: Optional[bool] = None\nprev_devices = self.devices\npacket = Packet(self.data_size)\npacket.with_command(Command.PING)\npacket.craft()\nself.send(packet.to_bytes())\npackets = self.receive()\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\n\"Serial port is off. Please turn on the serial port first\"\n)\nif prev_devices and not packets:\nraise CommandError(\n\"There were devices connected but now no devices could be identified\"\n)\nif not packets:\nraise CommandError(\"No devices could be identified\")\ndevices: List[Device] = []\nfor packet in packets:\nif not packet.check_crc():\nlogger.warning(f\"Packet {packet!s} is corrupted\")\nstatus_correct = False\nelse:\ndevices.append(\nDevice(format_uid(packet.uid), packet.pic, packet.options)\n)\nself.devices = devices\nif status_correct is None:\nlogger.results(json.dumps([d.__dict__ for d in self.devices]))\n</code></pre>"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_power_off","title":"<code>handle_power_off(props, logger, db_session)</code>","text":"<p>Power off the serial port.</p> <p>Parameters:</p> Name Type Description Default <code>props</code> <code>Dict[str, Any]</code> <p>Dictionary containing the message from the dispatcher.</p> required <p>Returns:</p> Type Description <p>Dictionary with the status of the operation and metadata if needed.</p> Source code in <code>src/stm32reader.py</code> <pre><code>def handle_power_off(self, props: Dict[str, Any], logger, db_session):\n\"\"\"Power off the serial port.\n    Args:\n        props: Dictionary containing the message from the dispatcher.\n    Returns:\n        Dictionary with the status of the operation and metadata if needed.\n    \"\"\"\ntry:\np = run([\"ykushcmd\", \"-d\", \"a\"])\nif p.returncode == 0:\nself.port[\"state\"] = \"OFF\"\nlogger.info(\"Port powered off\")\nelse:\nraise CommandError(\"Could not power off port\")\nexcept Exception as excep:\nraise CommandError(f\"Problem powering off port {self.port['path']}: {excep}\") from excep\n</code></pre>"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_power_on","title":"<code>handle_power_on(props, logger, db_session)</code>","text":"<p>Power on the serial port.</p> <p>Parameters:</p> Name Type Description Default <code>props</code> <code>Dict[str, Any]</code> <p>Dictionary containing the message from the dispatcher.</p> required <p>Returns:</p> Type Description <p>Dictionary with the status of the operation and metadata if needed.</p> Source code in <code>src/stm32reader.py</code> <pre><code>def handle_power_on(self, props: Dict[str, Any], logger, db_session):\n\"\"\"Power on the serial port.\n    Args:\n        props: Dictionary containing the message from the dispatcher.\n    Returns:\n        Dictionary with the status of the operation and metadata if needed.\n    \"\"\"\ntry:\np = run([\"ykushcmd\", \"-u\", \"a\"])\nif p.returncode == 0:\nself.port[\"state\"] = \"ON\"\nlogger.info(\"Port powered on\")\nelse:\nraise CommandError(\"Could not power on port\")\nexcept Exception as excep:\nraise CommandError(f\"Problem powering on port {self.port['path']}: {excep}\") from excep\n</code></pre>"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_sensors","title":"<code>handle_sensors(props, logger, db_session)</code>","text":"<p>Register the devices connected to the reader.</p> <p>Parameters:</p> Name Type Description Default <code>props</code> <code>Dict[str, Any]</code> <p>Dictionary containing the message from the dispatcher.</p> required <p>Returns:</p> Type Description <p>Dictionary with the status of the operation and metadata if needed.</p> Source code in <code>src/stm32reader.py</code> <pre><code>def handle_sensors(self, props: Dict[str, Any], logger, db_session):\n\"\"\"Register the devices connected to the reader.\n    Args:\n        props: Dictionary containing the message from the dispatcher.\n    Returns:\n        Dictionary with the status of the operation and metadata if needed.\n    \"\"\"\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\"Serial port is off. Turn on the serial port first\")\nif not self.devices:\nraise CommandError(\"No devices managed\")\ncurrent_day = datetime.now()\ncurrent_day = current_day.replace(hour=12, minute=0, second=0)\nfor dev in self.devices:\npacket = Packet(self.data_size)\npacket.with_command(Command.SENSORS)\npacket.with_uid(dev.uid)\npacket.craft()\nself.send(packet.to_bytes())\nres = next(iter(self.receive()), None)\nif res is None:\nlogger.error(f\"Problem reading sensors for device {dev}\")\ncontinue\nif not packet.check_crc() or packet.command == Command.ERR:\nlogger.warning(\nf\"Packet {packet!s} for device {dev} is corrupted\"\n)\ncontinue\nsensors_data = res.extract_sensors()\nlogger.results(\njson.dumps(\n{\n\"device\": {\"uid\": dev.uid, \"pic\": dev.pic},\n\"temperature\": sensors_data[\"temperature\"],\n\"voltage\": sensors_data[\"voltage\"],\n}\n)\n)\ndb_session.add(\nSensor(\nuid=format_uid(res.uid),\npic=dev.pic,\nboard_type=self.name,\ntemperature=sensors_data[\"temperature\"],\nvoltage=sensors_data[\"voltage\"],\ncreated_at=current_day,\n)\n)\ndb_session.commit()\n</code></pre>"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_status","title":"<code>handle_status(props, logger, db_session)</code>","text":"<p>Show the status of the reader.</p> <p>Parameters:</p> Name Type Description Default <code>props</code> <code>Dict[str, Any]</code> <p>Dict[str, Any] from the dispatcher</p> required <code>logger</code> <p>Logger instance to log data.</p> required <code>db_session</code> <p>DBManager instance to query and insert data.</p> required <p>Returns:</p> Type Description <p>Status of the operation</p> Source code in <code>src/stm32reader.py</code> <pre><code>def handle_status(self, props: Dict[str, Any], logger, db_session):\n\"\"\"Show the status of the reader.\n    Args:\n        props: Dict[str, Any] from the dispatcher\n        logger: Logger instance to log data.\n        db_session: DBManager instance to query and insert data.\n    Returns:\n        Status of the operation\n    \"\"\"\nlogger.results(\njson.dumps(\n{\n\"state\": self.port[\"state\"],\n\"devices\": [d.__dict__ for d in self.devices],\n}\n)\n)\n</code></pre>"},{"location":"tima_api/#src.stm32reader.STM32Reader.handle_write_invert","title":"<code>handle_write_invert(props, logger, db_session)</code>","text":"<p>We assume that a reader handles only one type of device, So all devices should have the same memory regions.</p> <p>Get first all different regions and later check that a device has at least one sample of all of them.</p> Source code in <code>src/stm32reader.py</code> <pre><code>def handle_write_invert(self, props: Dict[str, Any], logger, db_session):\n\"\"\"\n    We assume that a reader handles only one type of device,\n    So all devices *should* have the same memory regions.\n    Get first all different regions and later check that a device\n    has at least one sample of all of them.\n    \"\"\"\nif self.port[\"state\"] == \"OFF\":\nraise CommandError(\"Serial port is off. Turn on the serial port first\")\nif not self.devices:\nraise CommandError(\"No devices managed\")\ndevice_list = list(self.devices)\nfor dev in device_list[: len(self.devices) // 2]:\nnum_addresses = dev.sram_size // self.data_size\nsamples = (\ndb_session.query(Sample)\n.filter(Sample.uid == dev.uid)\n.order_by(Sample.address.asc(), Sample.created_at.asc())\n.limit(num_addresses)\n.all()\n)\nif not samples:\nlogger.warning(\nf\"At least one full memory sample has to be read from device {dev}\"\n)\ncontinue\nif len(samples) != num_addresses:\nlogger.warning(\nf\"The memory sample for device {dev} is not complete\"\n)\ncontinue\nend_offset = (num_addresses) - READ_ONLY_REGIONS\nfor offset in range(READ_ONLY_REGIONS, end_offset):\nsample = samples[offset]\npacket = Packet(self.data_size)\npacket.with_command(Command.WRITE)\npacket.with_uid(dev.uid)\npacket.with_options(offset)\npacket.with_data([0xFF ^ int(d) for d in sample.data.split(\",\")])\npacket.craft()\nself.send(packet.to_bytes())\nres = next(iter(self.receive()), None)\nif res is None:\nlogger.error(\nf\"Problem writing inverted values of device {dev.pic}{dev.uid} at offset {offset}\"\n)\ncontinue\nif not res.check_crc() or res.command == Command.ERR:\nlogger.warning(f\"Packet {packet!s} is corrupted\")\ncontinue\nlogger.debug(f\"Inverted memory of device {dev} at offset {offset}\")\nlogger.info(f\"Finished inverting memory of device {dev}\")\n</code></pre>"},{"location":"tima_api/#src.stm32reader.STM32Reader.receive","title":"<code>receive(timeout=0.2, tries=200)</code>","text":"<p>Received data from the serial port.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float</code> <p>Time to wait until start receiving information.</p> <code>0.2</code> <p>Returns:</p> Type Description <code>List[Packet]</code> <p>List of packets received.</p> Source code in <code>src/stm32reader.py</code> <pre><code>def receive(self, timeout: float = 0.2, tries=200) -&gt; List[Packet]:\n\"\"\"Received data from the serial port.\n    Args:\n        timeout: Time to wait until start receiving information.\n    Returns:\n        List of packets received.\n    \"\"\"\npacket_size = Packet.full_size(self.data_size)\nser = self.port[\"serial\"]\nser.flushInput()\npackets = []\nmsg = b\"\"\ntime.sleep(timeout)\nchecks = deque(maxlen=tries // 2)\nfor _ in range(tries):\nchecks.appendleft(ser.in_waiting)\nwhile ser.in_waiting:\nwhile len(msg) &lt; packet_size:\nmsg += ser.read()\npackets.append(Packet.from_bytes(self.data_size, msg))\nmsg = b\"\"\nif all(num == 0 for num in checks) and packets:\nreturn packets\ntime.sleep(0.05)\nreturn packets\n</code></pre>"},{"location":"tima_api/#src.stm32reader.STM32Reader.send","title":"<code>send(data)</code>","text":"<p>Transmit data through the serial port.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>Bytes to sent.</p> required Source code in <code>src/stm32reader.py</code> <pre><code>def send(self, data: bytes):\n\"\"\"Transmit data through the serial port.\n    Args:\n        data: Bytes to sent.\n    \"\"\"\nser = self.port[\"serial\"]\nser.flushInput()\nser.write(data)\nser.flushOutput()\n</code></pre>"},{"location":"tima_api/#database","title":"Database","text":"<p>         Bases: <code>TableBase</code></p> Source code in <code>src/database.py</code> <pre><code>class Sample(TableBase):\n__tablename__ = \"CRPs\"\n# Internal id of the sample.\nid = Column(Integer, primary_key=True)\n# Type of device connected in the chain.\nboard_type = Column(String, nullable=False)\n# Universal ID of the device.\nuid = Column(String, nullable=False)\n# Position In Chain of the device.\npic = Column(Integer, nullable=False)\n# Region of SRAM. Formated as 0x00000000\naddress = Column(String, nullable=False)\n# Comma separated list of values from the memory.\ndata = Column(String, nullable=False)\n# Timestamp when the sample was gathered.\ncreated_at = Column(DateTime, server_default=func.now(), nullable=False)\n</code></pre> <p>         Bases: <code>TableBase</code></p> Source code in <code>src/database.py</code> <pre><code>class Sensor(TableBase):\n__tablename__ = \"Sensors\"\n# Internal id of the sensor data.\nid = Column(Integer, primary_key=True)\n# Type of device connected in the chain.\nboard_type = Column(String, nullable=False)\n# Universal ID of the device.\nuid = Column(String, nullable=False)\n# Temperature value in degrees celsius.\ntemperature = Column(Float, nullable=False)\n# Internal VDD in volts.\nvoltage = Column(Float, nullable=False)\n# Timestamp when the sensor data was obtained.\ncreated_at = Column(DateTime, server_default=func.now(), nullable=False)\n</code></pre>"}]}